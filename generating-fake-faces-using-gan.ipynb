{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nimport keras \nfrom keras import layers\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport cv2\nimport os\nfrom tqdm import tqdm\nimport re\nfrom keras.preprocessing.image import img_to_array","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-08-11T21:20:42.855552Z","iopub.execute_input":"2022-08-11T21:20:42.855872Z","iopub.status.idle":"2022-08-11T21:20:42.861960Z","shell.execute_reply.started":"2022-08-11T21:20:42.855842Z","shell.execute_reply":"2022-08-11T21:20:42.860936Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"# # to get the files in proper order\n# def sorted_alphanumeric(data):  \n#     convert = lambda text: int(text) if text.isdigit() else text.lower()\n#     alphanum_key = lambda key: [convert(c) for c in re.split('([0-9]+)',key)]\n#     return sorted(data,key = alphanum_key)\n# # defining the size of the image\nimagetype= os.listdir(\"../input/fer2013/train/disgust\")\n_img = []\nfor i in imagetype: \n    img = cv2.imread(\"../input/fer2013/train/disgust/\"+i,1)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n            #resizing image\n    img = cv2.resize(img, (128 , 128))\n    img = (img - 127.5) / 127.5\n    img = img.astype(float)\n    _img.append(img_to_array(img))\n# for i in tqdm(files):    \n#         if i == 'seed9090.png':\n#             break\n#         else:    \n#             img = cv2.imread(path + '/'+i,1)\n#             # open cv reads images in BGR format so we have to convert it to RGB\n#             img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n#             #resizing image\n#             img = cv2.resize(img, (SIZE, SIZE))\n#             img = (img - 127.5) / 127.5\n#             imh = img.astype(float)\n#             _img.append(img_to_array(img))","metadata":{"execution":{"iopub.status.busy":"2022-08-11T21:20:43.063756Z","iopub.execute_input":"2022-08-11T21:20:43.064108Z","iopub.status.idle":"2022-08-11T21:20:43.824194Z","shell.execute_reply.started":"2022-08-11T21:20:43.064078Z","shell.execute_reply":"2022-08-11T21:20:43.823417Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"## Visailze our images","metadata":{}},{"cell_type":"code","source":"def plot_images(sqr = 5):\n    plt.figure(figsize = (10,10))\n    plt.title(\"Real Images\",fontsize = 35)\n    for i in range(sqr * sqr):\n        plt.subplot(sqr,sqr,i+1)\n        plt.imshow(_img[i]*0.5 + 0.5 )\n        plt.xticks([])\n        plt.yticks([])\n\n# to plot images\nplot_images(6)\n    ","metadata":{"execution":{"iopub.status.busy":"2022-08-11T21:20:44.211626Z","iopub.execute_input":"2022-08-11T21:20:44.212088Z","iopub.status.idle":"2022-08-11T21:20:45.915478Z","shell.execute_reply.started":"2022-08-11T21:20:44.212049Z","shell.execute_reply":"2022-08-11T21:20:45.914068Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":"Here, i have defined batch size so that these batches of images can be fed directly to the discriminator network","metadata":{}},{"cell_type":"code","source":"batch_size = 32\ndataset=tf.data.Dataset.from_tensor_slices(np.array(_img)).batch(batch_size)","metadata":{"execution":{"iopub.status.busy":"2022-08-11T21:21:14.127163Z","iopub.execute_input":"2022-08-11T21:21:14.127606Z","iopub.status.idle":"2022-08-11T21:21:14.228785Z","shell.execute_reply.started":"2022-08-11T21:21:14.127561Z","shell.execute_reply":"2022-08-11T21:21:14.228014Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"# Generator \nHere, I have defined generator network. It take random vector from normal distribution as input. This random vector is passed through dense layer and is reshaped and is finally fed through Convolution layers. Here, convolution layers does downsampling of our latent vector, after series of convolution batch normalization and leakyrelu layer our downsampled latent vector is upsampled using Conv2DTranspose.\n\nThe final output layer of Generator generate 128 by 128 by 3 image. The final layer of generator uses hyperbolic tangent as activation to squash the value in between -1 and 1. Generator model looks like simple autoencoder model, where input data is downsampled first and is finally upsampled .","metadata":{}},{"cell_type":"code","source":"latent_dim = 100\ndef Generator():\n    model = tf.keras.Sequential()\n    model.add(layers.Dense(128*128*3, use_bias=False, input_shape=(latent_dim,)))\n    model.add(layers.Reshape((128,128,3)))\n    # downsampling\n    model.add(tf.keras.layers.Conv2D(128,4, strides=1, padding='same',kernel_initializer='he_normal', use_bias=False))\n    model.add(tf.keras.layers.Conv2D(128,4, strides=2, padding='same',kernel_initializer='he_normal', use_bias=False))\n    model.add(tf.keras.layers.BatchNormalization())\n    model.add(tf.keras.layers.LeakyReLU())\n    model.add(tf.keras.layers.Conv2D(256,4, strides=1, padding='same',kernel_initializer='he_normal', use_bias=False))\n    model.add(tf.keras.layers.Conv2D(256,4, strides=2, padding='same',kernel_initializer='he_normal', use_bias=False))\n    model.add(tf.keras.layers.BatchNormalization())\n    model.add(tf.keras.layers.LeakyReLU())\n    model.add(tf.keras.layers.Conv2DTranspose(512, 4, strides=1,padding='same',kernel_initializer='he_normal',use_bias=False))\n    model.add(tf.keras.layers.Conv2D(512,4, strides=2, padding='same',kernel_initializer='he_normal', use_bias=False))\n    \n    model.add(tf.keras.layers.LeakyReLU())\n    #upsampling\n    model.add(tf.keras.layers.Conv2DTranspose(512, 4, strides=1,padding='same',kernel_initializer='he_normal',use_bias=False))\n    model.add(tf.keras.layers.Conv2DTranspose(512, 4, strides=2,padding='same',kernel_initializer='he_normal',use_bias=False))\n    model.add(tf.keras.layers.BatchNormalization())\n    model.add(tf.keras.layers.LeakyReLU())\n    model.add(tf.keras.layers.Conv2DTranspose(256, 4, strides=1,padding='same',kernel_initializer='he_normal',use_bias=False))\n    model.add(tf.keras.layers.Conv2DTranspose(256, 4, strides=2,padding='same',kernel_initializer='he_normal',use_bias=False))\n    model.add(tf.keras.layers.BatchNormalization())\n    \n    model.add(tf.keras.layers.Conv2DTranspose(128, 4, strides=2,padding='same',kernel_initializer='he_normal',use_bias=False))\n    model.add(tf.keras.layers.Conv2DTranspose(128, 4, strides=1,padding='same',kernel_initializer='he_normal',use_bias=False))\n    model.add(tf.keras.layers.BatchNormalization())\n    model.add(tf.keras.layers.Conv2DTranspose(3,4,strides = 1, padding = 'same',activation = 'tanh'))\n    \n    \n\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-08-11T21:21:44.836980Z","iopub.execute_input":"2022-08-11T21:21:44.837317Z","iopub.status.idle":"2022-08-11T21:21:44.850645Z","shell.execute_reply.started":"2022-08-11T21:21:44.837287Z","shell.execute_reply":"2022-08-11T21:21:44.849571Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"generator = Generator()\ngenerator.summary()","metadata":{"execution":{"iopub.status.busy":"2022-08-11T21:21:47.074007Z","iopub.execute_input":"2022-08-11T21:21:47.074388Z","iopub.status.idle":"2022-08-11T21:21:47.261637Z","shell.execute_reply.started":"2022-08-11T21:21:47.074355Z","shell.execute_reply":"2022-08-11T21:21:47.260872Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":"# Discriminator\nHere, discriminator model take 128 by 128 by 3 image that can be real or generated. This input image is downsampled using Convolution layer and is finally flattened and is fed to single neuron so that it can distinguish real and fake image. Since, final layer uses sigmoid function as activation, it output value in between 0 and 1. Here value greater than 0.5 refers to real and less than 0.5 refers to fake image. The output of discriminator is used in training of generator.","metadata":{}},{"cell_type":"code","source":"def Discriminator():\n    model = tf.keras.models.Sequential()\n    model.add(tf.keras.layers.Input((128, 128, 3)))\n    model.add(tf.keras.layers.Conv2D(128,4, strides=2, padding='same',kernel_initializer='he_normal', use_bias=False))\n    model.add(tf.keras.layers.BatchNormalization())\n    model.add(tf.keras.layers.LeakyReLU())\n    model.add(tf.keras.layers.Conv2D(128,4, strides=2, padding='same',kernel_initializer='he_normal', use_bias=False))\n    model.add(tf.keras.layers.BatchNormalization())\n    model.add(tf.keras.layers.LeakyReLU())\n    model.add(tf.keras.layers.Conv2D(256,4, strides=2, padding='same',kernel_initializer='he_normal', use_bias=False))\n    model.add(tf.keras.layers.BatchNormalization())\n    model.add(tf.keras.layers.LeakyReLU())\n    model.add(tf.keras.layers.Conv2D(256,4, strides=2, padding='same',kernel_initializer='he_normal', use_bias=False))\n    model.add(tf.keras.layers.BatchNormalization())\n    model.add(tf.keras.layers.LeakyReLU())\n    model.add(tf.keras.layers.Conv2D(512,4, strides=2, padding='same',kernel_initializer='he_normal', use_bias=False))\n    model.add(tf.keras.layers.LeakyReLU())\n    model.add(tf.keras.layers.Flatten())\n    model.add(tf.keras.layers.Dense(1,activation = 'sigmoid'))\n    return model\n  \n","metadata":{"execution":{"iopub.status.busy":"2022-08-11T21:21:51.337530Z","iopub.execute_input":"2022-08-11T21:21:51.337948Z","iopub.status.idle":"2022-08-11T21:21:51.349595Z","shell.execute_reply.started":"2022-08-11T21:21:51.337895Z","shell.execute_reply":"2022-08-11T21:21:51.348785Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"discriminator = Discriminator()\ndiscriminator.summary()","metadata":{"execution":{"iopub.status.busy":"2022-08-11T21:21:51.648150Z","iopub.execute_input":"2022-08-11T21:21:51.649073Z","iopub.status.idle":"2022-08-11T21:21:51.778519Z","shell.execute_reply.started":"2022-08-11T21:21:51.649033Z","shell.execute_reply":"2022-08-11T21:21:51.777687Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":"### Let's plot image generated by generator before training","metadata":{}},{"cell_type":"code","source":"noise = np.random.normal(-1,1,(1,100))\nimg = generator(noise)\nplt.imshow(img[0,:,:,0])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-11T21:21:54.026124Z","iopub.execute_input":"2022-08-11T21:21:54.026469Z","iopub.status.idle":"2022-08-11T21:21:54.335038Z","shell.execute_reply.started":"2022-08-11T21:21:54.026439Z","shell.execute_reply":"2022-08-11T21:21:54.334256Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"markdown","source":"### Defining loss function and optimizer ","metadata":{}},{"cell_type":"code","source":"optimizer = tf.keras.optimizers.RMSprop(\n        lr=.0001,\n        clipvalue=1.0,\n        decay=1e-8\n    )\ncross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits = True)","metadata":{"execution":{"iopub.status.busy":"2022-08-11T21:21:57.104208Z","iopub.execute_input":"2022-08-11T21:21:57.104539Z","iopub.status.idle":"2022-08-11T21:21:57.113478Z","shell.execute_reply.started":"2022-08-11T21:21:57.104510Z","shell.execute_reply":"2022-08-11T21:21:57.112624Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"def generator_loss(fake_output):\n    return cross_entropy(tf.ones_like(fake_output),fake_output)\ndef discriminator_loss(fake_output, real_output):\n    fake_loss = cross_entropy(tf.zeros_like(fake_output),fake_output)\n    real_loss = cross_entropy(tf.ones_like(real_output),real_output)\n    return fake_loss + real_loss","metadata":{"execution":{"iopub.status.busy":"2022-08-11T21:21:57.849149Z","iopub.execute_input":"2022-08-11T21:21:57.849462Z","iopub.status.idle":"2022-08-11T21:21:57.854563Z","shell.execute_reply.started":"2022-08-11T21:21:57.849434Z","shell.execute_reply":"2022-08-11T21:21:57.853338Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"markdown","source":"### Defining training steps","metadata":{}},{"cell_type":"code","source":"def train_steps(images):\n    noise = np.random.normal(0,1,(batch_size,latent_dim))\n    with tf.GradientTape() as gen_tape , tf.GradientTape() as disc_tape:\n        generated_images = generator(noise)\n        fake_output = discriminator(generated_images)\n        real_output = discriminator(images)\n        \n        gen_loss = generator_loss(fake_output)\n        dis_loss = discriminator_loss(fake_output, real_output)\n        \n        \n    gradient_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)    \n    gradient_of_discriminator = disc_tape.gradient(dis_loss, discriminator.trainable_variables)\n    \n    optimizer.apply_gradients(zip(gradient_of_generator,generator.trainable_variables))\n    optimizer.apply_gradients(zip(gradient_of_discriminator, discriminator.trainable_variables))\n    \n    loss = {'gen loss':gen_loss,\n           'disc loss': dis_loss}\n    return loss","metadata":{"execution":{"iopub.status.busy":"2022-08-11T21:22:01.666201Z","iopub.execute_input":"2022-08-11T21:22:01.666605Z","iopub.status.idle":"2022-08-11T21:22:01.673900Z","shell.execute_reply.started":"2022-08-11T21:22:01.666570Z","shell.execute_reply":"2022-08-11T21:22:01.672791Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"markdown","source":"## function to plot generated images\n","metadata":{}},{"cell_type":"code","source":"def plot_generated_images(square = 5, epochs = 0):\n    \n    \n  plt.figure(figsize = (10,10))\n  for i in range(square * square):\n    if epochs != 0:    \n        if(i == square //2):\n            plt.title(\"Generated Image at Epoch:{}\\n\".format(epochs), fontsize = 32, color = 'black')\n    plt.subplot(square, square, i+1)\n    noise = np.random.normal(0,1,(1,latent_dim))\n    img = generator(noise)\n    plt.imshow(np.clip((img[0,...]+1)/2, 0, 1))\n    \n    plt.xticks([])\n    plt.yticks([])\n    plt.grid()","metadata":{"execution":{"iopub.status.busy":"2022-08-11T21:22:03.765373Z","iopub.execute_input":"2022-08-11T21:22:03.765768Z","iopub.status.idle":"2022-08-11T21:22:03.773401Z","shell.execute_reply.started":"2022-08-11T21:22:03.765733Z","shell.execute_reply":"2022-08-11T21:22:03.772317Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"import time\ndef train(epochs,dataset):\n    \n    for epoch in range(epochs):\n        start = time.time()\n        print(\"\\nEpoch : {}\".format(epoch + 1))\n        for images in dataset:\n            loss = train_steps(images)\n        print(\" Time:{}\".format(np.round(time.time() - start),2)) \n        print(\"Generator Loss: {} Discriminator Loss: {}\".format(loss['gen loss'],loss['disc loss']))\n            \n        \n        \n    ","metadata":{"execution":{"iopub.status.busy":"2022-08-11T21:22:05.390055Z","iopub.execute_input":"2022-08-11T21:22:05.390383Z","iopub.status.idle":"2022-08-11T21:22:05.396132Z","shell.execute_reply.started":"2022-08-11T21:22:05.390351Z","shell.execute_reply":"2022-08-11T21:22:05.395253Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"code","source":"\ntrain(50,dataset)\n# i had train model previously for more than 10 epochs so generated images are quiet good","metadata":{"execution":{"iopub.status.busy":"2022-08-11T21:23:39.844594Z","iopub.execute_input":"2022-08-11T21:23:39.844906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Some Generated Images\n","metadata":{}},{"cell_type":"code","source":"plot_generated_images(1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_generated_images(2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_generated_images(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_generated_images(7)","metadata":{"execution":{"iopub.status.busy":"2022-08-11T21:23:14.149245Z","iopub.execute_input":"2022-08-11T21:23:14.149649Z","iopub.status.idle":"2022-08-11T21:23:16.398725Z","shell.execute_reply.started":"2022-08-11T21:23:14.149618Z","shell.execute_reply":"2022-08-11T21:23:16.397950Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"generator.save('generator.h5')\ndiscriminator.save(\"discriminator.h5\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### ref: <a href = 'https://machinelearningmastery.com/what-are-generative-adversarial-networks-gans/'> machinelearningmastery </a>, <a href = 'https://towardsdatascience.com/generative-adversarial-network-gan-for-dummies-a-step-by-step-tutorial-fdefff170391'> towardsdatascience </a>","metadata":{}},{"cell_type":"markdown","source":"### Thanks for your visit\n## Any suggestion to improve generated images is really appreciated\n## Feel free to comment and upvote.....\n# Thank You","metadata":{}}]}