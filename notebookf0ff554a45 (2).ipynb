{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"    # This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"../input/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-24T18:45:47.051742Z","iopub.execute_input":"2022-02-24T18:45:47.052177Z","iopub.status.idle":"2022-02-24T18:45:47.056684Z","shell.execute_reply.started":"2022-02-24T18:45:47.05214Z","shell.execute_reply":"2022-02-24T18:45:47.055575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### import libs\n","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport tensorflow as tf\nimport tensorflow.keras as k\n\nimport csv\nimport cv2\nimport os\n\nfrom tensorflow.keras.layers import Input, Lambda, Dense, Flatten\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.applications.densenet import DenseNet201\nfrom tensorflow.keras.applications.mobilenet import MobileNet\nfrom tensorflow.keras.applications import VGG16,VGG19\nfrom tensorflow.keras.applications.densenet import preprocess_input\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow import keras\n\n\nfrom sklearn.utils import shuffle\nfrom sklearn.preprocessing import LabelEncoder , OneHotEncoder\nfrom sklearn.model_selection import train_test_split\n\nfrom scipy import ndimage","metadata":{"execution":{"iopub.status.busy":"2022-02-25T18:57:00.718100Z","iopub.execute_input":"2022-02-25T18:57:00.718527Z","iopub.status.idle":"2022-02-25T18:57:08.950117Z","shell.execute_reply.started":"2022-02-25T18:57:00.718421Z","shell.execute_reply":"2022-02-25T18:57:08.949074Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"\nimg = cv2.imread('../input/emotion-detection-fer/train/angry/im1003.png')\n\ngray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n\nfloat_gray = img.astype(np.float32)/255\n\nblur = cv2.GaussianBlur(float_gray, (0, 0), sigmaX=2, sigmaY=2)\nnum = float_gray - blur\n\nblur = cv2.GaussianBlur(num*num, (0, 0), sigmaX=20, sigmaY=20)\nden = cv2.pow(blur, 0.25)\n\ngray = num / den\n\n# cv2.normalize(gray, dst=gray, alpha=0.0, beta=1.0, norm_type=cv2.NORM_MINMAX)\ngray = cv2.resize(gray,(48,48))\n\nplt.imshow(gray)\nprint(gray.shape)\n","metadata":{"execution":{"iopub.status.busy":"2022-02-25T18:51:08.859690Z","iopub.execute_input":"2022-02-25T18:51:08.860038Z","iopub.status.idle":"2022-02-25T18:51:09.105201Z","shell.execute_reply.started":"2022-02-25T18:51:08.859996Z","shell.execute_reply":"2022-02-25T18:51:09.104277Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"original_img =cv2.imread(\"../input/emotion-detection-fer/train/angry/im1003.png\")\noriginal_img = cv2.resize(original_img,(128,128))\nplt.imshow(original_img)\n","metadata":{"execution":{"iopub.status.busy":"2022-02-25T18:51:09.106391Z","iopub.execute_input":"2022-02-25T18:51:09.107061Z","iopub.status.idle":"2022-02-25T18:51:09.330350Z","shell.execute_reply.started":"2022-02-25T18:51:09.107024Z","shell.execute_reply":"2022-02-25T18:51:09.329516Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"imagetype= os.listdir(\"../input/emotion-detection-fer/train\")\nprint(imagetype)","metadata":{"execution":{"iopub.status.busy":"2022-02-25T18:51:09.332337Z","iopub.execute_input":"2022-02-25T18:51:09.332652Z","iopub.status.idle":"2022-02-25T18:51:09.343784Z","shell.execute_reply.started":"2022-02-25T18:51:09.332618Z","shell.execute_reply":"2022-02-25T18:51:09.342583Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import numpy\nimport scipy\nimport scipy.misc\nfrom PIL import Image\n\n\n\ndef global_contrast_normalization(filename, s, lmda, epsilon):\n    X = cv2.imread(filename)\n    \n    # replacement for the loop\n    X_average = numpy.mean(X)\n    print('Mean: ', X_average)\n    X = X - X_average\n\n    # `su` is here the mean, instead of the sum\n    contrast = numpy.sqrt(lmda + numpy.mean(X**2))\n\n    X = s * X / max(contrast, epsilon)\n    plt.imshow(X*255)\n    # scipy can handle it\n    X= numpy.array(X)\n    print(X.shape)\n\nglobal_contrast_normalization(\"../input/emotion-detection-fer/train/angry/im1003.png\", 1, 10, 0.000000001)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-02-25T18:51:09.345117Z","iopub.execute_input":"2022-02-25T18:51:09.345414Z","iopub.status.idle":"2022-02-25T18:51:09.535306Z","shell.execute_reply.started":"2022-02-25T18:51:09.345373Z","shell.execute_reply":"2022-02-25T18:51:09.534489Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"images = []    #images list will store all images\npath = \"../input/emotion-detection-fer/train\"\nlabels= []","metadata":{"execution":{"iopub.status.busy":"2022-02-25T18:53:33.973627Z","iopub.execute_input":"2022-02-25T18:53:33.973943Z","iopub.status.idle":"2022-02-25T18:53:33.985823Z","shell.execute_reply.started":"2022-02-25T18:53:33.973905Z","shell.execute_reply":"2022-02-25T18:53:33.984877Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"for i in imagetype:\n    print(i)\n    flower_path=path+\"/\"+str(i)\n    data_list=[j for j in os.listdir(flower_path) if j.endswith(\".png\") ]\n    counter=0\n    for data in data_list:\n        if counter> 2390: break\n        img=cv2.imread(flower_path + '/'+ data)\n        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n#         images.append(img)\n#         labels.append(i)\n        float_gray = img.astype(np.float32)/255\n\n        blur = cv2.GaussianBlur(float_gray, (0, 0), sigmaX=2, sigmaY=2)\n        num = float_gray - blur\n\n        blur = cv2.GaussianBlur(num*num, (0, 0), sigmaX=20, sigmaY=20)\n        den = cv2.pow(blur, 0.25)\n\n        gray = num / den\n\n#         invert = cv2.bitwise_not(image)\n#         blur = cv2.GaussianBlur(invert , (13,13), 0)\n#         inverterblur = cv2.bitwise_not(blur)\n#         sketch = cv2.divide(image , inverterblur , scale=256.0)\n#         image=cv2.resize(image,(48,48)) #resize the imag\n#         img = cv2.Canny(image,100,200)\n\n        images.append(gray)\n        labels.append(i)\n        counter = counter+1\n    \nprint(\"total images:\",len(images))\nprint(\"total images:\",len(labels))","metadata":{"execution":{"iopub.status.busy":"2022-02-25T18:53:34.200669Z","iopub.execute_input":"2022-02-25T18:53:34.201534Z","iopub.status.idle":"2022-02-25T18:54:11.651568Z","shell.execute_reply.started":"2022-02-25T18:53:34.201475Z","shell.execute_reply":"2022-02-25T18:54:11.650923Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"encode= LabelEncoder()\nlabels=encode.fit_transform(labels)\nlabels","metadata":{"execution":{"iopub.status.busy":"2022-02-25T18:54:15.150004Z","iopub.execute_input":"2022-02-25T18:54:15.150441Z","iopub.status.idle":"2022-02-25T18:54:15.162631Z","shell.execute_reply.started":"2022-02-25T18:54:15.150410Z","shell.execute_reply":"2022-02-25T18:54:15.161597Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"labels=labels.reshape(-1,1)\nonehotencoder= OneHotEncoder()\nlabels=onehotencoder.fit_transform(labels)\nlabels=labels.toarray()\nlabels","metadata":{"execution":{"iopub.status.busy":"2022-02-25T18:54:15.330409Z","iopub.execute_input":"2022-02-25T18:54:15.330686Z","iopub.status.idle":"2022-02-25T18:54:15.342382Z","shell.execute_reply.started":"2022-02-25T18:54:15.330658Z","shell.execute_reply":"2022-02-25T18:54:15.341334Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"type(images)","metadata":{"execution":{"iopub.status.busy":"2022-02-25T18:54:15.505380Z","iopub.execute_input":"2022-02-25T18:54:15.506593Z","iopub.status.idle":"2022-02-25T18:54:15.513686Z","shell.execute_reply.started":"2022-02-25T18:54:15.506535Z","shell.execute_reply":"2022-02-25T18:54:15.512791Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"images=np.array(images)\nprint(images.shape)\nprint(labels.shape)","metadata":{"execution":{"iopub.status.busy":"2022-02-25T18:54:15.658933Z","iopub.execute_input":"2022-02-25T18:54:15.659222Z","iopub.status.idle":"2022-02-25T18:54:15.842595Z","shell.execute_reply.started":"2022-02-25T18:54:15.659191Z","shell.execute_reply":"2022-02-25T18:54:15.841692Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"images,labels = shuffle(images, labels, random_state=1)\n","metadata":{"execution":{"iopub.status.busy":"2022-02-25T18:54:15.844015Z","iopub.execute_input":"2022-02-25T18:54:15.844660Z","iopub.status.idle":"2022-02-25T18:54:16.013825Z","shell.execute_reply.started":"2022-02-25T18:54:15.844621Z","shell.execute_reply":"2022-02-25T18:54:16.013118Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"x_train , x_test , y_train , y_test = train_test_split(images, labels, test_size=0.1 , random_state=415)\n\nprint(x_train.shape)\nprint(x_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2022-02-25T18:54:16.015262Z","iopub.execute_input":"2022-02-25T18:54:16.015674Z","iopub.status.idle":"2022-02-25T18:54:16.147608Z","shell.execute_reply.started":"2022-02-25T18:54:16.015626Z","shell.execute_reply":"2022-02-25T18:54:16.146710Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"plt.imshow(images[6])\nplt.xlabel(labels[6])","metadata":{"execution":{"iopub.status.busy":"2022-02-25T18:54:20.653526Z","iopub.execute_input":"2022-02-25T18:54:20.653880Z","iopub.status.idle":"2022-02-25T18:54:20.857829Z","shell.execute_reply.started":"2022-02-25T18:54:20.653846Z","shell.execute_reply":"2022-02-25T18:54:20.856907Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"DenseNet201 = DenseNet201(input_shape= (48,48,3) ,  include_top=False , weights=\"imagenet\", pooling='max')\n","metadata":{"execution":{"iopub.status.busy":"2022-02-25T18:53:08.077544Z","iopub.status.idle":"2022-02-25T18:53:08.078321Z","shell.execute_reply.started":"2022-02-25T18:53:08.078137Z","shell.execute_reply":"2022-02-25T18:53:08.078158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DenseNet201.trainable = False","metadata":{"execution":{"iopub.status.busy":"2022-02-24T18:00:02.34982Z","iopub.execute_input":"2022-02-24T18:00:02.350106Z","iopub.status.idle":"2022-02-24T18:00:02.385602Z","shell.execute_reply.started":"2022-02-24T18:00:02.350066Z","shell.execute_reply":"2022-02-24T18:00:02.384758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = Flatten()(DenseNet201.output)\n","metadata":{"execution":{"iopub.status.busy":"2022-02-24T18:00:02.665833Z","iopub.execute_input":"2022-02-24T18:00:02.666365Z","iopub.status.idle":"2022-02-24T18:00:02.677898Z","shell.execute_reply.started":"2022-02-24T18:00:02.666293Z","shell.execute_reply":"2022-02-24T18:00:02.676842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow import keras\n\nprediction = Dense(7, activation='softmax')(x)\n\n# create a model object\nmodel = Model(inputs=DenseNet201.input, outputs=prediction)\nopt = keras.optimizers.Adam(learning_rate=0.1)\n","metadata":{"execution":{"iopub.status.busy":"2022-02-24T18:00:27.739469Z","iopub.execute_input":"2022-02-24T18:00:27.73978Z","iopub.status.idle":"2022-02-24T18:00:27.806983Z","shell.execute_reply.started":"2022-02-24T18:00:27.739746Z","shell.execute_reply":"2022-02-24T18:00:27.806097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(\n  loss='categorical_crossentropy',\n  optimizer=opt,\n  metrics=['accuracy']\n)\n","metadata":{"execution":{"iopub.status.busy":"2022-02-24T18:00:27.911057Z","iopub.execute_input":"2022-02-24T18:00:27.911378Z","iopub.status.idle":"2022-02-24T18:00:27.933626Z","shell.execute_reply.started":"2022-02-24T18:00:27.911315Z","shell.execute_reply":"2022-02-24T18:00:27.932849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"r = model.fit(x_train , y_train , batch_size=16 , epochs=10 , validation_data = (x_test , y_test))","metadata":{"execution":{"iopub.status.busy":"2022-02-24T18:00:28.057596Z","iopub.execute_input":"2022-02-24T18:00:28.058204Z","iopub.status.idle":"2022-02-24T18:23:38.673721Z","shell.execute_reply.started":"2022-02-24T18:00:28.058156Z","shell.execute_reply":"2022-02-24T18:23:38.672623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(r.history['loss'], label='train loss')\nplt.plot(r.history['val_loss'], label='val loss')\nplt.legend()\nplt.show()\n# plt.savefig('LossVal_loss_DenseNet201')\n\n# plot the accuracy\nplt.plot(r.history['accuracy'], label='train acc')\nplt.plot(r.history['val_accuracy'], label='val acc')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-24T07:08:12.63585Z","iopub.execute_input":"2022-02-24T07:08:12.636197Z","iopub.status.idle":"2022-02-24T07:08:13.052911Z","shell.execute_reply.started":"2022-02-24T07:08:12.636161Z","shell.execute_reply":"2022-02-24T07:08:13.05206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(\n  loss='binary_crossentropy',\n  optimizer='adam',\n  metrics=['accuracy']\n)","metadata":{"execution":{"iopub.status.busy":"2022-02-24T07:08:15.746086Z","iopub.execute_input":"2022-02-24T07:08:15.746655Z","iopub.status.idle":"2022-02-24T07:08:15.765226Z","shell.execute_reply.started":"2022-02-24T07:08:15.74662Z","shell.execute_reply":"2022-02-24T07:08:15.764513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"r = model.fit(x_train , y_train , batch_size=16 , epochs=20 , validation_data = (x_test , y_test))","metadata":{"execution":{"iopub.status.busy":"2022-02-24T07:08:15.766687Z","iopub.execute_input":"2022-02-24T07:08:15.767496Z","iopub.status.idle":"2022-02-24T07:26:44.242385Z","shell.execute_reply.started":"2022-02-24T07:08:15.767457Z","shell.execute_reply":"2022-02-24T07:26:44.240238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"r = model.fit(x_train , y_train , batch_size=64 , epochs=10 , validation_data = (x_test , y_test))","metadata":{"execution":{"iopub.status.busy":"2022-02-24T07:26:50.557013Z","iopub.execute_input":"2022-02-24T07:26:50.557292Z","iopub.status.idle":"2022-02-24T07:27:01.150241Z","shell.execute_reply.started":"2022-02-24T07:26:50.557262Z","shell.execute_reply":"2022-02-24T07:27:01.148909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mobile = MobileNet(input_shape= (48,48,3) , dropout = 0.01 ,  include_top=False , weights=\"imagenet\", pooling='max')","metadata":{"execution":{"iopub.status.busy":"2022-02-24T19:00:57.561063Z","iopub.execute_input":"2022-02-24T19:00:57.561319Z","iopub.status.idle":"2022-02-24T19:01:00.613944Z","shell.execute_reply.started":"2022-02-24T19:00:57.561291Z","shell.execute_reply":"2022-02-24T19:01:00.613215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mobile.trainable = False","metadata":{"execution":{"iopub.status.busy":"2022-02-24T19:01:00.617017Z","iopub.execute_input":"2022-02-24T19:01:00.617214Z","iopub.status.idle":"2022-02-24T19:01:00.624772Z","shell.execute_reply.started":"2022-02-24T19:01:00.61719Z","shell.execute_reply":"2022-02-24T19:01:00.623525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = Flatten()(mobile.output)","metadata":{"execution":{"iopub.status.busy":"2022-02-24T19:01:00.625699Z","iopub.execute_input":"2022-02-24T19:01:00.626418Z","iopub.status.idle":"2022-02-24T19:01:00.636936Z","shell.execute_reply.started":"2022-02-24T19:01:00.62638Z","shell.execute_reply":"2022-02-24T19:01:00.636254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction = Dense(7, activation='softmax')(x)\n\n# create a model object\nmobile = Model(inputs=mobile.input, outputs=prediction)","metadata":{"execution":{"iopub.status.busy":"2022-02-24T19:01:17.260364Z","iopub.execute_input":"2022-02-24T19:01:17.26086Z","iopub.status.idle":"2022-02-24T19:01:17.449718Z","shell.execute_reply.started":"2022-02-24T19:01:17.260813Z","shell.execute_reply":"2022-02-24T19:01:17.448985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mobile.compile(\n  loss='binary_crossentropy',\n  optimizer='adam',\n  metrics=['accuracy']\n)","metadata":{"execution":{"iopub.status.busy":"2022-02-24T19:01:17.525037Z","iopub.execute_input":"2022-02-24T19:01:17.52524Z","iopub.status.idle":"2022-02-24T19:01:17.537127Z","shell.execute_reply.started":"2022-02-24T19:01:17.525216Z","shell.execute_reply":"2022-02-24T19:01:17.536342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"r = mobile.fit(x_train , y_train , batch_size=16 , epochs=40 , validation_data = (x_test , y_test))","metadata":{"execution":{"iopub.status.busy":"2022-02-24T19:01:17.758386Z","iopub.execute_input":"2022-02-24T19:01:17.758872Z","iopub.status.idle":"2022-02-24T19:03:25.895963Z","shell.execute_reply.started":"2022-02-24T19:01:17.758819Z","shell.execute_reply":"2022-02-24T19:03:25.893866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(r.history['loss'], label='train loss')\nplt.plot(r.history['val_loss'], label='val loss')\nplt.legend()\nplt.show()\n# plt.savefig('LossVal_loss_DenseNet201')\n\n# plot the accuracy\nplt.plot(r.history['accuracy'], label='train acc')\nplt.plot(r.history['val_accuracy'], label='val acc')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-24T19:03:25.896681Z","iopub.status.idle":"2022-02-24T19:03:25.896962Z","shell.execute_reply.started":"2022-02-24T19:03:25.896811Z","shell.execute_reply":"2022-02-24T19:03:25.896834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"r = model.fit(x_train , y_train , batch_size=32 , epochs=10 , validation_data = (x_test , y_test))","metadata":{"execution":{"iopub.status.busy":"2022-02-24T07:45:28.086724Z","iopub.execute_input":"2022-02-24T07:45:28.087602Z","iopub.status.idle":"2022-02-24T07:46:06.593453Z","shell.execute_reply.started":"2022-02-24T07:45:28.087544Z","shell.execute_reply":"2022-02-24T07:46:06.592254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(r.history['loss'], label='train loss')\nplt.plot(r.history['val_loss'], label='val loss')\nplt.legend()\nplt.show()\n# plt.savefig('LossVal_loss_DenseNet201')\n\n# plot the accuracy\nplt.plot(r.history['accuracy'], label='train acc')\nplt.plot(r.history['val_accuracy'], label='val acc')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-24T07:45:20.331149Z","iopub.status.idle":"2022-02-24T07:45:20.33163Z","shell.execute_reply.started":"2022-02-24T07:45:20.331382Z","shell.execute_reply":"2022-02-24T07:45:20.331408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### canny edge detection\n1. Noise reduction;\n2. Gradient calculation;\n3. Non-maximum suppression;\n4. Double threshold;\n5. Edge Tracking by Hysteresis.","metadata":{}},{"cell_type":"code","source":"from scipy.ndimage.filters import convolve\n\nimgs_final = []\nimg_smoothed = convolve(image, gaussian_kernel(2304, 1))\ngradientMat, thetaMat = sobel_filters(img_smoothed)\nnonMaxImg = non_max_suppression(gradientMat, thetaMat)\nthresholdImg = threshold(nonMaxImg)\nimg_final = hysteresis(thresholdImg)\nimgs_final.append(img_final)","metadata":{"execution":{"iopub.status.busy":"2022-02-23T19:10:57.403499Z","iopub.execute_input":"2022-02-23T19:10:57.40382Z","iopub.status.idle":"2022-02-23T19:10:57.668502Z","shell.execute_reply.started":"2022-02-23T19:10:57.403782Z","shell.execute_reply":"2022-02-23T19:10:57.667297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Noise reduction:","metadata":{}},{"cell_type":"code","source":"def gaussian_kernel(size, sigma=1):\n    size = int(size) // 2\n    x, y = np.mgrid[-size:size+1, -size:size+1]\n    normal = 1 / (2.0 * np.pi * sigma**2)\n    g =  np.exp(-((x**2 + y**2) / (2.0*sigma**2))) * normal\n    return g","metadata":{"execution":{"iopub.status.busy":"2022-02-23T19:03:57.999449Z","iopub.execute_input":"2022-02-23T19:03:57.999996Z","iopub.status.idle":"2022-02-23T19:03:58.005835Z","shell.execute_reply.started":"2022-02-23T19:03:57.99996Z","shell.execute_reply":"2022-02-23T19:03:58.005169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image=cv2.imread(\"../input/emotion-detection-fer/train/happy/im0.png\")\nedges = cv2.Canny(image,1,150)\nplt.subplot(121),plt.imshow(image,cmap = 'gray')\nplt.title('Original Image'), plt.xticks([]), plt.yticks([])\nplt.subplot(122),plt.imshow(edges,cmap = 'gray')\nplt.title('Edge Image'), plt.xticks([]), plt.yticks([])","metadata":{"execution":{"iopub.status.busy":"2022-02-23T20:50:58.480661Z","iopub.execute_input":"2022-02-23T20:50:58.481401Z","iopub.status.idle":"2022-02-23T20:50:58.560918Z","shell.execute_reply.started":"2022-02-23T20:50:58.481289Z","shell.execute_reply":"2022-02-23T20:50:58.559879Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plt.imshow(imagess)\nimport cv2\nimport matplotlib.pyplot as plt\n\nimage=cv2.imread(\"../input/emotion-detection-fer/train/disgusted/im118.png\")\n# image = cv2.cvtColor(image , cv2.COLOR_BGR2GRAY)\ninvert = cv2.bitwise_not(image)\nblur = cv2.GaussianBlur(invert , (13,13), 0)\ninverterblur = cv2.bitwise_not(blur)\nsketch = cv2.divide(image , inverterblur , scale=256.0)\n\nplt.imshow(sketch)\n","metadata":{"execution":{"iopub.status.busy":"2022-02-23T22:28:35.204265Z","iopub.execute_input":"2022-02-23T22:28:35.204775Z","iopub.status.idle":"2022-02-23T22:28:35.407003Z","shell.execute_reply.started":"2022-02-23T22:28:35.204743Z","shell.execute_reply":"2022-02-23T22:28:35.406421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(image)\n","metadata":{"execution":{"iopub.status.busy":"2022-02-23T22:29:03.029778Z","iopub.execute_input":"2022-02-23T22:29:03.030444Z","iopub.status.idle":"2022-02-23T22:29:03.225183Z","shell.execute_reply.started":"2022-02-23T22:29:03.030409Z","shell.execute_reply":"2022-02-23T22:29:03.224305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimagesnp=np.array(sketch)\nimagesnp.shape","metadata":{"execution":{"iopub.status.busy":"2022-02-23T22:27:23.109032Z","iopub.execute_input":"2022-02-23T22:27:23.109534Z","iopub.status.idle":"2022-02-23T22:27:23.117344Z","shell.execute_reply.started":"2022-02-23T22:27:23.109493Z","shell.execute_reply":"2022-02-23T22:27:23.116587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Gradient Calculation\n","metadata":{}},{"cell_type":"code","source":"from scipy import ndimage\n\ndef sobel_filters(img):\n    Kx = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], np.float32)\n    Ky = np.array([[1, 2, 1], [0, 0, 0], [-1, -2, -1]], np.float32)\n    \n    Ix = ndimage.filters.convolve(img, Kx)\n    Iy = ndimage.filters.convolve(img, Ky)\n    \n    G = np.hypot(Ix, Iy)\n    G = G / G.max() * 255\n    theta = np.arctan2(Iy, Ix)\n    \n    return (G, theta)","metadata":{"execution":{"iopub.status.busy":"2022-02-23T19:04:01.102389Z","iopub.execute_input":"2022-02-23T19:04:01.102813Z","iopub.status.idle":"2022-02-23T19:04:01.111207Z","shell.execute_reply.started":"2022-02-23T19:04:01.102778Z","shell.execute_reply":"2022-02-23T19:04:01.110578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Non-Maximum Suppression\n","metadata":{}},{"cell_type":"code","source":"def non_max_suppression(img, D):\n    M, N = img.shape\n    Z = np.zeros((M,N), dtype=np.int32)\n    angle = D * 180. / np.pi\n    angle[angle < 0] += 180\n\n    \n    for i in range(1,M-1):\n        for j in range(1,N-1):\n            try:\n                q = 255\n                r = 255\n                \n               #angle 0\n                if (0 <= angle[i,j] < 22.5) or (157.5 <= angle[i,j] <= 180):\n                    q = img[i, j+1]\n                    r = img[i, j-1]\n                #angle 45\n                elif (22.5 <= angle[i,j] < 67.5):\n                    q = img[i+1, j-1]\n                    r = img[i-1, j+1]\n                #angle 90\n                elif (67.5 <= angle[i,j] < 112.5):\n                    q = img[i+1, j]\n                    r = img[i-1, j]\n                #angle 135\n                elif (112.5 <= angle[i,j] < 157.5):\n                    q = img[i-1, j-1]\n                    r = img[i+1, j+1]\n\n                if (img[i,j] >= q) and (img[i,j] >= r):\n                    Z[i,j] = img[i,j]\n                else:\n                    Z[i,j] = 0\n\n            except IndexError as e:\n                pass\n    \n    return Z\n","metadata":{"execution":{"iopub.status.busy":"2022-02-23T19:04:01.15693Z","iopub.status.idle":"2022-02-23T19:04:01.157704Z","shell.execute_reply.started":"2022-02-23T19:04:01.157475Z","shell.execute_reply":"2022-02-23T19:04:01.157504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Double threshold\n","metadata":{}},{"cell_type":"code","source":"def threshold(img, lowThresholdRatio=0.05, highThresholdRatio=0.09):\n    \n    highThreshold = img.max() * highThresholdRatio;\n    lowThreshold = highThreshold * lowThresholdRatio;\n    \n    M, N = img.shape\n    res = np.zeros((M,N), dtype=np.int32)\n    \n    weak = np.int32(25)\n    strong = np.int32(255)\n    \n    strong_i, strong_j = np.where(img >= highThreshold)\n    zeros_i, zeros_j = np.where(img < lowThreshold)\n    \n    weak_i, weak_j = np.where((img <= highThreshold) & (img >= lowThreshold))\n    \n    res[strong_i, strong_j] = strong\n    res[weak_i, weak_j] = weak\n    \n    return (res, weak, strong)","metadata":{"execution":{"iopub.status.busy":"2022-02-23T19:04:01.158716Z","iopub.status.idle":"2022-02-23T19:04:01.159578Z","shell.execute_reply.started":"2022-02-23T19:04:01.15932Z","shell.execute_reply":"2022-02-23T19:04:01.15935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Edge Tracking by Hysteresis\n","metadata":{}},{"cell_type":"code","source":"def hysteresis(img, weak=75, strong=255):\n    M, N = img.shape  \n    for i in range(1, M-1):\n        for j in range(1, N-1):\n            if (img[i,j] == weak):\n                try:\n                    if ((img[i+1, j-1] == strong) or (img[i+1, j] == strong) or (img[i+1, j+1] == strong)\n                        or (img[i, j-1] == strong) or (img[i, j+1] == strong)\n                        or (img[i-1, j-1] == strong) or (img[i-1, j] == strong) or (img[i-1, j+1] == strong)):\n                        img[i, j] = strong\n                    else:\n                        img[i, j] = 0\n                except IndexError as e:\n                    pass\n    return img","metadata":{"execution":{"iopub.status.busy":"2022-02-23T19:04:01.377342Z","iopub.execute_input":"2022-02-23T19:04:01.378248Z","iopub.status.idle":"2022-02-23T19:04:01.390578Z","shell.execute_reply.started":"2022-02-23T19:04:01.378198Z","shell.execute_reply":"2022-02-23T19:04:01.389771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nsrc = cv2.imread(\"../input/emotion-detection-fer/train/angry/im1008.png\")\nsrc = cv2.GaussianBlur(src, (11, 21),0)\n# src_gray = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)\ndst = cv2.Laplacian(src_gray, cv2.CV_8, ksize=5)","metadata":{"execution":{"iopub.status.busy":"2022-02-24T12:46:15.654484Z","iopub.execute_input":"2022-02-24T12:46:15.654842Z","iopub.status.idle":"2022-02-24T12:46:15.69995Z","shell.execute_reply.started":"2022-02-24T12:46:15.654807Z","shell.execute_reply":"2022-02-24T12:46:15.698699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(dst)\ndst=np.array(dst)","metadata":{"execution":{"iopub.status.busy":"2022-02-24T12:43:27.680163Z","iopub.execute_input":"2022-02-24T12:43:27.680514Z","iopub.status.idle":"2022-02-24T12:43:27.894073Z","shell.execute_reply.started":"2022-02-24T12:43:27.680479Z","shell.execute_reply":"2022-02-24T12:43:27.893016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dst.shape","metadata":{"execution":{"iopub.status.busy":"2022-02-24T12:42:04.164744Z","iopub.execute_input":"2022-02-24T12:42:04.165745Z","iopub.status.idle":"2022-02-24T12:42:04.172406Z","shell.execute_reply.started":"2022-02-24T12:42:04.165704Z","shell.execute_reply":"2022-02-24T12:42:04.171117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vgg16 = VGG16(input_shape= (48,48,3) , include_top=False , weights=\"imagenet\", pooling='max')\n","metadata":{"execution":{"iopub.status.busy":"2022-02-24T19:03:25.898422Z","iopub.status.idle":"2022-02-24T19:03:25.899235Z","shell.execute_reply.started":"2022-02-24T19:03:25.898987Z","shell.execute_reply":"2022-02-24T19:03:25.899013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vgg16.trainable = False","metadata":{"execution":{"iopub.status.busy":"2022-02-24T19:03:25.900285Z","iopub.status.idle":"2022-02-24T19:03:25.901066Z","shell.execute_reply.started":"2022-02-24T19:03:25.900821Z","shell.execute_reply":"2022-02-24T19:03:25.900859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = Flatten()(vgg16.output)","metadata":{"execution":{"iopub.status.busy":"2022-02-24T19:03:25.902222Z","iopub.status.idle":"2022-02-24T19:03:25.903033Z","shell.execute_reply.started":"2022-02-24T19:03:25.902766Z","shell.execute_reply":"2022-02-24T19:03:25.902791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction = Dense(7, activation='softmax')(x)\n\n# create a model object\nvgg16 = Model(inputs=vgg16.input, outputs=prediction)","metadata":{"execution":{"iopub.status.busy":"2022-02-24T19:03:25.904192Z","iopub.status.idle":"2022-02-24T19:03:25.904971Z","shell.execute_reply.started":"2022-02-24T19:03:25.904723Z","shell.execute_reply":"2022-02-24T19:03:25.904753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vgg16.compile(\n  loss='binary_crossentropy',\n  optimizer='adam',\n  metrics=['accuracy']\n)","metadata":{"execution":{"iopub.status.busy":"2022-02-24T19:03:25.906083Z","iopub.status.idle":"2022-02-24T19:03:25.906859Z","shell.execute_reply.started":"2022-02-24T19:03:25.906613Z","shell.execute_reply":"2022-02-24T19:03:25.90664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"r = vgg16.fit(x_train , y_train , batch_size=16 , epochs=40 , validation_data = (x_test , y_test))","metadata":{"execution":{"iopub.status.busy":"2022-02-24T19:03:25.908012Z","iopub.status.idle":"2022-02-24T19:03:25.908876Z","shell.execute_reply.started":"2022-02-24T19:03:25.908599Z","shell.execute_reply":"2022-02-24T19:03:25.908627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.layers import Activation, Conv2D, MaxPooling2D, Dense, Flatten, Dropout, BatchNormalization\nmodel = tf.keras.Sequential()\n\nmodel.add(Conv2D(16,(3,3),padding='same',kernel_initializer='he_normal',input_shape=(48,48,3)))\nmodel.add(Activation('relu'))\n# model.add(BatchNormalization())\n# model.add(Conv2D(32,(3,3),padding='same',kernel_initializer='he_normal',input_shape=(48,48,3)))\n# model.add(Activation('relu'))\n# model.add(BatchNormalization())\n# model.add(Conv2D(32,(3,3),padding='same',kernel_initializer='he_normal',input_shape=(48,48,3)))\n# model.add(Activation('relu'))\n# model.add(BatchNormalization())\n# model.add(Conv2D(32,(3,3),padding='same',kernel_initializer='he_normal',input_shape=(48,48,3)))\n# model.add(Activation('relu'))\n# model.add(BatchNormalization())\n# model.add(Conv2D(32,(3,3),padding='same',kernel_initializer='he_normal',input_shape=(48,48,3)))\n# model.add(Activation('relu'))\n# model.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.01))\n\n\nmodel.add(Conv2D(32,(3,3),padding='same',kernel_initializer='he_normal'))\n# model.add(Activation('relu'))\n# model.add(BatchNormalization())\n# model.add(Conv2D(64,(3,3),padding='same',kernel_initializer='he_normal'))\n# model.add(Activation('relu'))\n# model.add(BatchNormalization())\n# model.add(MaxPooling2D(pool_size=(2,2)))\n# model.add(Dropout(0.2))\n\n\nmodel.add(Conv2D(32,(3,3),padding='same',kernel_initializer='he_normal'))\nmodel.add(Activation('relu'))\n# model.add(BatchNormalization())\nmodel.add(Conv2D(32,(3,3),padding='same',kernel_initializer='he_normal'))\nmodel.add(Activation('relu'))\n# model.add(BatchNormalization())\n# model.add(Conv2D(32,(3,3),padding='same',kernel_initializer='he_normal'))\n# model.add(Activation('relu'))\n# model.add(BatchNormalization())\n# model.add(Conv2D(32,(3,3),padding='same',kernel_initializer='he_normal'))\n# model.add(Activation('relu'))\n# model.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.01))\n\n# # model.add(Conv2D(128,(3,3),padding='same',kernel_initializer='he_normal'))\n# # model.add(Activation('relu'))\n# # model.add(BatchNormalization())\n# # model.add(Conv2D(128,(3,3),padding='same',kernel_initializer='he_normal'))\n# # model.add(Activation('relu'))\n# # model.add(BatchNormalization())\n# # model.add(MaxPooling2D(pool_size=(2,2)))\n# # model.add(Dropout(0.2))\n\n\n# # model.add(Conv2D(256,(3,3),padding='same',kernel_initializer='he_normal'))\n# # model.add(Activation('relu'))\n# # model.add(BatchNormalization())\n# # model.add(Conv2D(256,(3,3),padding='same',kernel_initializer='he_normal'))\n# # model.add(Activation('relu'))\n# # model.add(BatchNormalization())\n# # model.add(MaxPooling2D(pool_size=(2,2)))\n# # model.add(Dropout(0.2))\n\n\n# model.add(Flatten())\n# model.add(Dense(64,kernel_initializer='he_normal'))\n# model.add(Activation('relu'))\n# model.add(BatchNormalization())\n# model.add(Dropout(0.5))\n\n\n# model.add(Dense(64,kernel_initializer='he_normal'))\n# model.add(Activation('relu'))\n# model.add(BatchNormalization())\n# model.add(Dropout(0.5))\n\n\nmodel.add(Dense(7,kernel_initializer='he_normal'))\nmodel.add(Activation('softmax'))\n\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = tf.keras.models.Sequential([\n    # Note the input shape is the desired size of the image 300x300 with 3 bytes color\n    # This is the first convolution\n    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(48, 48, 3)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    # The second convolution\n    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    # The third convolution\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    # The fourth convolution\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    # The fifth convolution\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    # Flatten the results to feed into a DNN\n    tf.keras.layers.Flatten(),\n    # 512 neuron hidden layer\n    tf.keras.layers.Dense(512, activation='relu'),\n    # Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class ('horses') and 1 for the other ('humans')\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])","metadata":{"execution":{"iopub.status.busy":"2022-02-25T18:57:10.587060Z","iopub.execute_input":"2022-02-25T18:57:10.587509Z","iopub.status.idle":"2022-02-25T18:57:11.175866Z","shell.execute_reply.started":"2022-02-25T18:57:10.587464Z","shell.execute_reply":"2022-02-25T18:57:11.174406Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-02-25T18:55:02.482586Z","iopub.execute_input":"2022-02-25T18:55:02.482884Z","iopub.status.idle":"2022-02-25T18:55:02.493048Z","shell.execute_reply.started":"2022-02-25T18:55:02.482855Z","shell.execute_reply":"2022-02-25T18:55:02.492022Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.optimizers import RMSprop\n \nmodel.compile(loss='binary_crossentropy', optimizer=RMSprop(lr=0.001), metrics=['acc'])\n# model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.3),loss='categorical_crossentropy',metrics=['accuracy'])\n","metadata":{"execution":{"iopub.status.busy":"2022-02-25T18:55:44.334902Z","iopub.execute_input":"2022-02-25T18:55:44.335167Z","iopub.status.idle":"2022-02-25T18:55:44.353334Z","shell.execute_reply.started":"2022-02-25T18:55:44.335139Z","shell.execute_reply":"2022-02-25T18:55:44.352775Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"history = model.fit(x_train , y_train , batch_size=16 , epochs=50 , validation_data = (x_test , y_test))","metadata":{"execution":{"iopub.status.busy":"2022-02-24T19:03:34.578651Z","iopub.execute_input":"2022-02-24T19:03:34.578978Z","iopub.status.idle":"2022-02-24T19:06:16.965468Z","shell.execute_reply.started":"2022-02-24T19:03:34.578908Z","shell.execute_reply":"2022-02-24T19:06:16.964288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['loss'], label='train loss')\nplt.plot(history.history['val_loss'], label='val loss')\nplt.legend()\nplt.show()\n# plt.savefig('LossVal_loss_DenseNet201')\n\n# plot the accuracy\nplt.plot(r.history['accuracy'], label='train acc')\nplt.plot(r.history['val_accuracy'], label='val acc')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-24T19:06:16.96647Z","iopub.status.idle":"2022-02-24T19:06:16.967346Z","shell.execute_reply.started":"2022-02-24T19:06:16.967088Z","shell.execute_reply":"2022-02-24T19:06:16.967118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}