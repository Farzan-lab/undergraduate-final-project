{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"    # This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"../input/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-24T18:45:47.051742Z","iopub.execute_input":"2022-02-24T18:45:47.052177Z","iopub.status.idle":"2022-02-24T18:45:47.056684Z","shell.execute_reply.started":"2022-02-24T18:45:47.05214Z","shell.execute_reply":"2022-02-24T18:45:47.055575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### import libs\n","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport tensorflow as tf\nimport tensorflow.keras as k\n\nimport csv\nimport cv2\nimport os\n\nfrom tensorflow.keras.layers import Input, Lambda, Dense, Flatten\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.applications.densenet import DenseNet201\nfrom tensorflow.keras.applications.mobilenet import MobileNet\nfrom tensorflow.keras.applications import VGG16,VGG19\nfrom tensorflow.keras.applications.densenet import preprocess_input\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow import keras\n\n\nfrom sklearn.utils import shuffle\nfrom sklearn.preprocessing import LabelEncoder , OneHotEncoder\nfrom sklearn.model_selection import train_test_split\n\nfrom scipy import ndimage","metadata":{"execution":{"iopub.status.busy":"2022-02-26T06:41:47.367997Z","iopub.execute_input":"2022-02-26T06:41:47.368828Z","iopub.status.idle":"2022-02-26T06:41:47.376631Z","shell.execute_reply.started":"2022-02-26T06:41:47.368781Z","shell.execute_reply":"2022-02-26T06:41:47.375722Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"### Local edge","metadata":{}},{"cell_type":"code","source":"\nimg = cv2.imread('../input/emotion-detection-fer/train/angry/im1003.png')\n\ngray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n\nfloat_gray = img.astype(np.float32)/255\n\nblur = cv2.GaussianBlur(float_gray, (0, 0), sigmaX=2, sigmaY=2)\nnum = float_gray - blur\n\nblur = cv2.GaussianBlur(num*num, (0, 0), sigmaX=20, sigmaY=20)\nden = cv2.pow(blur, 0.25)\n\ngray = num / den\n\n# cv2.normalize(gray, dst=gray, alpha=0.0, beta=1.0, norm_type=cv2.NORM_MINMAX)\ngray = cv2.resize(gray,(48,48))\n\nplt.imshow(gray)\nprint(gray.shape)\n","metadata":{"execution":{"iopub.status.busy":"2022-02-26T06:41:48.725630Z","iopub.execute_input":"2022-02-26T06:41:48.726197Z","iopub.status.idle":"2022-02-26T06:41:48.965911Z","shell.execute_reply.started":"2022-02-26T06:41:48.726164Z","shell.execute_reply":"2022-02-26T06:41:48.964735Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"original_img =cv2.imread(\"../input/emotion-detection-fer/train/angry/im1003.png\")\noriginal_img = cv2.resize(original_img,(128,128))\nplt.imshow(original_img)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-02-26T06:41:48.968307Z","iopub.execute_input":"2022-02-26T06:41:48.969064Z","iopub.status.idle":"2022-02-26T06:41:49.273137Z","shell.execute_reply.started":"2022-02-26T06:41:48.969019Z","shell.execute_reply":"2022-02-26T06:41:49.272323Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"imagetype= os.listdir(\"../input/emotion-detection-fer/train\")\nimagetype.remove(\"disgusted\")\nprint(imagetype)\n","metadata":{"execution":{"iopub.status.busy":"2022-02-26T06:41:49.274746Z","iopub.execute_input":"2022-02-26T06:41:49.275233Z","iopub.status.idle":"2022-02-26T06:41:49.283931Z","shell.execute_reply.started":"2022-02-26T06:41:49.275195Z","shell.execute_reply":"2022-02-26T06:41:49.283080Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"import numpy\nimport scipy\nimport scipy.misc\nfrom PIL import Image\n\n\n\ndef global_contrast_normalization(filename, s, lmda, epsilon):\n    X = cv2.imread(filename)\n    \n    # replacement for the loop\n    X_average = numpy.mean(X)\n    print('Mean: ', X_average)\n    X = X - X_average\n\n    # `su` is here the mean, instead of the sum\n    contrast = numpy.sqrt(lmda + numpy.mean(X**2))\n\n    X = s * X / max(contrast, epsilon)\n    plt.imshow(X*255)\n    # scipy can handle it\n    X= numpy.array(X)\n    print(X.shape)\n\nglobal_contrast_normalization(\"../input/emotion-detection-fer/train/angry/im1003.png\", 1, 10, 0.000000001)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-02-26T06:41:51.683744Z","iopub.execute_input":"2022-02-26T06:41:51.683991Z","iopub.status.idle":"2022-02-26T06:41:51.858095Z","shell.execute_reply.started":"2022-02-26T06:41:51.683964Z","shell.execute_reply":"2022-02-26T06:41:51.857397Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"images = []    #images list will store all images\npath = \"../input/emotion-detection-fer/train\"\nlabels= []","metadata":{"execution":{"iopub.status.busy":"2022-02-26T06:41:51.859698Z","iopub.execute_input":"2022-02-26T06:41:51.860358Z","iopub.status.idle":"2022-02-26T06:41:51.865670Z","shell.execute_reply.started":"2022-02-26T06:41:51.860317Z","shell.execute_reply":"2022-02-26T06:41:51.864869Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"### **classes exept disgusted**","metadata":{}},{"cell_type":"code","source":"for i in imagetype:\n    print(i)\n    flower_path=path+\"/\"+str(i)\n    data_list=[j for j in os.listdir(flower_path) if j.endswith(\".png\") ]\n    counter=0\n    for data in data_list:\n#         if counter> 2390: break\n        img=cv2.imread(flower_path + '/'+ data)\n        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n#         images.append(img)\n#         labels.append(i)\n        float_gray = img.astype(np.float32)/255\n\n        blur = cv2.GaussianBlur(float_gray, (0, 0), sigmaX=2, sigmaY=2)\n        num = float_gray - blur\n\n        blur = cv2.GaussianBlur(num*num, (0, 0), sigmaX=20, sigmaY=20)\n        den = cv2.pow(blur, 0.25)\n\n        gray = num / den\n\n#         invert = cv2.bitwise_not(image)\n#         blur = cv2.GaussianBlur(invert , (13,13), 0)\n#         inverterblur = cv2.bitwise_not(blur)\n#         sketch = cv2.divide(image , inverterblur , scale=256.0)\n#         image=cv2.resize(image,(48,48)) #resize the imag\n#         img = cv2.Canny(image,100,200)\n\n        images.append(gray)\n        labels.append(i)\n#         counter = counter+1\n    \nprint(\"total images:\",len(images))\nprint(\"total images:\",len(labels))","metadata":{"execution":{"iopub.status.busy":"2022-02-26T06:41:58.312683Z","iopub.execute_input":"2022-02-26T06:41:58.313211Z","iopub.status.idle":"2022-02-26T06:45:10.530743Z","shell.execute_reply.started":"2022-02-26T06:41:58.313175Z","shell.execute_reply":"2022-02-26T06:45:10.530016Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"encode= LabelEncoder()\nlabels=encode.fit_transform(labels)\nlabels","metadata":{"execution":{"iopub.status.busy":"2022-02-26T06:45:17.625916Z","iopub.execute_input":"2022-02-26T06:45:17.626174Z","iopub.status.idle":"2022-02-26T06:45:17.647364Z","shell.execute_reply.started":"2022-02-26T06:45:17.626145Z","shell.execute_reply":"2022-02-26T06:45:17.646733Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"labels=labels.reshape(-1,1)\nonehotencoder= OneHotEncoder()\nlabels=onehotencoder.fit_transform(labels)\nlabels=labels.toarray()\nlabels","metadata":{"execution":{"iopub.status.busy":"2022-02-26T06:45:17.838076Z","iopub.execute_input":"2022-02-26T06:45:17.838359Z","iopub.status.idle":"2022-02-26T06:45:17.857719Z","shell.execute_reply.started":"2022-02-26T06:45:17.838327Z","shell.execute_reply":"2022-02-26T06:45:17.856955Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"type(images)","metadata":{"execution":{"iopub.status.busy":"2022-02-26T06:45:18.822189Z","iopub.execute_input":"2022-02-26T06:45:18.822434Z","iopub.status.idle":"2022-02-26T06:45:18.827331Z","shell.execute_reply.started":"2022-02-26T06:45:18.822406Z","shell.execute_reply":"2022-02-26T06:45:18.826529Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"images=np.array(images)\nprint(images.shape)\nprint(labels.shape)","metadata":{"execution":{"iopub.status.busy":"2022-02-26T06:45:18.965844Z","iopub.execute_input":"2022-02-26T06:45:18.966545Z","iopub.status.idle":"2022-02-26T06:45:19.222856Z","shell.execute_reply.started":"2022-02-26T06:45:18.966495Z","shell.execute_reply":"2022-02-26T06:45:19.222141Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"images,labels = shuffle(images, labels, random_state=1)\n","metadata":{"execution":{"iopub.status.busy":"2022-02-26T06:45:19.979992Z","iopub.execute_input":"2022-02-26T06:45:19.980533Z","iopub.status.idle":"2022-02-26T06:45:20.220023Z","shell.execute_reply.started":"2022-02-26T06:45:19.980492Z","shell.execute_reply":"2022-02-26T06:45:20.219257Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"x_train , x_test , y_train , y_test = train_test_split(images, labels, test_size=0.02 , random_state=415)\n\nprint(x_train.shape)\nprint(x_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2022-02-26T06:45:21.251054Z","iopub.execute_input":"2022-02-26T06:45:21.251605Z","iopub.status.idle":"2022-02-26T06:45:21.479895Z","shell.execute_reply.started":"2022-02-26T06:45:21.251568Z","shell.execute_reply":"2022-02-26T06:45:21.479155Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"plt.imshow(images[4])\nplt.xlabel(labels[4])","metadata":{"execution":{"iopub.status.busy":"2022-02-26T06:45:22.257257Z","iopub.execute_input":"2022-02-26T06:45:22.257821Z","iopub.status.idle":"2022-02-26T06:45:22.433533Z","shell.execute_reply.started":"2022-02-26T06:45:22.257782Z","shell.execute_reply":"2022-02-26T06:45:22.432822Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"DenseNet201 = DenseNet201(input_shape= (48,48,3) ,  include_top=False , weights=\"imagenet\", pooling='max')\n","metadata":{"execution":{"iopub.status.busy":"2022-02-26T04:15:34.661999Z","iopub.execute_input":"2022-02-26T04:15:34.662646Z","iopub.status.idle":"2022-02-26T04:15:40.236361Z","shell.execute_reply.started":"2022-02-26T04:15:34.662604Z","shell.execute_reply":"2022-02-26T04:15:40.235330Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"DenseNet201.trainable = False","metadata":{"execution":{"iopub.status.busy":"2022-02-26T04:15:40.237912Z","iopub.execute_input":"2022-02-26T04:15:40.238147Z","iopub.status.idle":"2022-02-26T04:15:40.269791Z","shell.execute_reply.started":"2022-02-26T04:15:40.238119Z","shell.execute_reply":"2022-02-26T04:15:40.268955Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"x = Flatten()(DenseNet201.output)\n","metadata":{"execution":{"iopub.status.busy":"2022-02-26T04:15:42.949541Z","iopub.execute_input":"2022-02-26T04:15:42.949818Z","iopub.status.idle":"2022-02-26T04:15:42.959996Z","shell.execute_reply.started":"2022-02-26T04:15:42.949791Z","shell.execute_reply":"2022-02-26T04:15:42.958947Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"from tensorflow import keras\n\nprediction = Dense(6, activation='softmax')(x)\n\n# create a model object\nmodel = Model(inputs=DenseNet201.input, outputs=prediction)\nopt = keras.optimizers.Adam(learning_rate=0.0001)\n","metadata":{"execution":{"iopub.status.busy":"2022-02-26T04:16:07.572177Z","iopub.execute_input":"2022-02-26T04:16:07.572492Z","iopub.status.idle":"2022-02-26T04:16:07.636728Z","shell.execute_reply.started":"2022-02-26T04:16:07.572460Z","shell.execute_reply":"2022-02-26T04:16:07.635811Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"model.compile(\n  loss='categorical_crossentropy',\n  optimizer=opt,\n  metrics=['accuracy']\n)\n","metadata":{"execution":{"iopub.status.busy":"2022-02-26T04:16:11.443049Z","iopub.execute_input":"2022-02-26T04:16:11.443355Z","iopub.status.idle":"2022-02-26T04:16:11.471752Z","shell.execute_reply.started":"2022-02-26T04:16:11.443321Z","shell.execute_reply":"2022-02-26T04:16:11.470715Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"r = model.fit(x_train , y_train , batch_size=32 , epochs=20 , validation_data = (x_test , y_test))","metadata":{"execution":{"iopub.status.busy":"2022-02-26T04:16:17.363567Z","iopub.execute_input":"2022-02-26T04:16:17.363863Z","iopub.status.idle":"2022-02-26T05:17:51.499133Z","shell.execute_reply.started":"2022-02-26T04:16:17.363835Z","shell.execute_reply":"2022-02-26T05:17:51.497998Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"plt.plot(r.history['loss'], label='train loss')\nplt.plot(r.history['val_loss'], label='val loss')\nplt.legend()\nplt.show()\n# plt.savefig('LossVal_loss_DenseNet201')\n\n# plot the accuracy\nplt.plot(r.history['accuracy'], label='train acc')\nplt.plot(r.history['val_accuracy'], label='val acc')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-26T05:17:51.928968Z","iopub.execute_input":"2022-02-26T05:17:51.929400Z","iopub.status.idle":"2022-02-26T05:17:52.731925Z","shell.execute_reply.started":"2022-02-26T05:17:51.929352Z","shell.execute_reply":"2022-02-26T05:17:52.730921Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"model.compile(\n  loss='binary_crossentropy',\n  optimizer='adam',\n  metrics=['accuracy']\n)","metadata":{"execution":{"iopub.status.busy":"2022-02-24T07:08:15.746086Z","iopub.execute_input":"2022-02-24T07:08:15.746655Z","iopub.status.idle":"2022-02-24T07:08:15.765226Z","shell.execute_reply.started":"2022-02-24T07:08:15.74662Z","shell.execute_reply":"2022-02-24T07:08:15.764513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"r = model.fit(x_train , y_train , batch_size=16 , epochs=20 , validation_data = (x_test , y_test))","metadata":{"execution":{"iopub.status.busy":"2022-02-24T07:08:15.766687Z","iopub.execute_input":"2022-02-24T07:08:15.767496Z","iopub.status.idle":"2022-02-24T07:26:44.242385Z","shell.execute_reply.started":"2022-02-24T07:08:15.767457Z","shell.execute_reply":"2022-02-24T07:26:44.240238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"r = model.fit(x_train , y_train , batch_size=64 , epochs=10 , validation_data = (x_test , y_test))","metadata":{"execution":{"iopub.status.busy":"2022-02-24T07:26:50.557013Z","iopub.execute_input":"2022-02-24T07:26:50.557292Z","iopub.status.idle":"2022-02-24T07:27:01.150241Z","shell.execute_reply.started":"2022-02-24T07:26:50.557262Z","shell.execute_reply":"2022-02-24T07:27:01.148909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mobile = MobileNet(input_shape= (48,48,3) , dropout = 0.01 ,  include_top=False , weights=\"imagenet\", pooling='max')","metadata":{"execution":{"iopub.status.busy":"2022-02-26T05:18:29.075347Z","iopub.execute_input":"2022-02-26T05:18:29.075631Z","iopub.status.idle":"2022-02-26T05:18:29.986662Z","shell.execute_reply.started":"2022-02-26T05:18:29.075603Z","shell.execute_reply":"2022-02-26T05:18:29.985562Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"mobile.trainable = False","metadata":{"execution":{"iopub.status.busy":"2022-02-26T05:18:31.175639Z","iopub.execute_input":"2022-02-26T05:18:31.175973Z","iopub.status.idle":"2022-02-26T05:18:31.184264Z","shell.execute_reply.started":"2022-02-26T05:18:31.175941Z","shell.execute_reply":"2022-02-26T05:18:31.183289Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"x = Flatten()(mobile.output)","metadata":{"execution":{"iopub.status.busy":"2022-02-26T05:18:32.190638Z","iopub.execute_input":"2022-02-26T05:18:32.191266Z","iopub.status.idle":"2022-02-26T05:18:32.200168Z","shell.execute_reply.started":"2022-02-26T05:18:32.191211Z","shell.execute_reply":"2022-02-26T05:18:32.198780Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"prediction = Dense(6, activation='softmax')(x)\n\n# create a model object\nmobile = Model(inputs=mobile.input, outputs=prediction)\nopt = keras.optimizers.Adam(learning_rate=0.0005)\n","metadata":{"execution":{"iopub.status.busy":"2022-02-26T05:38:31.874701Z","iopub.execute_input":"2022-02-26T05:38:31.875197Z","iopub.status.idle":"2022-02-26T05:38:31.900283Z","shell.execute_reply.started":"2022-02-26T05:38:31.875141Z","shell.execute_reply":"2022-02-26T05:38:31.899410Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"mobile.compile(\n  loss='categorical_crossentropy',\n  optimizer=opt,\n  metrics=['accuracy']\n)","metadata":{"execution":{"iopub.status.busy":"2022-02-26T05:38:32.059884Z","iopub.execute_input":"2022-02-26T05:38:32.060625Z","iopub.status.idle":"2022-02-26T05:38:32.072445Z","shell.execute_reply.started":"2022-02-26T05:38:32.060576Z","shell.execute_reply":"2022-02-26T05:38:32.071511Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"r = mobile.fit(x_train , y_train , batch_size=32 , epochs=40 , validation_data = (x_test , y_test))","metadata":{"execution":{"iopub.status.busy":"2022-02-26T05:38:32.244174Z","iopub.execute_input":"2022-02-26T05:38:32.244800Z","iopub.status.idle":"2022-02-26T05:59:41.013617Z","shell.execute_reply.started":"2022-02-26T05:38:32.244758Z","shell.execute_reply":"2022-02-26T05:59:41.012772Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"plt.plot(r.history['loss'], label='train loss')\nplt.plot(r.history['val_loss'], label='val loss')\nplt.legend()\nplt.show()\n# plt.savefig('LossVal_loss_DenseNet201')\n\n# plot the accuracy\nplt.plot(r.history['accuracy'], label='train acc')\nplt.plot(r.history['val_accuracy'], label='val acc')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-26T06:07:14.494843Z","iopub.execute_input":"2022-02-26T06:07:14.495267Z","iopub.status.idle":"2022-02-26T06:07:35.330063Z","shell.execute_reply.started":"2022-02-26T06:07:14.495137Z","shell.execute_reply":"2022-02-26T06:07:35.329004Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"r = model.fit(x_train , y_train , batch_size=32 , epochs=10 , validation_data = (x_test , y_test))","metadata":{"execution":{"iopub.status.busy":"2022-02-24T07:45:28.086724Z","iopub.execute_input":"2022-02-24T07:45:28.087602Z","iopub.status.idle":"2022-02-24T07:46:06.593453Z","shell.execute_reply.started":"2022-02-24T07:45:28.087544Z","shell.execute_reply":"2022-02-24T07:46:06.592254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(r.history['loss'], label='train loss')\nplt.plot(r.history['val_loss'], label='val loss')\nplt.legend()\nplt.show()\n# plt.savefig('LossVal_loss_DenseNet201')\n\n# plot the accuracy\nplt.plot(r.history['accuracy'], label='train acc')\nplt.plot(r.history['val_accuracy'], label='val acc')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-24T07:45:20.331149Z","iopub.status.idle":"2022-02-24T07:45:20.33163Z","shell.execute_reply.started":"2022-02-24T07:45:20.331382Z","shell.execute_reply":"2022-02-24T07:45:20.331408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### canny edge detection\n1. Noise reduction;\n2. Gradient calculation;\n3. Non-maximum suppression;\n4. Double threshold;\n5. Edge Tracking by Hysteresis.","metadata":{}},{"cell_type":"code","source":"from scipy.ndimage.filters import convolve\n\nimgs_final = []\nimg_smoothed = convolve(image, gaussian_kernel(2304, 1))\ngradientMat, thetaMat = sobel_filters(img_smoothed)\nnonMaxImg = non_max_suppression(gradientMat, thetaMat)\nthresholdImg = threshold(nonMaxImg)\nimg_final = hysteresis(thresholdImg)\nimgs_final.append(img_final)","metadata":{"execution":{"iopub.status.busy":"2022-02-23T19:10:57.403499Z","iopub.execute_input":"2022-02-23T19:10:57.40382Z","iopub.status.idle":"2022-02-23T19:10:57.668502Z","shell.execute_reply.started":"2022-02-23T19:10:57.403782Z","shell.execute_reply":"2022-02-23T19:10:57.667297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Noise reduction:","metadata":{}},{"cell_type":"code","source":"def gaussian_kernel(size, sigma=1):\n    size = int(size) // 2\n    x, y = np.mgrid[-size:size+1, -size:size+1]\n    normal = 1 / (2.0 * np.pi * sigma**2)\n    g =  np.exp(-((x**2 + y**2) / (2.0*sigma**2))) * normal\n    return g","metadata":{"execution":{"iopub.status.busy":"2022-02-23T19:03:57.999449Z","iopub.execute_input":"2022-02-23T19:03:57.999996Z","iopub.status.idle":"2022-02-23T19:03:58.005835Z","shell.execute_reply.started":"2022-02-23T19:03:57.99996Z","shell.execute_reply":"2022-02-23T19:03:58.005169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image=cv2.imread(\"../input/emotion-detection-fer/train/happy/im0.png\")\nedges = cv2.Canny(image,1,150)\nplt.subplot(121),plt.imshow(image,cmap = 'gray')\nplt.title('Original Image'), plt.xticks([]), plt.yticks([])\nplt.subplot(122),plt.imshow(edges,cmap = 'gray')\nplt.title('Edge Image'), plt.xticks([]), plt.yticks([])","metadata":{"execution":{"iopub.status.busy":"2022-02-23T20:50:58.480661Z","iopub.execute_input":"2022-02-23T20:50:58.481401Z","iopub.status.idle":"2022-02-23T20:50:58.560918Z","shell.execute_reply.started":"2022-02-23T20:50:58.481289Z","shell.execute_reply":"2022-02-23T20:50:58.559879Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plt.imshow(imagess)\nimport cv2\nimport matplotlib.pyplot as plt\n\nimage=cv2.imread(\"../input/emotion-detection-fer/train/disgusted/im118.png\")\n# image = cv2.cvtColor(image , cv2.COLOR_BGR2GRAY)\ninvert = cv2.bitwise_not(image)\nblur = cv2.GaussianBlur(invert , (13,13), 0)\ninverterblur = cv2.bitwise_not(blur)\nsketch = cv2.divide(image , inverterblur , scale=256.0)\n\nplt.imshow(sketch)\n","metadata":{"execution":{"iopub.status.busy":"2022-02-23T22:28:35.204265Z","iopub.execute_input":"2022-02-23T22:28:35.204775Z","iopub.status.idle":"2022-02-23T22:28:35.407003Z","shell.execute_reply.started":"2022-02-23T22:28:35.204743Z","shell.execute_reply":"2022-02-23T22:28:35.406421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(image)\n","metadata":{"execution":{"iopub.status.busy":"2022-02-23T22:29:03.029778Z","iopub.execute_input":"2022-02-23T22:29:03.030444Z","iopub.status.idle":"2022-02-23T22:29:03.225183Z","shell.execute_reply.started":"2022-02-23T22:29:03.030409Z","shell.execute_reply":"2022-02-23T22:29:03.224305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimagesnp=np.array(sketch)\nimagesnp.shape","metadata":{"execution":{"iopub.status.busy":"2022-02-23T22:27:23.109032Z","iopub.execute_input":"2022-02-23T22:27:23.109534Z","iopub.status.idle":"2022-02-23T22:27:23.117344Z","shell.execute_reply.started":"2022-02-23T22:27:23.109493Z","shell.execute_reply":"2022-02-23T22:27:23.116587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Gradient Calculation\n","metadata":{}},{"cell_type":"code","source":"from scipy import ndimage\n\ndef sobel_filters(img):\n    Kx = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], np.float32)\n    Ky = np.array([[1, 2, 1], [0, 0, 0], [-1, -2, -1]], np.float32)\n    \n    Ix = ndimage.filters.convolve(img, Kx)\n    Iy = ndimage.filters.convolve(img, Ky)\n    \n    G = np.hypot(Ix, Iy)\n    G = G / G.max() * 255\n    theta = np.arctan2(Iy, Ix)\n    \n    return (G, theta)","metadata":{"execution":{"iopub.status.busy":"2022-02-23T19:04:01.102389Z","iopub.execute_input":"2022-02-23T19:04:01.102813Z","iopub.status.idle":"2022-02-23T19:04:01.111207Z","shell.execute_reply.started":"2022-02-23T19:04:01.102778Z","shell.execute_reply":"2022-02-23T19:04:01.110578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Non-Maximum Suppression\n","metadata":{}},{"cell_type":"code","source":"def non_max_suppression(img, D):\n    M, N = img.shape\n    Z = np.zeros((M,N), dtype=np.int32)\n    angle = D * 180. / np.pi\n    angle[angle < 0] += 180\n\n    \n    for i in range(1,M-1):\n        for j in range(1,N-1):\n            try:\n                q = 255\n                r = 255\n                \n               #angle 0\n                if (0 <= angle[i,j] < 22.5) or (157.5 <= angle[i,j] <= 180):\n                    q = img[i, j+1]\n                    r = img[i, j-1]\n                #angle 45\n                elif (22.5 <= angle[i,j] < 67.5):\n                    q = img[i+1, j-1]\n                    r = img[i-1, j+1]\n                #angle 90\n                elif (67.5 <= angle[i,j] < 112.5):\n                    q = img[i+1, j]\n                    r = img[i-1, j]\n                #angle 135\n                elif (112.5 <= angle[i,j] < 157.5):\n                    q = img[i-1, j-1]\n                    r = img[i+1, j+1]\n\n                if (img[i,j] >= q) and (img[i,j] >= r):\n                    Z[i,j] = img[i,j]\n                else:\n                    Z[i,j] = 0\n\n            except IndexError as e:\n                pass\n    \n    return Z\n","metadata":{"execution":{"iopub.status.busy":"2022-02-23T19:04:01.15693Z","iopub.status.idle":"2022-02-23T19:04:01.157704Z","shell.execute_reply.started":"2022-02-23T19:04:01.157475Z","shell.execute_reply":"2022-02-23T19:04:01.157504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Double threshold\n","metadata":{}},{"cell_type":"code","source":"def threshold(img, lowThresholdRatio=0.05, highThresholdRatio=0.09):\n    \n    highThreshold = img.max() * highThresholdRatio;\n    lowThreshold = highThreshold * lowThresholdRatio;\n    \n    M, N = img.shape\n    res = np.zeros((M,N), dtype=np.int32)\n    \n    weak = np.int32(25)\n    strong = np.int32(255)\n    \n    strong_i, strong_j = np.where(img >= highThreshold)\n    zeros_i, zeros_j = np.where(img < lowThreshold)\n    \n    weak_i, weak_j = np.where((img <= highThreshold) & (img >= lowThreshold))\n    \n    res[strong_i, strong_j] = strong\n    res[weak_i, weak_j] = weak\n    \n    return (res, weak, strong)","metadata":{"execution":{"iopub.status.busy":"2022-02-23T19:04:01.158716Z","iopub.status.idle":"2022-02-23T19:04:01.159578Z","shell.execute_reply.started":"2022-02-23T19:04:01.15932Z","shell.execute_reply":"2022-02-23T19:04:01.15935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Edge Tracking by Hysteresis\n","metadata":{}},{"cell_type":"code","source":"def hysteresis(img, weak=75, strong=255):\n    M, N = img.shape  \n    for i in range(1, M-1):\n        for j in range(1, N-1):\n            if (img[i,j] == weak):\n                try:\n                    if ((img[i+1, j-1] == strong) or (img[i+1, j] == strong) or (img[i+1, j+1] == strong)\n                        or (img[i, j-1] == strong) or (img[i, j+1] == strong)\n                        or (img[i-1, j-1] == strong) or (img[i-1, j] == strong) or (img[i-1, j+1] == strong)):\n                        img[i, j] = strong\n                    else:\n                        img[i, j] = 0\n                except IndexError as e:\n                    pass\n    return img","metadata":{"execution":{"iopub.status.busy":"2022-02-23T19:04:01.377342Z","iopub.execute_input":"2022-02-23T19:04:01.378248Z","iopub.status.idle":"2022-02-23T19:04:01.390578Z","shell.execute_reply.started":"2022-02-23T19:04:01.378198Z","shell.execute_reply":"2022-02-23T19:04:01.389771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nsrc = cv2.imread(\"../input/emotion-detection-fer/train/angry/im1008.png\")\nsrc = cv2.GaussianBlur(src, (11, 21),0)\n# src_gray = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)\ndst = cv2.Laplacian(src_gray, cv2.CV_8, ksize=5)","metadata":{"execution":{"iopub.status.busy":"2022-02-24T12:46:15.654484Z","iopub.execute_input":"2022-02-24T12:46:15.654842Z","iopub.status.idle":"2022-02-24T12:46:15.69995Z","shell.execute_reply.started":"2022-02-24T12:46:15.654807Z","shell.execute_reply":"2022-02-24T12:46:15.698699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(dst)\ndst=np.array(dst)","metadata":{"execution":{"iopub.status.busy":"2022-02-24T12:43:27.680163Z","iopub.execute_input":"2022-02-24T12:43:27.680514Z","iopub.status.idle":"2022-02-24T12:43:27.894073Z","shell.execute_reply.started":"2022-02-24T12:43:27.680479Z","shell.execute_reply":"2022-02-24T12:43:27.893016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dst.shape","metadata":{"execution":{"iopub.status.busy":"2022-02-24T12:42:04.164744Z","iopub.execute_input":"2022-02-24T12:42:04.165745Z","iopub.status.idle":"2022-02-24T12:42:04.172406Z","shell.execute_reply.started":"2022-02-24T12:42:04.165704Z","shell.execute_reply":"2022-02-24T12:42:04.171117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vgg16 = VGG16(input_shape= (48,48,3) , include_top=False , weights=\"imagenet\", pooling='max')\n","metadata":{"execution":{"iopub.status.busy":"2022-02-26T06:45:32.419539Z","iopub.execute_input":"2022-02-26T06:45:32.420059Z","iopub.status.idle":"2022-02-26T06:45:35.249554Z","shell.execute_reply.started":"2022-02-26T06:45:32.420023Z","shell.execute_reply":"2022-02-26T06:45:35.248734Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"vgg16.trainable = False","metadata":{"execution":{"iopub.status.busy":"2022-02-26T06:45:35.251131Z","iopub.execute_input":"2022-02-26T06:45:35.251363Z","iopub.status.idle":"2022-02-26T06:45:35.255166Z","shell.execute_reply.started":"2022-02-26T06:45:35.251331Z","shell.execute_reply":"2022-02-26T06:45:35.254512Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"x = Flatten()(vgg16.output)","metadata":{"execution":{"iopub.status.busy":"2022-02-26T06:45:43.087241Z","iopub.execute_input":"2022-02-26T06:45:43.087517Z","iopub.status.idle":"2022-02-26T06:45:43.095439Z","shell.execute_reply.started":"2022-02-26T06:45:43.087481Z","shell.execute_reply":"2022-02-26T06:45:43.094608Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"prediction = Dense(6, activation='softmax')(x)\n\n# create a model object\nvgg16 = Model(inputs=vgg16.input, outputs=prediction)\n","metadata":{"execution":{"iopub.status.busy":"2022-02-26T06:45:43.957077Z","iopub.execute_input":"2022-02-26T06:45:43.957329Z","iopub.status.idle":"2022-02-26T06:45:43.974634Z","shell.execute_reply.started":"2022-02-26T06:45:43.957301Z","shell.execute_reply":"2022-02-26T06:45:43.973974Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"vgg16.compile(\n  loss='categorical_crossentropy',\n  optimizer='adam',\n  metrics=['accuracy']\n)","metadata":{"execution":{"iopub.status.busy":"2022-02-26T06:45:47.690241Z","iopub.execute_input":"2022-02-26T06:45:47.690521Z","iopub.status.idle":"2022-02-26T06:45:47.705902Z","shell.execute_reply.started":"2022-02-26T06:45:47.690490Z","shell.execute_reply":"2022-02-26T06:45:47.705201Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"r = vgg16.fit(x_train , y_train , batch_size=16 , epochs=40 , validation_data = (x_test , y_test))","metadata":{"execution":{"iopub.status.busy":"2022-02-26T06:45:49.645818Z","iopub.execute_input":"2022-02-26T06:45:49.646565Z","iopub.status.idle":"2022-02-26T06:54:30.558180Z","shell.execute_reply.started":"2022-02-26T06:45:49.646515Z","shell.execute_reply":"2022-02-26T06:54:30.557508Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"plt.plot(r.history['loss'], label='train loss')\nplt.plot(r.history['val_loss'], label='val loss')\nplt.legend()\nplt.show()\n# plt.savefig('LossVal_loss_DenseNet201')\n\n# plot the accuracy\nplt.plot(r.history['accuracy'], label='train acc')\nplt.plot(r.history['val_accuracy'], label='val acc')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-26T06:54:35.452258Z","iopub.execute_input":"2022-02-26T06:54:35.452811Z","iopub.status.idle":"2022-02-26T06:54:35.834955Z","shell.execute_reply.started":"2022-02-26T06:54:35.452772Z","shell.execute_reply":"2022-02-26T06:54:35.834313Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"prediction = Dense(6, activation='softmax')(x)\n\n# create a model object\nvgg16 = Model(inputs=vgg16.input, outputs=prediction)\nopt = keras.optimizers.Adam(learning_rate=0.0001)\nvgg16.compile(\n  loss='categorical_crossentropy',\n  optimizer=opt ,\n  metrics=['accuracy']\n)","metadata":{"execution":{"iopub.status.busy":"2022-02-26T06:55:56.761442Z","iopub.execute_input":"2022-02-26T06:55:56.761718Z","iopub.status.idle":"2022-02-26T06:55:56.783318Z","shell.execute_reply.started":"2022-02-26T06:55:56.761690Z","shell.execute_reply":"2022-02-26T06:55:56.782688Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"r = vgg16.fit(x_train , y_train , batch_size=16 , epochs=40 , validation_data = (x_test , y_test))","metadata":{"execution":{"iopub.status.busy":"2022-02-26T06:56:02.894866Z","iopub.execute_input":"2022-02-26T06:56:02.895119Z","iopub.status.idle":"2022-02-26T07:05:26.638777Z","shell.execute_reply.started":"2022-02-26T06:56:02.895090Z","shell.execute_reply":"2022-02-26T07:05:26.637936Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"plt.plot(r.history['loss'], label='train loss')\nplt.plot(r.history['val_loss'], label='val loss')\nplt.legend()\nplt.show()\n# plt.savefig('LossVal_loss_DenseNet201')\n\n# plot the accuracy\nplt.plot(r.history['accuracy'], label='train acc')\nplt.plot(r.history['val_accuracy'], label='val acc')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-26T07:05:26.640852Z","iopub.execute_input":"2022-02-26T07:05:26.641126Z","iopub.status.idle":"2022-02-26T07:05:27.027002Z","shell.execute_reply.started":"2022-02-26T07:05:26.641089Z","shell.execute_reply":"2022-02-26T07:05:27.026344Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.layers import Activation, Conv2D, MaxPooling2D, Dense, Flatten, Dropout, BatchNormalization\nmodel = tf.keras.Sequential()\n\nmodel.add(Conv2D(16,(3,3),padding='same',kernel_initializer='he_normal',input_shape=(48,48,3)))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(32,(3,3),padding='same',kernel_initializer='he_normal',input_shape=(48,48,3)))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\n# model.add(Conv2D(32,(3,3),padding='same',kernel_initializer='he_normal',input_shape=(48,48,3)))\n# model.add(Activation('relu'))\n# model.add(BatchNormalization())\n# model.add(Conv2D(32,(3,3),padding='same',kernel_initializer='he_normal',input_shape=(48,48,3)))\n# model.add(Activation('relu'))\n# model.add(BatchNormalization())\n# model.add(Conv2D(32,(3,3),padding='same',kernel_initializer='he_normal',input_shape=(48,48,3)))\n# model.add(Activation('relu'))\n# model.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.01))\n\n\nmodel.add(Conv2D(32,(3,3),padding='same',kernel_initializer='he_normal'))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(64,(3,3),padding='same',kernel_initializer='he_normal'))\n# model.add(Activation('relu'))\n# model.add(BatchNormalization())\n# model.add(MaxPooling2D(pool_size=(2,2)))\n# model.add(Dropout(0.2))\n\n\nmodel.add(Conv2D(32,(3,3),padding='same',kernel_initializer='he_normal'))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(32,(3,3),padding='same',kernel_initializer='he_normal'))\nmodel.add(Activation('relu'))\n# model.add(BatchNormalization())\n# model.add(Conv2D(32,(3,3),padding='same',kernel_initializer='he_normal'))\n# model.add(Activation('relu'))\n# model.add(BatchNormalization())\n# model.add(Conv2D(32,(3,3),padding='same',kernel_initializer='he_normal'))\n# model.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.01))\n\n# # model.add(Conv2D(128,(3,3),padding='same',kernel_initializer='he_normal'))\n# # model.add(Activation('relu'))\n# # model.add(BatchNormalization())\n# # model.add(Conv2D(128,(3,3),padding='same',kernel_initializer='he_normal'))\n# # model.add(Activation('relu'))\n# # model.add(BatchNormalization())\n# # model.add(MaxPooling2D(pool_size=(2,2)))\n# # model.add(Dropout(0.2))\n\n\n# # model.add(Conv2D(256,(3,3),padding='same',kernel_initializer='he_normal'))\n# # model.add(Activation('relu'))\n# # model.add(BatchNormalization())\n# # model.add(Conv2D(256,(3,3),padding='same',kernel_initializer='he_normal'))\n# # model.add(Activation('relu'))\n# # model.add(BatchNormalization())\n# # model.add(MaxPooling2D(pool_size=(2,2)))\n# # model.add(Dropout(0.2))\n\n\nmodel.add(Flatten())\nmodel.add(Dense(64,kernel_initializer='he_normal'))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\n\n\nmodel.add(Dense(64,kernel_initializer='he_normal'))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\n\n\nmodel.add(Dense(7,kernel_initializer='he_normal'))\nmodel.add(Activation('softmax'))\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-02-25T19:41:18.869904Z","iopub.execute_input":"2022-02-25T19:41:18.870478Z","iopub.status.idle":"2022-02-25T19:41:18.985759Z","shell.execute_reply.started":"2022-02-25T19:41:18.870441Z","shell.execute_reply":"2022-02-25T19:41:18.984208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = tf.keras.models.Sequential([\n    # Note the input shape is the desired size of the image 300x300 with 3 bytes color\n    # This is the first convolution\n    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(48, 48, 3)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    # The second convolution\n    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    # The third convolution\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    # The fourth convolution\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    # The fifth convolution\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    # Flatten the results to feed into a DNN\n    tf.keras.layers.Flatten(),\n    # 512 neuron hidden layer\n    tf.keras.layers.Dense(128, activation='relu'),\n    # Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class ('horses') and 1 for the other ('humans')\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])","metadata":{"execution":{"iopub.status.busy":"2022-02-25T19:30:17.144387Z","iopub.execute_input":"2022-02-25T19:30:17.144735Z","iopub.status.idle":"2022-02-25T19:30:17.351636Z","shell.execute_reply.started":"2022-02-25T19:30:17.144694Z","shell.execute_reply":"2022-02-25T19:30:17.349488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-02-25T19:17:08.637425Z","iopub.execute_input":"2022-02-25T19:17:08.637923Z","iopub.status.idle":"2022-02-25T19:17:08.651442Z","shell.execute_reply.started":"2022-02-25T19:17:08.637885Z","shell.execute_reply":"2022-02-25T19:17:08.650632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.optimizers import RMSprop\n \nmodel.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.1), metrics=['acc'])\n# model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.3),loss='categorical_crossentropy',metrics=['accuracy'])\n","metadata":{"execution":{"iopub.status.busy":"2022-02-25T19:27:12.900177Z","iopub.execute_input":"2022-02-25T19:27:12.900688Z","iopub.status.idle":"2022-02-25T19:27:12.915472Z","shell.execute_reply.started":"2022-02-25T19:27:12.900644Z","shell.execute_reply":"2022-02-25T19:27:12.914848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(x_train , y_train , batch_size=32 , epochs=50 , validation_data = (x_test , y_test))","metadata":{"execution":{"iopub.status.busy":"2022-02-25T19:27:13.012642Z","iopub.execute_input":"2022-02-25T19:27:13.012849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}