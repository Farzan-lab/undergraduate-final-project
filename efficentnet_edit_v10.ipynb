{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### import libs\n","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport tensorflow as tf\nimport tensorflow.keras as k\n\nimport csv\nimport cv2\nimport os\n\nfrom tensorflow.keras.layers import Input, Lambda, Dense, Flatten\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.applications.densenet import DenseNet201 ,DenseNet121\nfrom tensorflow.keras.applications.mobilenet import MobileNet\nfrom tensorflow.keras.applications import VGG16,VGG19\nfrom tensorflow.keras.applications.densenet import preprocess_input\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\n\nfrom sklearn.utils import shuffle\nfrom sklearn.preprocessing import LabelEncoder , OneHotEncoder\nfrom sklearn.model_selection import train_test_split\n\nfrom scipy import ndimage","metadata":{"execution":{"iopub.status.busy":"2022-07-12T17:51:07.271726Z","iopub.execute_input":"2022-07-12T17:51:07.272392Z","iopub.status.idle":"2022-07-12T17:51:07.281950Z","shell.execute_reply.started":"2022-07-12T17:51:07.272355Z","shell.execute_reply":"2022-07-12T17:51:07.281180Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imagetype= os.listdir(\"../input/emotion-detection-fer/train\")\ntest_imagetype= os.listdir(\"../input/emotion-detection-fer/test\")\nck_imagetype= os.listdir(\"../input/ckplus/CK+48\")\n# imagetype.remove(\"disgusted\")\n# test_imagetype.remove(\"disgusted\")\n# ck_imagetype.remove(\"contempt\")\nprint(imagetype)\nprint(test_imagetype)\nprint(ck_imagetype)","metadata":{"execution":{"iopub.status.busy":"2022-07-12T17:51:07.446230Z","iopub.execute_input":"2022-07-12T17:51:07.446439Z","iopub.status.idle":"2022-07-12T17:51:07.455147Z","shell.execute_reply.started":"2022-07-12T17:51:07.446414Z","shell.execute_reply":"2022-07-12T17:51:07.454398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images = []    #images for train list will store all images\nlabels= []\nt_images = []    #images for test list will store all images\nt_labels= []\nck_images = []\nck_labels = []\npath = \"../input/emotion-detection-fer/train/\"\nt_path = \"../input/emotion-detection-fer/test/\"\nck_path = \"../input/ckplus/CK+48\"","metadata":{"execution":{"iopub.status.busy":"2022-07-12T17:51:07.592138Z","iopub.execute_input":"2022-07-12T17:51:07.592456Z","iopub.status.idle":"2022-07-12T17:51:07.598028Z","shell.execute_reply.started":"2022-07-12T17:51:07.592426Z","shell.execute_reply":"2022-07-12T17:51:07.597035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **FER13**","metadata":{}},{"cell_type":"markdown","source":"### *Load data*","metadata":{}},{"cell_type":"code","source":"for i in imagetype:\n    print(i)\n    flower_path=path+str(i)\n    data_list=[j for j in os.listdir(flower_path) if j.endswith(\".png\") ]\n    counter=0\n    for data in data_list:\n#         if counter> 2390: break\n        img=cv2.imread(flower_path + '/'+ data)\n#         img = cv2.resize(img , (64,64))\n        images.append(img)\n        labels.append(i)\n    \nprint(\"total train images:\",len(images))\nprint(\"total train images:\",len(labels))\n","metadata":{"execution":{"iopub.status.busy":"2022-07-12T17:51:09.894061Z","iopub.execute_input":"2022-07-12T17:51:09.894722Z","iopub.status.idle":"2022-07-12T17:51:53.450241Z","shell.execute_reply.started":"2022-07-12T17:51:09.894666Z","shell.execute_reply":"2022-07-12T17:51:53.449142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in test_imagetype:\n    print(i)\n    flower_path=t_path+str(i)\n    test_data_list=[j for j in os.listdir(flower_path) if j.endswith(\".png\") ]\n    counter=0\n    for data in test_data_list:\n#         if counter> 2390: break\n        img=cv2.imread(flower_path + '/'+ data)\n#         img = cv2.resize(img , (64,64))\n        t_images.append(img)\n        t_labels.append(i)\nprint(\"total test images:\",len(t_images))\nprint(\"total test images:\",len(t_labels))","metadata":{"execution":{"iopub.status.busy":"2022-07-12T17:51:53.452960Z","iopub.execute_input":"2022-07-12T17:51:53.454014Z","iopub.status.idle":"2022-07-12T17:52:04.431292Z","shell.execute_reply.started":"2022-07-12T17:51:53.453975Z","shell.execute_reply":"2022-07-12T17:52:04.430542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"type(images)","metadata":{"execution":{"iopub.status.busy":"2022-07-12T17:52:04.433496Z","iopub.execute_input":"2022-07-12T17:52:04.434581Z","iopub.status.idle":"2022-07-12T17:52:04.441916Z","shell.execute_reply.started":"2022-07-12T17:52:04.434541Z","shell.execute_reply":"2022-07-12T17:52:04.441121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encode= LabelEncoder()\nlabels=encode.fit_transform(labels)\nencode2= LabelEncoder()\nt_labels = encode2.fit_transform(t_labels)\nt_labels[1:10]","metadata":{"execution":{"iopub.status.busy":"2022-07-12T17:52:04.444226Z","iopub.execute_input":"2022-07-12T17:52:04.445459Z","iopub.status.idle":"2022-07-12T17:52:04.477550Z","shell.execute_reply.started":"2022-07-12T17:52:04.445420Z","shell.execute_reply":"2022-07-12T17:52:04.476893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels=labels.reshape(-1,1)\nonehotencoder= OneHotEncoder()\nlabels=onehotencoder.fit_transform(labels)\nlabels=labels.toarray()\nlabels\nprint(\"train labels is ready!\")","metadata":{"execution":{"iopub.status.busy":"2022-07-12T17:52:04.480204Z","iopub.execute_input":"2022-07-12T17:52:04.481259Z","iopub.status.idle":"2022-07-12T17:52:04.492034Z","shell.execute_reply.started":"2022-07-12T17:52:04.481221Z","shell.execute_reply":"2022-07-12T17:52:04.491110Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"t_labels=t_labels.reshape(-1,1)\nonehotencoder= OneHotEncoder()\nt_labels=onehotencoder.fit_transform(t_labels)\nt_labels=t_labels.toarray()\nprint(\"test labels is ready!\")\nt_labels[:10]","metadata":{"execution":{"iopub.status.busy":"2022-07-12T17:52:04.494199Z","iopub.execute_input":"2022-07-12T17:52:04.495258Z","iopub.status.idle":"2022-07-12T17:52:04.509111Z","shell.execute_reply.started":"2022-07-12T17:52:04.495222Z","shell.execute_reply":"2022-07-12T17:52:04.508441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images=np.array(images)\nprint(images.shape)\nprint(labels.shape)","metadata":{"execution":{"iopub.status.busy":"2022-07-12T17:52:04.511183Z","iopub.execute_input":"2022-07-12T17:52:04.512324Z","iopub.status.idle":"2022-07-12T17:52:04.626991Z","shell.execute_reply.started":"2022-07-12T17:52:04.512286Z","shell.execute_reply":"2022-07-12T17:52:04.626250Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"t_images=np.array(t_images)\nprint(t_images.shape)\nprint(t_labels.shape)","metadata":{"execution":{"iopub.status.busy":"2022-07-12T17:52:04.629201Z","iopub.execute_input":"2022-07-12T17:52:04.630443Z","iopub.status.idle":"2022-07-12T17:52:04.658972Z","shell.execute_reply.started":"2022-07-12T17:52:04.630400Z","shell.execute_reply":"2022-07-12T17:52:04.658261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images,labels = shuffle(images, labels, random_state=1)\nt_images , t_labels =  shuffle(t_images, t_labels, random_state=1)","metadata":{"execution":{"iopub.status.busy":"2022-07-12T18:27:38.695004Z","iopub.execute_input":"2022-07-12T18:27:38.695258Z","iopub.status.idle":"2022-07-12T18:27:38.793015Z","shell.execute_reply.started":"2022-07-12T18:27:38.695228Z","shell.execute_reply":"2022-07-12T18:27:38.792252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(images[4])\nplt.xlabel(labels[4])","metadata":{"execution":{"iopub.status.busy":"2022-07-12T18:27:42.292195Z","iopub.execute_input":"2022-07-12T18:27:42.292452Z","iopub.status.idle":"2022-07-12T18:27:42.491093Z","shell.execute_reply.started":"2022-07-12T18:27:42.292421Z","shell.execute_reply":"2022-07-12T18:27:42.487204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **CKPLUS**","metadata":{}},{"cell_type":"markdown","source":"### *load data*","metadata":{}},{"cell_type":"code","source":"for i in ck_imagetype:\n    print(i)\n    flower_path=ck_path+\"/\"+str(i)\n    data_list=[j for j in os.listdir(flower_path) if j.endswith(\".png\") ]\n    counter=0\n    for data in data_list:\n#         if counter> 2390: break\n        img=cv2.imread(flower_path + '/'+ data)\n#         img = cv2.resize(img , (64,64))\n        images.append(img)\n        labels.append(i)\n    \nprint(\"total train images:\",len(images))\nprint(\"total train images:\",len(labels))","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.878341Z","iopub.status.idle":"2022-07-11T20:20:07.879214Z","shell.execute_reply.started":"2022-07-11T20:20:07.878941Z","shell.execute_reply":"2022-07-11T20:20:07.878970Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"start encoding\", end=\" ---> \")\nencode= LabelEncoder()\nlabels=encode.fit_transform(labels)\nprint (\"encoding finished\")\nprint (\"start one hot encoding\", end=\" ---> \")\nlabels=labels.reshape(-1,1)\nonehotencoder= OneHotEncoder()\nlabels=onehotencoder.fit_transform(labels)\nlabels=labels.toarray()\nprint(\"one hot encoding finished\")\nimages=np.array(images)\nprint(\"images and list shapes:\")\nprint(\"images shape:\", end=\" \" )\nprint(images.shape)\nprint(\"labels shape:\", end=\" \" )\nprint(labels.shape)\n","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.880555Z","iopub.status.idle":"2022-07-11T20:20:07.881481Z","shell.execute_reply.started":"2022-07-11T20:20:07.881140Z","shell.execute_reply":"2022-07-11T20:20:07.881174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images,labels = shuffle(images, labels, random_state=10)\nplt.imshow(images[4])\nplt.xlabel(labels[4])","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.882864Z","iopub.status.idle":"2022-07-11T20:20:07.883837Z","shell.execute_reply.started":"2022-07-11T20:20:07.883581Z","shell.execute_reply":"2022-07-11T20:20:07.883607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### *DenseNet201*","metadata":{}},{"cell_type":"code","source":"DenseNet201 = DenseNet201(input_shape= (48,48,3) ,  include_top=False , weights=\"imagenet\", pooling='max')","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.885066Z","iopub.status.idle":"2022-07-11T20:20:07.885724Z","shell.execute_reply.started":"2022-07-11T20:20:07.885468Z","shell.execute_reply":"2022-07-11T20:20:07.885510Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DenseNet201.trainable = False\nx = Flatten()(DenseNet201.output)\nprediction = Dense(6, activation='softmax')(x)\n\n# create a model object\nDenseNet201 = Model(inputs=DenseNet201.input, outputs=prediction)","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.886952Z","iopub.status.idle":"2022-07-11T20:20:07.887622Z","shell.execute_reply.started":"2022-07-11T20:20:07.887374Z","shell.execute_reply":"2022-07-11T20:20:07.887400Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"opt = keras.optimizers.Adam(learning_rate=0.00010000000474974513)\nDenseNet201.compile(\n  loss='categorical_crossentropy',\n  optimizer=opt,\n  metrics=['accuracy']\n)","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.888999Z","iopub.status.idle":"2022-07-11T20:20:07.889724Z","shell.execute_reply.started":"2022-07-11T20:20:07.889476Z","shell.execute_reply":"2022-07-11T20:20:07.889503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"r = DenseNet201.fit(images , labels , batch_size=32 , epochs=50 , validation_data = (t_images , t_labels))","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.891071Z","iopub.status.idle":"2022-07-11T20:20:07.891788Z","shell.execute_reply.started":"2022-07-11T20:20:07.891523Z","shell.execute_reply":"2022-07-11T20:20:07.891551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(r.history['loss'], label='train loss')\nplt.plot(r.history['val_loss'], label='val loss')\nplt.legend()\nplt.show()\n# plt.savefig('LossVal_loss_DenseNet201')\n\n# plot the accuracy\nplt.plot(r.history['accuracy'], label='train acc')\nplt.plot(r.history['val_accuracy'], label='val acc')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.893108Z","iopub.status.idle":"2022-07-11T20:20:07.893789Z","shell.execute_reply.started":"2022-07-11T20:20:07.893539Z","shell.execute_reply":"2022-07-11T20:20:07.893565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### *MobileNet*","metadata":{}},{"cell_type":"code","source":"mobile = MobileNet(input_shape= (48,48,3) , dropout = 0.1 ,  include_top=False , weights=\"imagenet\", pooling='max')","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.895078Z","iopub.status.idle":"2022-07-11T20:20:07.895751Z","shell.execute_reply.started":"2022-07-11T20:20:07.895503Z","shell.execute_reply":"2022-07-11T20:20:07.895530Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mobile.trainable = False\nx = Flatten()(mobile.output)\nprediction = Dense(7, activation='softmax')(x)\nmobile = Model(inputs=mobile.input, outputs=prediction)","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.897000Z","iopub.status.idle":"2022-07-11T20:20:07.897699Z","shell.execute_reply.started":"2022-07-11T20:20:07.897424Z","shell.execute_reply":"2022-07-11T20:20:07.897450Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"opt = keras.optimizers.Adam(learning_rate=0.00010000000474974513)\nmobile.compile(\n  loss='categorical_crossentropy',\n  optimizer=opt,\n  metrics=['accuracy']\n)","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.899356Z","iopub.status.idle":"2022-07-11T20:20:07.900053Z","shell.execute_reply.started":"2022-07-11T20:20:07.899788Z","shell.execute_reply":"2022-07-11T20:20:07.899816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"r = mobile.fit(images[736:] , labels[736:] , batch_size=32 , epochs=50 , validation_data = (images[:245] , labels[:245]))","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.901338Z","iopub.status.idle":"2022-07-11T20:20:07.902050Z","shell.execute_reply.started":"2022-07-11T20:20:07.901732Z","shell.execute_reply":"2022-07-11T20:20:07.901812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(r.history['loss'], label='train loss')\nplt.plot(r.history['val_loss'], label='val loss')\nplt.legend()\nplt.show()\n# plt.savefig('LossVal_loss_DenseNet201')\n\n# plot the accuracy\nplt.plot(r.history['accuracy'], label='train acc')\nplt.plot(r.history['val_accuracy'], label='val acc')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.903476Z","iopub.status.idle":"2022-07-11T20:20:07.904187Z","shell.execute_reply.started":"2022-07-11T20:20:07.903916Z","shell.execute_reply":"2022-07-11T20:20:07.903944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### *VGG16*","metadata":{}},{"cell_type":"code","source":"vgg16 = VGG16(input_shape= (48,48,3) , include_top=False , weights=\"imagenet\", pooling='max')\n","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.905578Z","iopub.status.idle":"2022-07-11T20:20:07.906286Z","shell.execute_reply.started":"2022-07-11T20:20:07.906004Z","shell.execute_reply":"2022-07-11T20:20:07.906032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vgg16.trainable = True\nx = Flatten()(vgg16.output)\nprediction = Dense(7, activation='softmax')(x)\n\n# create a model object\nvgg16 = Model(inputs=vgg16.input, outputs=prediction)","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.907619Z","iopub.status.idle":"2022-07-11T20:20:07.908330Z","shell.execute_reply.started":"2022-07-11T20:20:07.908037Z","shell.execute_reply":"2022-07-11T20:20:07.908064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"opt = keras.optimizers.Adam(learning_rate=0.00010000000474974513)\nvgg16.compile(\n  loss='categorical_crossentropy',\n  optimizer=opt,\n  metrics=['accuracy']\n)","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.909643Z","iopub.status.idle":"2022-07-11T20:20:07.910364Z","shell.execute_reply.started":"2022-07-11T20:20:07.910067Z","shell.execute_reply":"2022-07-11T20:20:07.910095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"r = vgg16.fit(images[736:] , labels[736:] , batch_size=32 , epochs=50 , validation_data = (images[:245] , labels[:245]))","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.911684Z","iopub.status.idle":"2022-07-11T20:20:07.912389Z","shell.execute_reply.started":"2022-07-11T20:20:07.912101Z","shell.execute_reply":"2022-07-11T20:20:07.912128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(r.history['loss'], label='train loss')\nplt.plot(r.history['val_loss'], label='val loss')\nplt.legend()\nplt.show()\n# plt.savefig('LossVal_loss_DenseNet201')\n\n# plot the accuracy\nplt.plot(r.history['accuracy'], label='train acc')\nplt.plot(r.history['val_accuracy'], label='val acc')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.913691Z","iopub.status.idle":"2022-07-11T20:20:07.914399Z","shell.execute_reply.started":"2022-07-11T20:20:07.914111Z","shell.execute_reply":"2022-07-11T20:20:07.914137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# vgg16.save_weights('vgg16_ckplus.h5')\n# ","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.915716Z","iopub.status.idle":"2022-07-11T20:20:07.916434Z","shell.execute_reply.started":"2022-07-11T20:20:07.916145Z","shell.execute_reply":"2022-07-11T20:20:07.916173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **models**","metadata":{}},{"cell_type":"markdown","source":"*NO.1*","metadata":{}},{"cell_type":"code","source":"model = keras.Sequential([\n# Data Augmentation \n  \n\n  DenseNet121(weights='imagenet',include_top=False, classes=7, input_shape=(48,48,3)), #Extract features \n\n  layers.BatchNormalization(),\n\n\n#CNN layer \n\n  layers.Conv2D(128,(3,3),padding = 'same'), \n  layers.BatchNormalization(),\n  layers.LeakyReLU(alpha=0.1),\n  layers.MaxPooling2D(pool_size = (2,2),padding = 'same'), \n  layers.Dropout(0.5), \n\n\n  layers.Flatten(),\n#Fully connected 1st layer \n\n  layers.Dense(256),\n  layers.BatchNormalization(), \n  layers.Activation('relu'), \n  layers.Dropout(0.65), \n\n# Fully connected layer 2nd layer\n\n#   layers.Dense(128),\n#   layers.BatchNormalization(), \n#   layers.Activation('relu'), \n#   layers.Dropout(0.5), \n\n\n  layers.Dense(7, activation='softmax'),\n                          \n])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-07-12T12:28:09.182825Z","iopub.execute_input":"2022-07-12T12:28:09.183491Z","iopub.status.idle":"2022-07-12T12:28:15.851553Z","shell.execute_reply.started":"2022-07-12T12:28:09.183453Z","shell.execute_reply":"2022-07-12T12:28:15.850817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"opt = keras.optimizers.Adam(learning_rate=0.00010000000474974513)\nmodel.compile(\n  loss='categorical_crossentropy',\n  optimizer=opt,\n  metrics=['accuracy']\n)\n","metadata":{"execution":{"iopub.status.busy":"2022-07-12T12:28:22.357475Z","iopub.execute_input":"2022-07-12T12:28:22.358169Z","iopub.status.idle":"2022-07-12T12:28:22.380052Z","shell.execute_reply.started":"2022-07-12T12:28:22.358133Z","shell.execute_reply":"2022-07-12T12:28:22.379394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(images , labels , batch_size=128 , epochs=30 , validation_data = (t_images ,t_labels))","metadata":{"execution":{"iopub.status.busy":"2022-07-12T12:29:10.237657Z","iopub.execute_input":"2022-07-12T12:29:10.237937Z","iopub.status.idle":"2022-07-12T12:38:32.550036Z","shell.execute_reply.started":"2022-07-12T12:29:10.237908Z","shell.execute_reply":"2022-07-12T12:38:32.549267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['loss'], label='train loss')\nplt.plot(history.history['val_loss'], label='val loss')\nplt.legend()\nplt.show()\n# plt.savefig('LossVal_loss_DenseNet201')\n\n# plot the accuracy\nplt.plot(history.history['accuracy'], label='train acc')\nplt.plot(history.history['val_accuracy'], label='val acc')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-12T12:38:32.552089Z","iopub.execute_input":"2022-07-12T12:38:32.552320Z","iopub.status.idle":"2022-07-12T12:38:32.919159Z","shell.execute_reply.started":"2022-07-12T12:38:32.552289Z","shell.execute_reply":"2022-07-12T12:38:32.918379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### some change","metadata":{}},{"cell_type":"code","source":"model = keras.Sequential([\n# Data Augmentation \n  \n\n  DenseNet121(weights='imagenet',include_top=False, classes=7, input_shape=(48,48,3)), #Extract features \n\n  layers.BatchNormalization(),\n\n\n  #CNN layer \n# 32 ,64 ,128\n  layers.Conv2D(128,(3,3),padding = 'same'), \n  layers.BatchNormalization(),\n  layers.LeakyReLU(alpha=0.1),\n  layers.MaxPooling2D(pool_size = (2,2),padding = 'same'), \n  layers.Dropout(0.65), \n\n  layers.Conv2D(128,(3,3),padding = 'same'), \n  layers.BatchNormalization(),\n  layers.LeakyReLU(alpha=0.1),\n  layers.MaxPooling2D(pool_size = (2,2),padding = 'same'), \n  layers.Dropout(0.65), \n\n  layers.Flatten(),\n#Fully connected 1st layer \n\n  layers.Dense(16),\n  layers.BatchNormalization(), \n  layers.Activation('relu'), \n  layers.Dropout(0.6), \n    \n  layers.Dense(8),\n  layers.BatchNormalization(), \n  layers.Activation('relu'), \n  layers.Dropout(0.6), \n\n# Fully connected layer 2nd layer\n\n#   layers.Dense(128),\n#   layers.BatchNormalization(), \n#   layers.Activation('relu'), \n#   layers.Dropout(0.5), \n\n\n  layers.Dense(7, activation='softmax'),\n                          \n])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-07-12T06:18:09.844818Z","iopub.execute_input":"2022-07-12T06:18:09.845106Z","iopub.status.idle":"2022-07-12T06:18:13.854922Z","shell.execute_reply.started":"2022-07-12T06:18:09.845072Z","shell.execute_reply":"2022-07-12T06:18:13.854192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"opt = keras.optimizers.Adam(learning_rate=0.00010000000474974513)\nmodel.compile(\n  loss='categorical_crossentropy',\n  optimizer=opt,\n  metrics=['accuracy']\n)\n","metadata":{"execution":{"iopub.status.busy":"2022-07-12T06:18:19.053552Z","iopub.execute_input":"2022-07-12T06:18:19.054081Z","iopub.status.idle":"2022-07-12T06:18:19.072156Z","shell.execute_reply.started":"2022-07-12T06:18:19.054044Z","shell.execute_reply":"2022-07-12T06:18:19.071476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(images , labels , batch_size=32 , epochs=40 , validation_data = (t_images ,t_labels))","metadata":{"execution":{"iopub.status.busy":"2022-07-12T06:18:19.203797Z","iopub.execute_input":"2022-07-12T06:18:19.204115Z","iopub.status.idle":"2022-07-12T06:58:51.009118Z","shell.execute_reply.started":"2022-07-12T06:18:19.204085Z","shell.execute_reply":"2022-07-12T06:58:51.008347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['loss'], label='train loss')\nplt.plot(history.history['val_loss'], label='val loss')\nplt.legend()\nplt.show()\n# plt.savefig('LossVal_loss_DenseNet201')\n\n# plot the accuracy\nplt.plot(history.history['accuracy'], label='train acc')\nplt.plot(history.history['val_accuracy'], label='val acc')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-12T06:58:51.560641Z","iopub.execute_input":"2022-07-12T06:58:51.560867Z","iopub.status.idle":"2022-07-12T06:58:52.341803Z","shell.execute_reply.started":"2022-07-12T06:58:51.560839Z","shell.execute_reply":"2022-07-12T06:58:52.341121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = keras.Sequential([\n# Data Augmentation \n  \n\n  DenseNet121(weights='imagenet',include_top=False, classes=7, input_shape=(48,48,3)), #Extract features \n\n  layers.BatchNormalization(),\n\n\n  #CNN layer \n# 32 ,64 ,128\n  layers.Conv2D(128,(3,3),padding = 'same'), \n  layers.BatchNormalization(),\n  layers.LeakyReLU(alpha=0.1),\n  layers.MaxPooling2D(pool_size = (2,2),padding = 'same'), \n  layers.Dropout(0.65), \n\n  layers.Conv2D(128,(3,3),padding = 'same'), \n  layers.BatchNormalization(),\n  layers.LeakyReLU(alpha=0.1),\n  layers.MaxPooling2D(pool_size = (2,2),padding = 'same'), \n  layers.Dropout(0.65), \n    \n  layers.Conv2D(64,(3,3),padding = 'same'), \n  layers.BatchNormalization(),\n  layers.LeakyReLU(alpha=0.1),\n  layers.MaxPooling2D(pool_size = (2,2),padding = 'same'), \n  layers.Dropout(0.65), \n\n  layers.Flatten(),\n#Fully connected 1st layer \n\n  layers.Dense(32),\n  layers.BatchNormalization(), \n  layers.Activation('relu'), \n  layers.Dropout(0.6), \n    \n  layers.Dense(16),\n  layers.BatchNormalization(), \n  layers.Activation('relu'), \n  layers.Dropout(0.6), \n\n# Fully connected layer 2nd layer\n\n#   layers.Dense(128),\n#   layers.BatchNormalization(), \n#   layers.Activation('relu'), \n#   layers.Dropout(0.5), \n\n\n  layers.Dense(7, activation='softmax'),\n                          \n])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-07-12T07:00:49.771726Z","iopub.execute_input":"2022-07-12T07:00:49.771984Z","iopub.status.idle":"2022-07-12T07:00:52.998193Z","shell.execute_reply.started":"2022-07-12T07:00:49.771955Z","shell.execute_reply":"2022-07-12T07:00:52.997509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"opt = keras.optimizers.Adam(learning_rate=0.00010000000474974513)\nmodel.compile(\n  loss='categorical_crossentropy',\n  optimizer=opt,\n  metrics=['accuracy']\n)\nhistory = model.fit(images , labels , batch_size=32 , epochs=40 , validation_data = (t_images ,t_labels))","metadata":{"execution":{"iopub.status.busy":"2022-07-12T07:01:25.959018Z","iopub.execute_input":"2022-07-12T07:01:25.959271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*NO.2*","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.layers import Activation, Conv2D, MaxPooling2D, Dense, Flatten, Dropout, BatchNormalization\nmodel2 = tf.keras.Sequential()\n\n#Block 1:\nmodel2.add(Conv2D(64,(3,3),padding='same',kernel_initializer='he_normal',input_shape=(48,48,3)))\nmodel2.add(Activation('relu'))\nmodel2.add(BatchNormalization())\n# model2.add(Conv2D(64,(3,3),padding='same',kernel_initializer='he_normal'))\n# model2.add(Activation('relu'))\n# model2.add(BatchNormalization())\nmodel2.add(MaxPooling2D(pool_size=(2,2)))\nmodel2.add(Dropout(0.65))\n\n#Block 2:\nmodel2.add(Conv2D(256,(3,3),padding='same',kernel_initializer='he_normal'))\nmodel2.add(Activation('relu'))\nmodel2.add(BatchNormalization())\n# model2.add(Conv2D(256,(3,3),padding='same',kernel_initializer='he_normal'))\n# model2.add(Activation('relu'))\n# model2.add(BatchNormalization())\nmodel2.add(MaxPooling2D(pool_size=(2,2)))\nmodel2.add(Dropout(0.65))\n\n# #block 3:\nmodel2.add(Conv2D(512,(3,3),padding='same',kernel_initializer='he_normal'))\nmodel2.add(Activation('relu'))\nmodel2.add(BatchNormalization())\nmodel2.add(MaxPooling2D(pool_size=(2,2)))\nmodel2.add(Dropout(0.65))\n\n\nmodel2.add(Flatten())\nmodel2.add(Dense(1024,kernel_initializer='he_normal'))\nmodel2.add(Activation('relu'))\nmodel2.add(BatchNormalization())\nmodel.add(Dropout(0.65))\n\n\nmodel2.add(Dense(1024,kernel_initializer='he_normal'))\nmodel2.add(Activation('relu'))\nmodel2.add(BatchNormalization())\nmodel2.add(Dropout(0.65))\n\n\nmodel2.add(Dense(7,kernel_initializer='he_normal'))\nmodel2.add(Activation('softmax'))\n\nmodel2.summary()","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.926161Z","iopub.status.idle":"2022-07-11T20:20:07.926944Z","shell.execute_reply.started":"2022-07-11T20:20:07.926627Z","shell.execute_reply":"2022-07-11T20:20:07.926659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"opt = keras.optimizers.Adam(learning_rate=0.00010000000474974513)\nmodel2.compile(\n  loss='categorical_crossentropy',\n  optimizer=opt,\n  metrics=['accuracy']\n)\n","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.928256Z","iopub.status.idle":"2022-07-11T20:20:07.928948Z","shell.execute_reply.started":"2022-07-11T20:20:07.928687Z","shell.execute_reply":"2022-07-11T20:20:07.928716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model2.fit(images[736:] , labels[736:] , batch_size=32 , epochs=50 , validation_data = (images[:245] , labels[:245]))","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.930246Z","iopub.status.idle":"2022-07-11T20:20:07.930906Z","shell.execute_reply.started":"2022-07-11T20:20:07.930660Z","shell.execute_reply":"2022-07-11T20:20:07.930686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['loss'], label='train loss')\nplt.plot(history.history['val_loss'], label='val loss')\nplt.legend()\nplt.show()\n# plt.savefig('LossVal_loss_DenseNet201')\n\n# plot the accuracy\nplt.plot(history.history['accuracy'], label='train acc')\nplt.plot(history.history['val_accuracy'], label='val acc')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.932202Z","iopub.status.idle":"2022-07-11T20:20:07.932929Z","shell.execute_reply.started":"2022-07-11T20:20:07.932664Z","shell.execute_reply":"2022-07-11T20:20:07.932690Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Augmentation\n","metadata":{}},{"cell_type":"code","source":"datagen =  ImageDataGenerator(\n  #preprocessing_function=preprocess_input,\n  rotation_range=30,\n  width_shift_range=0.2,\n  height_shift_range=0.2,\n  shear_range=0.2,\n  zoom_range=0.2,\n  horizontal_flip=True\n)","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.934284Z","iopub.status.idle":"2022-07-11T20:20:07.934998Z","shell.execute_reply.started":"2022-07-11T20:20:07.934728Z","shell.execute_reply":"2022-07-11T20:20:07.934756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"aug = ImageDataGenerator(rotation_range=45, width_shift_range=0.2,\n                        height_shift_range=0.2, horizontal_flip = False,\n                        fill_mode='nearrest')","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.936297Z","iopub.status.idle":"2022-07-11T20:20:07.936976Z","shell.execute_reply.started":"2022-07-11T20:20:07.936702Z","shell.execute_reply":"2022-07-11T20:20:07.936746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"aug.fit(images)\n","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.938256Z","iopub.status.idle":"2022-07-11T20:20:07.938901Z","shell.execute_reply.started":"2022-07-11T20:20:07.938674Z","shell.execute_reply":"2022-07-11T20:20:07.938699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(images , labels, batch_size=32 , epochs=60 , validation_data = (t_images , t_labels))","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.940158Z","iopub.status.idle":"2022-07-11T20:20:07.940831Z","shell.execute_reply.started":"2022-07-11T20:20:07.940584Z","shell.execute_reply":"2022-07-11T20:20:07.940610Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### VGG16\n\n","metadata":{}},{"cell_type":"code","source":"model = keras.Sequential([\n# Data Augmentation \n  \n\n  VGG16(weights='imagenet',include_top=False, classes=6, input_shape=(64,64,3)), #Extract features \n\n  layers.BatchNormalization(),\n\n\n#CNN layer \n\n  layers.Conv2D(64,(3,3),padding = 'same'), \n  layers.BatchNormalization(),\n  layers.LeakyReLU(alpha=0.1),\n  layers.MaxPooling2D(pool_size = (2,2),padding = 'same'), \n  layers.Dropout(0.65), \n    \n#    layers.Conv2D(128,(3,3),padding = 'same'), \n#   layers.BatchNormalization(),\n#   layers.LeakyReLU(alpha=0.1),\n#   layers.MaxPooling2D(pool_size = (2,2),padding = 'same'), \n#   layers.Dropout(0.65),\n    \n#  layers.Conv2D(512,(3,3),padding = 'same'), \n#  layers.BatchNormalization(),\n#  layers.LeakyReLU(alpha=0.1),\n#  layers.MaxPooling2D(pool_size = (2,2),padding = 'same'), \n#  layers.Dropout(0.65), \n    \n layers.Flatten(),\n#Fully connected 1st layer \n\n  layers.Dense(1000),\n  layers.BatchNormalization(), \n  layers.Activation('relu'), \n  layers.Dropout(0.65), \n\n# Fully connected layer 2nd layer\n\n#   layers.Dense(128),\n#   layers.BatchNormalization(), \n#   layers.Activation('relu'), \n#   layers.Dropout(0.5), \n\n\n  layers.Dense(6, activation='softmax'),\n                          \n])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.942129Z","iopub.status.idle":"2022-07-11T20:20:07.942792Z","shell.execute_reply.started":"2022-07-11T20:20:07.942546Z","shell.execute_reply":"2022-07-11T20:20:07.942572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model.trainable = False\n# dropout1 = Dropout(0.5)\n# x = Flatten()(model.output)\n# x= x = dropout1(model.output)\n# prediction = Dense(6, activation='softmax')(x)\n# model = Model(inputs=model.input, outputs=prediction)","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.944001Z","iopub.status.idle":"2022-07-11T20:20:07.944772Z","shell.execute_reply.started":"2022-07-11T20:20:07.944502Z","shell.execute_reply":"2022-07-11T20:20:07.944531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# opt = keras.optimizers.Adam(learning_rate=0.00010000000474974513)\nopt = keras.optimizers.Adam(learning_rate=1e-7)\nmodel.compile(\n  loss='categorical_crossentropy',\n  optimizer=opt,\n  metrics=['accuracy']\n)\n","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.946018Z","iopub.status.idle":"2022-07-11T20:20:07.946673Z","shell.execute_reply.started":"2022-07-11T20:20:07.946438Z","shell.execute_reply":"2022-07-11T20:20:07.946462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(images , labels, batch_size=128 , epochs=30 , validation_data = (t_images , t_labels))","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.947908Z","iopub.status.idle":"2022-07-11T20:20:07.948580Z","shell.execute_reply.started":"2022-07-11T20:20:07.948333Z","shell.execute_reply":"2022-07-11T20:20:07.948361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['loss'], label='train loss')\nplt.plot(history.history['val_loss'], label='val loss')\nplt.legend()\nplt.show()\n# plt.savefig('LossVal_loss_DenseNet201')\n\n# plot the accuracy\nplt.plot(history.history['accuracy'], label='train acc')\nplt.plot(history.history['val_accuracy'], label='val acc')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.949784Z","iopub.status.idle":"2022-07-11T20:20:07.950417Z","shell.execute_reply.started":"2022-07-11T20:20:07.950157Z","shell.execute_reply":"2022-07-11T20:20:07.950182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### NASNetLarge","metadata":{}},{"cell_type":"code","source":"nas = NASNetLarge(\n    input_shape=(64,64,3),\n    include_top=True,\n#     weights=\"imagenet\",\n    pooling='max',\n#     classes=6\n)","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.951774Z","iopub.status.idle":"2022-07-11T20:20:07.952497Z","shell.execute_reply.started":"2022-07-11T20:20:07.952205Z","shell.execute_reply":"2022-07-11T20:20:07.952233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nas.trainable = False\nx = Flatten()(nas.output)\nprediction = Dense(7, activation='softmax')(x)\n\n# create a model object\nnas = Model(inputs=nas.input, outputs=prediction)","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.953907Z","iopub.status.idle":"2022-07-11T20:20:07.954590Z","shell.execute_reply.started":"2022-07-11T20:20:07.954355Z","shell.execute_reply":"2022-07-11T20:20:07.954380Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"opt = keras.optimizers.Adam(learning_rate=0.00010000000474974513)\nnas.compile(\n  loss='categorical_crossentropy',\n  optimizer=opt,\n  metrics=['accuracy']\n)\nhistory = nas.fit(images , labels, batch_size=32 , epochs=30 , validation_data = (t_images , t_labels))","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.955784Z","iopub.status.idle":"2022-07-11T20:20:07.956420Z","shell.execute_reply.started":"2022-07-11T20:20:07.956161Z","shell.execute_reply":"2022-07-11T20:20:07.956185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### efficientNet B0","metadata":{}},{"cell_type":"code","source":"ef_b0 = tf.keras.applications.EfficientNetB0(input_shape= (48,48,3) , include_top=False , weights=\"imagenet\", pooling='max')","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.957781Z","iopub.status.idle":"2022-07-11T20:20:07.958410Z","shell.execute_reply.started":"2022-07-11T20:20:07.958156Z","shell.execute_reply":"2022-07-11T20:20:07.958181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ef_b0.trainable = False\nx = Flatten()(ef_b0.output)\nprediction = Dense(6, activation='softmax')(x)\n\n# create a model object\nef_b0 = Model(inputs=ef_b0.input, outputs=prediction)\n\n# learning rate \nopt = keras.optimizers.Adam(learning_rate=0.00010000000474974513)\nef_b0.compile(\n  loss='categorical_crossentropy',\n  optimizer=opt,\n  metrics=['accuracy']\n)","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.959594Z","iopub.status.idle":"2022-07-11T20:20:07.960203Z","shell.execute_reply.started":"2022-07-11T20:20:07.959972Z","shell.execute_reply":"2022-07-11T20:20:07.959996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"r = ef_b0.fit(images[736:] , labels[736:] , batch_size=32 , epochs=50 , validation_data = (images[:245] , labels[:245]))","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.961464Z","iopub.status.idle":"2022-07-11T20:20:07.962141Z","shell.execute_reply.started":"2022-07-11T20:20:07.961895Z","shell.execute_reply":"2022-07-11T20:20:07.961921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(r.history['loss'], label='train loss')\nplt.plot(r.history['val_loss'], label='val loss')\nplt.legend()\nplt.show()\n# plt.savefig('LossVal_loss_DenseNet201')\n\n# plot the accuracy\nplt.plot(r.history['accuracy'], label='train acc')\nplt.plot(r.history['val_accuracy'], label='val acc')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.963401Z","iopub.status.idle":"2022-07-11T20:20:07.964012Z","shell.execute_reply.started":"2022-07-11T20:20:07.963781Z","shell.execute_reply":"2022-07-11T20:20:07.963805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### edit version\n","metadata":{}},{"cell_type":"code","source":"model = keras.Sequential([\n# Data Augmentation \n  \n tf.keras.applications.EfficientNetB0(weights='imagenet',include_top=False, classes=7, input_shape=(48,48,3)),\n# Data Augmentation \n  \n\n#   DenseNet121(weights='imagenet',include_top=False, classes=7, input_shape=(48,48,3)), #Extract features \n\n  layers.BatchNormalization(),\n\n#CNN layer \n\n  layers.Conv2D(256,(3,3),padding = 'same'), \n  layers.BatchNormalization(),\n  layers.LeakyReLU(alpha=0.1),\n  layers.MaxPooling2D(pool_size = (2,2),padding = 'same'), \n  layers.Dropout(0.5), \n\n\n  layers.Flatten(),\n#Fully connected 1st layer \n\n  layers.Dense(16),\n  layers.BatchNormalization(), \n  layers.Activation('relu'), \n  layers.Dropout(0.65), \n\n# Fully connected layer 2nd layer\n\n#   layers.Dense(128),\n#   layers.BatchNormalization(), \n#   layers.Activation('relu'), \n#   layers.Dropout(0.5), \n\n\n  layers.Dense(7, activation='softmax'),\n                          \n])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-07-12T17:53:17.018579Z","iopub.execute_input":"2022-07-12T17:53:17.019109Z","iopub.status.idle":"2022-07-12T17:53:19.042130Z","shell.execute_reply.started":"2022-07-12T17:53:17.019070Z","shell.execute_reply":"2022-07-12T17:53:19.040575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"opt = keras.optimizers.Adam(learning_rate=0.00010000000474974513)\nmodel.compile(\n  loss='categorical_crossentropy',\n  optimizer=opt,\n  metrics=['accuracy']\n)\nr = model.fit(images , labels , batch_size=32 , epochs=30 , validation_data = (t_images , t_labels))","metadata":{"execution":{"iopub.status.busy":"2022-07-12T17:53:19.045340Z","iopub.execute_input":"2022-07-12T17:53:19.045774Z","iopub.status.idle":"2022-07-12T18:20:42.786059Z","shell.execute_reply.started":"2022-07-12T17:53:19.045736Z","shell.execute_reply":"2022-07-12T18:20:42.785216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(r.history['loss'], label='train loss')\nplt.plot(r.history['val_loss'], label='val loss')\nplt.legend()\nplt.show()\n# plt.savefig('LossVal_loss_DenseNet201')\n\n# plot the accuracy\nplt.plot(r.history['accuracy'], label='train acc')\nplt.plot(r.history['val_accuracy'], label='val acc')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-12T18:20:42.788249Z","iopub.execute_input":"2022-07-12T18:20:42.788668Z","iopub.status.idle":"2022-07-12T18:20:43.253724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"r = model.fit(images , labels , batch_size=16 , epochs=30 , validation_data = (t_images , t_labels))","metadata":{"execution":{"iopub.status.busy":"2022-07-12T18:27:56.647580Z","iopub.execute_input":"2022-07-12T18:27:56.648120Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(r.history['loss'], label='train loss')\nplt.plot(r.history['val_loss'], label='val loss')\nplt.legend()\nplt.show()\n# plt.savefig('LossVal_loss_DenseNet201')\n\n# plot the accuracy\nplt.plot(r.history['accuracy'], label='train acc')\nplt.plot(r.history['val_accuracy'], label='val acc')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-12T18:26:45.979849Z","iopub.status.idle":"2022-07-12T18:26:45.981336Z","shell.execute_reply.started":"2022-07-12T18:26:45.981083Z","shell.execute_reply":"2022-07-12T18:26:45.981108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ef_b1 = tf.keras.applications.EfficientNetB1(input_shape= (48,48,3) , include_top=False , weights=\"imagenet\", pooling='max')\n\n################## B1\n\nef_b1.trainable = False\nx = Flatten()(ef_b1.output)\nprediction = Dense(6, activation='softmax')(x)\n\n# create a model object\nef_b1 = Model(inputs=ef_b1.input, outputs=prediction)\n\n# learning rate \nopt = keras.optimizers.Adam(learning_rate=0.00010000000474974513)\nef_b1.compile(\n  loss='categorical_crossentropy',\n  optimizer=opt,\n  metrics=['accuracy']\n)","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.972696Z","iopub.status.idle":"2022-07-11T20:20:07.973366Z","shell.execute_reply.started":"2022-07-11T20:20:07.973100Z","shell.execute_reply":"2022-07-11T20:20:07.973135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"r = ef_b1.fit(images[736:] , labels[736:] , batch_size=32 , epochs=50 , validation_data = (images[:245] , labels[:245]))","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.974542Z","iopub.status.idle":"2022-07-11T20:20:07.975194Z","shell.execute_reply.started":"2022-07-11T20:20:07.974947Z","shell.execute_reply":"2022-07-11T20:20:07.974974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(r.history['loss'], label='train loss')\nplt.plot(r.history['val_loss'], label='val loss')\nplt.legend()\nplt.show()\n# plt.savefig('LossVal_loss_DenseNet201')\n\n# plot the accuracy\nplt.plot(r.history['accuracy'], label='train acc')\nplt.plot(r.history['val_accuracy'], label='val acc')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.976464Z","iopub.status.idle":"2022-07-11T20:20:07.977101Z","shell.execute_reply.started":"2022-07-11T20:20:07.976843Z","shell.execute_reply":"2022-07-11T20:20:07.976886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### EfficentNet B2","metadata":{}},{"cell_type":"code","source":"ef_b2 = tf.keras.applications.EfficientNetB2(input_shape= (48,48,3) , include_top=False , weights=\"imagenet\", pooling='max')\n\n################## B1\n\nef_b2.trainable = False\nx = Flatten()(ef_b2.output)\nprediction = Dense(6, activation='softmax')(x)\n\n# create a model object\nef_b2 = Model(inputs=ef_b2.input, outputs=prediction)\n\n# learning rate \nopt = keras.optimizers.Adam(learning_rate=0.00010000000474974513)\nef_b2.compile(\n  loss='categorical_crossentropy',\n  optimizer=opt,\n  metrics=['accuracy']\n)","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.978351Z","iopub.status.idle":"2022-07-11T20:20:07.978976Z","shell.execute_reply.started":"2022-07-11T20:20:07.978742Z","shell.execute_reply":"2022-07-11T20:20:07.978767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"r = ef_b2.fit(images , labels , batch_size=32 , epochs=50 , validation_data = (t_images , t_labels))","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.980177Z","iopub.status.idle":"2022-07-11T20:20:07.980868Z","shell.execute_reply.started":"2022-07-11T20:20:07.980632Z","shell.execute_reply":"2022-07-11T20:20:07.980658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(r.history['loss'], label='train loss')\nplt.plot(r.history['val_loss'], label='val loss')\nplt.legend()\nplt.show()\n# plt.savefig('LossVal_loss_DenseNet201')\n\n# plot the accuracy\nplt.plot(r.history['accuracy'], label='train acc')\nplt.plot(r.history['val_accuracy'], label='val acc')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.982118Z","iopub.status.idle":"2022-07-11T20:20:07.982800Z","shell.execute_reply.started":"2022-07-11T20:20:07.982551Z","shell.execute_reply":"2022-07-11T20:20:07.982577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ef_b3 = tf.keras.applications.EfficientNetB3(input_shape= (48,48,3) , include_top=False , weights=\"imagenet\", pooling='max')\n\n################## B1\n\nef_b3.trainable = False\nx = Flatten()(ef_b3.output)\nprediction = Dense(6, activation='softmax')(x)\n\n# create a model object\nef_b3 = Model(inputs=ef_b3.input, outputs=prediction)\n\n# learning rate \nopt = keras.optimizers.Adam(learning_rate=0.00010000000474974513)\nef_b3.compile(\n  loss='categorical_crossentropy',\n  optimizer=opt,\n  metrics=['accuracy']\n)","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.984046Z","iopub.status.idle":"2022-07-11T20:20:07.984712Z","shell.execute_reply.started":"2022-07-11T20:20:07.984480Z","shell.execute_reply":"2022-07-11T20:20:07.984505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"r = ef_b3.fit(images , labels , batch_size=32 , epochs=50 , validation_data = (t_images , t_labels))","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.986040Z","iopub.status.idle":"2022-07-11T20:20:07.986751Z","shell.execute_reply.started":"2022-07-11T20:20:07.986486Z","shell.execute_reply":"2022-07-11T20:20:07.986512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## DeepFace","metadata":{}},{"cell_type":"code","source":"!pip install deepface\n","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.988008Z","iopub.status.idle":"2022-07-11T20:20:07.988700Z","shell.execute_reply.started":"2022-07-11T20:20:07.988460Z","shell.execute_reply":"2022-07-11T20:20:07.988486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from deepface import DeepFace\n","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.989954Z","iopub.status.idle":"2022-07-11T20:20:07.990603Z","shell.execute_reply.started":"2022-07-11T20:20:07.990368Z","shell.execute_reply":"2022-07-11T20:20:07.990394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"face_analysis = DeepFace.analyze(img_path = \"../input/emotion-detection-fer/train/neutral/im1026.png\")\n","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.991858Z","iopub.status.idle":"2022-07-11T20:20:07.992561Z","shell.execute_reply.started":"2022-07-11T20:20:07.992312Z","shell.execute_reply":"2022-07-11T20:20:07.992339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"face_analysis","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.993823Z","iopub.status.idle":"2022-07-11T20:20:07.994498Z","shell.execute_reply.started":"2022-07-11T20:20:07.994229Z","shell.execute_reply":"2022-07-11T20:20:07.994269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}