{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from keras.datasets import mnist\nfrom keras.layers import Input, Dense, Reshape, Flatten\nfrom keras.layers import BatchNormalization\nfrom keras.layers.advanced_activations import LeakyReLU\nfrom keras.models import Sequential, Model\nfrom tensorflow.keras.optimizers import Adam # - Works\nimport matplotlib.pyplot as plt\nimport numpy as np\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-08-12T10:56:38.379235Z","iopub.execute_input":"2022-08-12T10:56:38.379698Z","iopub.status.idle":"2022-08-12T10:56:38.386301Z","shell.execute_reply.started":"2022-08-12T10:56:38.379650Z","shell.execute_reply":"2022-08-12T10:56:38.385109Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"imagetype= os.listdir(\"../input/fer2013/train/disgust\")\n# imagetype","metadata":{"execution":{"iopub.status.busy":"2022-08-12T10:56:39.799967Z","iopub.execute_input":"2022-08-12T10:56:39.800387Z","iopub.status.idle":"2022-08-12T10:56:39.811059Z","shell.execute_reply.started":"2022-08-12T10:56:39.800351Z","shell.execute_reply":"2022-08-12T10:56:39.809988Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"train_images = []\nfor i in imagetype: \n    image = cv2.imread(\"../input/fer2013/train/disgust\"+'/'+i)\n#     grayscale = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    train_images.append(image)\n# plt.imshow(image)","metadata":{"execution":{"iopub.status.busy":"2022-08-12T10:56:46.168963Z","iopub.execute_input":"2022-08-12T10:56:46.169733Z","iopub.status.idle":"2022-08-12T10:56:46.582268Z","shell.execute_reply.started":"2022-08-12T10:56:46.169692Z","shell.execute_reply":"2022-08-12T10:56:46.581029Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"img_rows = 48\nimg_cols = 48\nchannels = 3\nimg_shape = (img_rows, img_cols, channels)\ntrain_images = np.array(train_images)\nX_train = train_images.reshape(train_images.shape[0], 48,48,3).astype('float32')\nX_train = (X_train - 127.5) / 127.5 ","metadata":{"execution":{"iopub.status.busy":"2022-08-12T10:57:34.784033Z","iopub.execute_input":"2022-08-12T10:57:34.784871Z","iopub.status.idle":"2022-08-12T10:57:34.802921Z","shell.execute_reply.started":"2022-08-12T10:57:34.784827Z","shell.execute_reply":"2022-08-12T10:57:34.801715Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"X_train.shape","metadata":{"execution":{"iopub.status.busy":"2022-08-12T10:57:43.919925Z","iopub.execute_input":"2022-08-12T10:57:43.920365Z","iopub.status.idle":"2022-08-12T10:57:43.927597Z","shell.execute_reply.started":"2022-08-12T10:57:43.920316Z","shell.execute_reply":"2022-08-12T10:57:43.926624Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"for i in range(25):\n\t# define subplot\n\tplt.subplot(5, 5, 1 + i)\n\t# turn off axis\n\tplt.axis('off')\n\t# plot raw pixel data\n\tplt.imshow(train_images[i], cmap='gray_r')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-12T10:31:17.320177Z","iopub.execute_input":"2022-08-12T10:31:17.320613Z","iopub.status.idle":"2022-08-12T10:31:18.306549Z","shell.execute_reply.started":"2022-08-12T10:31:17.320573Z","shell.execute_reply":"2022-08-12T10:31:18.305379Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def build_generator():\n\n    noise_shape = (100,) #1D array of size 100 (latent vector / noise)\n\n#Define your generator network \n#Here we are only using Dense layers. But network can be complicated based\n#on the application. For example, you can use VGG for super res. GAN.         \n\n    model = Sequential()\n\n    model.add(Dense(256, input_shape=noise_shape))\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(BatchNormalization(momentum=0.8))\n    model.add(Dense(512))\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(BatchNormalization(momentum=0.8))\n    model.add(Dense(1024))\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(BatchNormalization(momentum=0.8))\n    \n    model.add(Dense(np.prod(img_shape), activation='tanh'))\n    model.add(Reshape(img_shape))\n\n    model.summary()\n\n    noise = Input(shape=noise_shape)\n    img = model(noise)    #Generated image\n\n    return Model(noise, img)","metadata":{"execution":{"iopub.status.busy":"2022-08-12T10:57:48.490509Z","iopub.execute_input":"2022-08-12T10:57:48.491589Z","iopub.status.idle":"2022-08-12T10:57:48.502153Z","shell.execute_reply.started":"2022-08-12T10:57:48.491534Z","shell.execute_reply":"2022-08-12T10:57:48.501002Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"def build_discriminator():\n\n\n    model = Sequential()\n\n    model.add(Flatten(input_shape=img_shape))\n    model.add(Dense(512))\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(Dense(256))\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(Dense(1, activation='sigmoid'))\n    model.summary()\n\n    img = Input(shape=img_shape)\n    validity = model(img)\n\n    return Model(img, validity)","metadata":{"execution":{"iopub.status.busy":"2022-08-12T10:57:54.748689Z","iopub.execute_input":"2022-08-12T10:57:54.749119Z","iopub.status.idle":"2022-08-12T10:57:54.756977Z","shell.execute_reply.started":"2022-08-12T10:57:54.749081Z","shell.execute_reply":"2022-08-12T10:57:54.755659Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"# (X_train, _), (_, _) = mnist.load_data()\n# X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n# X_train = np.expand_dims(X_train, axis=3) \n# X_train.shape","metadata":{"execution":{"iopub.status.busy":"2022-08-12T10:41:38.289603Z","iopub.execute_input":"2022-08-12T10:41:38.290029Z","iopub.status.idle":"2022-08-12T10:41:38.742356Z","shell.execute_reply.started":"2022-08-12T10:41:38.289993Z","shell.execute_reply":"2022-08-12T10:41:38.740078Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"def train(epochs, batch_size=128, save_interval=50):\n\n    # Load the dataset\n#     (X_train, _), (_, _) = mnist.load_data()\n\n#     # Convert to float and Rescale -1 to 1 (Can also do 0 to 1)\n#     X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n\n# #Add channels dimension. As the input to our gen and discr. has a shape 28x28x1.\n#     X_train = np.expand_dims(X_train, axis=3) \n\n    half_batch = int(batch_size / 2)\n\n\n#We then loop through a number of epochs to train our Discriminator by first selecting\n#a random batch of images from our true dataset, generating a set of images from our\n#Generator, feeding both set of images into our Discriminator, and finally setting the\n#loss parameters for both the real and fake images, as well as the combined loss. \n    \n    for epoch in range(epochs):\n\n        # ---------------------\n        #  Train Discriminator\n        # ---------------------\n\n        # Select a random half batch of real images\n        idx = np.random.randint(0, X_train.shape[0], half_batch)\n        imgs = X_train[idx]\n\n \n        noise = np.random.normal(0, 1, (half_batch, 100))\n\n        # Generate a half batch of fake images\n        gen_imgs = generator.predict(noise)\n\n        # Train the discriminator on real and fake images, separately\n        #Research showed that separate training is more effective. \n        d_loss_real = discriminator.train_on_batch(imgs, np.ones((half_batch, 1)))\n        d_loss_fake = discriminator.train_on_batch(gen_imgs, np.zeros((half_batch, 1)))\n    #take average loss from real and fake images. \n    #\n        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake) \n\n#And within the same loop we train our Generator, by setting the input noise and\n#ultimately training the Generator to have the Discriminator label its samples as valid\n#by specifying the gradient loss.\n        # ---------------------\n        #  Train Generator\n        # ---------------------\n#Create noise vectors as input for generator. \n#Create as many noise vectors as defined by the batch size. \n#Based on normal distribution. Output will be of size (batch size, 100)\n        noise = np.random.normal(0, 1, (batch_size, 100)) \n\n        # The generator wants the discriminator to label the generated samples\n        # as valid (ones)\n        #This is where the genrator is trying to trick discriminator into believing\n        #the generated image is true (hence value of 1 for y)\n        valid_y = np.array([1] * batch_size) #Creates an array of all ones of size=batch size\n\n        # Generator is part of combined where it got directly linked with the discriminator\n        # Train the generator with noise as x and 1 as y. \n        # Again, 1 as the output as it is adversarial and if generator did a great\n        #job of folling the discriminator then the output would be 1 (true)\n        g_loss = combined.train_on_batch(noise, valid_y)\n\n\n#Additionally, in order for us to keep track of our training process, we print the\n#progress and save the sample image output depending on the epoch interval specified.  \n# Plot the progress\n        \n        print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n\n        # If at save interval => save generated image samples\n        if epoch % save_interval == 0:\n            save_imgs(epoch)\n\n#when the specific sample_interval is hit, we call the\n#sample_image function. Which looks as follows.","metadata":{"execution":{"iopub.status.busy":"2022-08-12T10:58:15.153808Z","iopub.execute_input":"2022-08-12T10:58:15.154233Z","iopub.status.idle":"2022-08-12T10:58:15.167119Z","shell.execute_reply.started":"2022-08-12T10:58:15.154195Z","shell.execute_reply":"2022-08-12T10:58:15.165525Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"def save_imgs(epoch):\n    r, c = 5, 5\n    noise = np.random.normal(0, 1, (r * c, 100))\n    gen_imgs = generator.predict(noise)\n\n    # Rescale images 0 - 1\n    gen_imgs = 0.5 * gen_imgs + 0.5\n\n    fig, axs = plt.subplots(r, c)\n    cnt = 0\n    for i in range(r):\n        for j in range(c):\n            axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n            axs[i,j].axis('off')\n            cnt += 1\n    fig.savefig(\"./natural_%d.png\" % epoch)\n    plt.close()\n#This function saves our images for us to view\n\n\n##############################################################################\n\n#Let us also define our optimizer for easy use later on.\n#That way if you change your mind, you can change it easily here\noptimizer = Adam(0.0002, 0.5)  #Learning rate and momentum.\n\n# Build and compile the discriminator first. \n#Generator will be trained as part of the combined model, later. \n#pick the loss function and the type of metric to keep track.                 \n#Binary cross entropy as we are doing prediction and it is a better\n#loss function compared to MSE or other. \ndiscriminator = build_discriminator()\ndiscriminator.compile(loss='binary_crossentropy',\n    optimizer=optimizer,\n    metrics=['accuracy'])\n\n#build and compile our Discriminator, pick the loss function\n\n#SInce we are only generating (faking) images, let us not track any metrics.\ngenerator = build_generator()\ngenerator.compile(loss='binary_crossentropy', optimizer=optimizer)\n\n##This builds the Generator and defines the input noise. \n#In a GAN the Generator network takes noise z as an input to produce its images.  \nz = Input(shape=(100,))   #Our random input to the generator\nimg = generator(z)\n\n#This ensures that when we combine our networks we only train the Generator.\n#While generator training we do not want discriminator weights to be adjusted. \n#This Doesn't affect the above descriminator training.     \ndiscriminator.trainable = False  \n\n#This specifies that our Discriminator will take the images generated by our Generator\n#and true dataset and set its output to a parameter called valid, which will indicate\n#whether the input is real or not.  \nvalid = discriminator(img)  #Validity check on the generated image\n\n\n#Here we combined the models and also set our loss function and optimizer. \n#Again, we are only training the generator here. \n#The ultimate goal here is for the Generator to fool the Discriminator.  \n# The combined model  (stacked generator and discriminator) takes\n# noise as input => generates images => determines validity\n\ncombined = Model(z, valid)\ncombined.compile(loss='binary_crossentropy', optimizer=optimizer)\n\n\ntrain(epochs=50000, batch_size=32, save_interval=1000)\n\n#Save model for future use to generate fake images\n#Not tested yet... make sure right model is being saved..\n#Compare with GAN4\n\ngenerator.save('generator_model.h5')  #Test the model on GAN4_predict...\n#Change epochs back to 30K\n                \n#Epochs dictate the number of backward and forward propagations, the batch_size\n#indicates the number of training samples per backward/forward propagation, and the\n#sample_interval specifies after how many epochs we call our sample_image function.\nFooter","metadata":{"execution":{"iopub.status.busy":"2022-08-12T11:00:28.492630Z","iopub.execute_input":"2022-08-12T11:00:28.493575Z","iopub.status.idle":"2022-08-12T12:56:09.209268Z","shell.execute_reply.started":"2022-08-12T11:00:28.493532Z","shell.execute_reply":"2022-08-12T12:56:09.207512Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}