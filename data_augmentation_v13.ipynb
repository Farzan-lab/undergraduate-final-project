{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### import libs\n","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport tensorflow as tf\nimport tensorflow.keras as k\n\nimport csv\nimport cv2\nimport os\n\nfrom tensorflow.keras.layers import Input, Lambda, Dense, Flatten\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.applications.densenet import DenseNet201 ,DenseNet121\nfrom tensorflow.keras.applications.mobilenet import MobileNet\nfrom tensorflow.keras.applications import VGG16,VGG19\nfrom tensorflow.keras.applications.densenet import preprocess_input\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\n\nfrom sklearn.utils import shuffle\nfrom sklearn.preprocessing import LabelEncoder , OneHotEncoder\nfrom sklearn.model_selection import train_test_split\n\nfrom scipy import ndimage","metadata":{"execution":{"iopub.status.busy":"2022-08-18T18:38:00.885312Z","iopub.execute_input":"2022-08-18T18:38:00.885729Z","iopub.status.idle":"2022-08-18T18:38:09.995421Z","shell.execute_reply.started":"2022-08-18T18:38:00.885686Z","shell.execute_reply":"2022-08-18T18:38:09.994172Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"imagetype= os.listdir(\"../input/fer2013/train\")\nimagetype","metadata":{"execution":{"iopub.status.busy":"2022-08-18T18:38:09.997498Z","iopub.execute_input":"2022-08-18T18:38:09.998122Z","iopub.status.idle":"2022-08-18T18:38:10.015220Z","shell.execute_reply.started":"2022-08-18T18:38:09.998082Z","shell.execute_reply":"2022-08-18T18:38:10.014006Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"test_imagetype= os.listdir(\"../input/fer2013/test\")\ntest_imagetype","metadata":{"execution":{"iopub.status.busy":"2022-08-18T18:38:10.018380Z","iopub.execute_input":"2022-08-18T18:38:10.018955Z","iopub.status.idle":"2022-08-18T18:38:10.032099Z","shell.execute_reply.started":"2022-08-18T18:38:10.018910Z","shell.execute_reply":"2022-08-18T18:38:10.030888Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# imagetype_affect= os.listdir(\"../input/affectnethq\")\n# imagetype_affect.remove('contempt')\n# imagetype_affect.remove('labels.csv')\n# imagetype_affect","metadata":{"execution":{"iopub.status.busy":"2022-08-18T18:38:10.035382Z","iopub.execute_input":"2022-08-18T18:38:10.036188Z","iopub.status.idle":"2022-08-18T18:38:10.040534Z","shell.execute_reply.started":"2022-08-18T18:38:10.036150Z","shell.execute_reply":"2022-08-18T18:38:10.039138Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"emotions_labels_dict = {\n   'surprise' : 0,\n    'fear': 1,\n    'neutral': 2,\n    'sad': 3,\n    'disgust': 4,\n    'happy' : 5,\n    'anger': 6,\n}","metadata":{"execution":{"iopub.status.busy":"2022-08-18T18:38:10.042506Z","iopub.execute_input":"2022-08-18T18:38:10.043009Z","iopub.status.idle":"2022-08-18T18:38:10.052584Z","shell.execute_reply.started":"2022-08-18T18:38:10.042964Z","shell.execute_reply":"2022-08-18T18:38:10.051441Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"images = []    #images for train list will store all images\nlabels= []\nt_images = []    #images for test list will store all images\nt_labels= []\npath_fer = \"../input/fer2013/train/\"\npath_affect = \"../input/affectnethq/\"\nt_path = \"../input/fer2013/test/\"\n","metadata":{"execution":{"iopub.status.busy":"2022-08-18T18:38:10.054213Z","iopub.execute_input":"2022-08-18T18:38:10.054855Z","iopub.status.idle":"2022-08-18T18:38:10.064398Z","shell.execute_reply.started":"2022-08-18T18:38:10.054801Z","shell.execute_reply":"2022-08-18T18:38:10.063019Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"## **FER13**","metadata":{}},{"cell_type":"markdown","source":"### *Load data*","metadata":{}},{"cell_type":"code","source":"for i in imagetype:\n    print(i)\n    flower_path=path_fer+str(i)\n    data_list=[j for j in os.listdir(flower_path) if j.endswith(\".jpg\") ]\n    counter=0\n    for data in data_list:\n#         if counter> 2390: break\n        img=cv2.imread(flower_path + '/'+ data)\n#         img = cv2.resize(img , (64,64))\n        images.append(img)\n        labels.append(i)\n        \n#     print(i)    \n#     flower_path1=path_affect+str(i)\n#     data_list1=[j for j in os.listdir(flower_path1) if j.endswith(\".jpg\") ]\n#     for data in data_list1:\n# #         if counter> 2390: break\n#         img=cv2.imread(flower_path + '/'+ data)\n#         img = cv2.resize(img , (48,48))\n#         images.append(img)\n#         labels.append(i)\n        \n        \nprint(\"total train images:\",len(images))\nprint(\"total train images:\",len(labels))\n","metadata":{"execution":{"iopub.status.busy":"2022-08-18T18:38:10.066012Z","iopub.execute_input":"2022-08-18T18:38:10.066972Z","iopub.status.idle":"2022-08-18T18:41:26.128336Z","shell.execute_reply.started":"2022-08-18T18:38:10.066926Z","shell.execute_reply":"2022-08-18T18:41:26.127051Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"for i in imagetype:\n    print(i)\n    flower_path=t_path+str(i)\n    test_data_list=[j for j in os.listdir(flower_path) if j.endswith(\".jpg\") ]\n    counter=0\n    for data in test_data_list:\n#         if counter> 2390: break\n        img=cv2.imread(flower_path + '/'+ data)\n#         img = cv2.resize(img , (64,64))\n        t_images.append(img)\n        t_labels.append(i)\nprint(\"total test images:\",len(t_images))\nprint(\"total test images:\",len(t_labels))","metadata":{"execution":{"iopub.status.busy":"2022-08-18T18:41:26.130694Z","iopub.execute_input":"2022-08-18T18:41:26.131248Z","iopub.status.idle":"2022-08-18T18:42:11.055979Z","shell.execute_reply.started":"2022-08-18T18:41:26.131212Z","shell.execute_reply":"2022-08-18T18:42:11.053722Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"type(images)","metadata":{"execution":{"iopub.status.busy":"2022-08-18T18:42:11.057372Z","iopub.execute_input":"2022-08-18T18:42:11.057718Z","iopub.status.idle":"2022-08-18T18:42:11.065548Z","shell.execute_reply.started":"2022-08-18T18:42:11.057687Z","shell.execute_reply":"2022-08-18T18:42:11.064329Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"encode= LabelEncoder()\nlabels=encode.fit_transform(labels)\nencode2= LabelEncoder()\nt_labels = encode2.fit_transform(t_labels)\nt_labels[1:10]","metadata":{"execution":{"iopub.status.busy":"2022-08-18T18:42:11.069283Z","iopub.execute_input":"2022-08-18T18:42:11.069792Z","iopub.status.idle":"2022-08-18T18:42:11.097325Z","shell.execute_reply.started":"2022-08-18T18:42:11.069757Z","shell.execute_reply":"2022-08-18T18:42:11.096060Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"labels=labels.reshape(-1,1)\nonehotencoder= OneHotEncoder()\nlabels=onehotencoder.fit_transform(labels)\nlabels=labels.toarray()\nlabels\nprint(\"train labels is ready!\")","metadata":{"execution":{"iopub.status.busy":"2022-08-18T18:42:11.098640Z","iopub.execute_input":"2022-08-18T18:42:11.098999Z","iopub.status.idle":"2022-08-18T18:42:11.109261Z","shell.execute_reply.started":"2022-08-18T18:42:11.098969Z","shell.execute_reply":"2022-08-18T18:42:11.107776Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"t_labels=t_labels.reshape(-1,1)\nonehotencoder= OneHotEncoder()\nt_labels=onehotencoder.fit_transform(t_labels)\nt_labels=t_labels.toarray()\nprint(\"test labels is ready!\")\nt_labels[:10]","metadata":{"execution":{"iopub.status.busy":"2022-08-18T18:42:11.111059Z","iopub.execute_input":"2022-08-18T18:42:11.111555Z","iopub.status.idle":"2022-08-18T18:42:11.125497Z","shell.execute_reply.started":"2022-08-18T18:42:11.111523Z","shell.execute_reply":"2022-08-18T18:42:11.124320Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"images=np.array(images)\nprint(images.shape)\nprint(labels.shape)","metadata":{"execution":{"iopub.status.busy":"2022-08-18T18:42:11.127000Z","iopub.execute_input":"2022-08-18T18:42:11.127357Z","iopub.status.idle":"2022-08-18T18:42:11.245563Z","shell.execute_reply.started":"2022-08-18T18:42:11.127326Z","shell.execute_reply":"2022-08-18T18:42:11.244225Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"t_images=np.array(t_images)\nprint(t_images.shape)\nprint(t_labels.shape)","metadata":{"execution":{"iopub.status.busy":"2022-08-18T18:42:11.247946Z","iopub.execute_input":"2022-08-18T18:42:11.248430Z","iopub.status.idle":"2022-08-18T18:42:11.274515Z","shell.execute_reply.started":"2022-08-18T18:42:11.248379Z","shell.execute_reply":"2022-08-18T18:42:11.273268Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"images = images/ 255\nt_images = t_images/ 255","metadata":{"execution":{"iopub.status.busy":"2022-08-18T18:42:11.276318Z","iopub.execute_input":"2022-08-18T18:42:11.276998Z","iopub.status.idle":"2022-08-18T18:42:12.130129Z","shell.execute_reply.started":"2022-08-18T18:42:11.276950Z","shell.execute_reply":"2022-08-18T18:42:12.128762Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"images,labels = shuffle(images, labels, random_state=1)\nt_images , t_labels =  shuffle(t_images, t_labels, random_state=1)","metadata":{"execution":{"iopub.status.busy":"2022-08-18T18:42:12.131481Z","iopub.execute_input":"2022-08-18T18:42:12.131861Z","iopub.status.idle":"2022-08-18T18:42:12.895301Z","shell.execute_reply.started":"2022-08-18T18:42:12.131826Z","shell.execute_reply":"2022-08-18T18:42:12.894046Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"plt.imshow(images[4])\nplt.xlabel(labels[4])","metadata":{"execution":{"iopub.status.busy":"2022-08-18T18:42:12.896842Z","iopub.execute_input":"2022-08-18T18:42:12.897902Z","iopub.status.idle":"2022-08-18T18:42:13.066640Z","shell.execute_reply.started":"2022-08-18T18:42:12.897862Z","shell.execute_reply":"2022-08-18T18:42:13.065311Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"## **CKPLUS**","metadata":{}},{"cell_type":"markdown","source":"### *load data*","metadata":{}},{"cell_type":"code","source":"for i in ck_imagetype:\n    print(i)\n    flower_path=ck_path+\"/\"+str(i)\n    data_list=[j for j in os.listdir(flower_path) if j.endswith(\".png\") ]\n    counter=0\n    for data in data_list:\n#         if counter> 2390: break\n        img=cv2.imread(flower_path + '/'+ data)\n#         img = cv2.resize(img , (64,64))\n        images.append(img)\n        labels.append(i)\n    \nprint(\"total train images:\",len(images))\nprint(\"total train images:\",len(labels))","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.878341Z","iopub.status.idle":"2022-07-11T20:20:07.879214Z","shell.execute_reply.started":"2022-07-11T20:20:07.878941Z","shell.execute_reply":"2022-07-11T20:20:07.878970Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"start encoding\", end=\" ---> \")\nencode= LabelEncoder()\nlabels=encode.fit_transform(labels)\nprint (\"encoding finished\")\nprint (\"start one hot encoding\", end=\" ---> \")\nlabels=labels.reshape(-1,1)\nonehotencoder= OneHotEncoder()\nlabels=onehotencoder.fit_transform(labels)\nlabels=labels.toarray()\nprint(\"one hot encoding finished\")\nimages=np.array(images)\nprint(\"images and list shapes:\")\nprint(\"images shape:\", end=\" \" )\nprint(images.shape)\nprint(\"labels shape:\", end=\" \" )\nprint(labels.shape)\n","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.880555Z","iopub.status.idle":"2022-07-11T20:20:07.881481Z","shell.execute_reply.started":"2022-07-11T20:20:07.881140Z","shell.execute_reply":"2022-07-11T20:20:07.881174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images,labels = shuffle(images, labels, random_state=10)\nplt.imshow(images[4])\nplt.xlabel(labels[4])","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.882864Z","iopub.status.idle":"2022-07-11T20:20:07.883837Z","shell.execute_reply.started":"2022-07-11T20:20:07.883581Z","shell.execute_reply":"2022-07-11T20:20:07.883607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### *DenseNet201*","metadata":{}},{"cell_type":"code","source":"DenseNet201 = DenseNet201(input_shape= (48,48,3) ,  include_top=False , weights=\"imagenet\", pooling='max')","metadata":{"execution":{"iopub.status.busy":"2022-08-18T18:42:27.673863Z","iopub.execute_input":"2022-08-18T18:42:27.674708Z","iopub.status.idle":"2022-08-18T18:42:52.658153Z","shell.execute_reply.started":"2022-08-18T18:42:27.674648Z","shell.execute_reply":"2022-08-18T18:42:52.655744Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"DenseNet201.trainable = False\nx = Flatten()(DenseNet201.output)\nprediction = Dense(6, activation='softmax')(x)\n\n# create a model object\nDenseNet201 = Model(inputs=DenseNet201.input, outputs=prediction)","metadata":{"execution":{"iopub.status.busy":"2022-08-18T18:42:52.660056Z","iopub.status.idle":"2022-08-18T18:42:52.660636Z","shell.execute_reply.started":"2022-08-18T18:42:52.660387Z","shell.execute_reply":"2022-08-18T18:42:52.660414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"opt = keras.optimizers.Adam(learning_rate=0.00010000000474974513)\nDenseNet201.compile(\n  loss='categorical_crossentropy',\n  optimizer=opt,\n  metrics=['accuracy']\n)","metadata":{"execution":{"iopub.status.busy":"2022-08-18T18:42:52.661985Z","iopub.status.idle":"2022-08-18T18:42:52.662474Z","shell.execute_reply.started":"2022-08-18T18:42:52.662252Z","shell.execute_reply":"2022-08-18T18:42:52.662274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"r = DenseNet201.fit(images , labels , batch_size=32 , epochs=50 , validation_data = (t_images , t_labels))","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.891071Z","iopub.status.idle":"2022-07-11T20:20:07.891788Z","shell.execute_reply.started":"2022-07-11T20:20:07.891523Z","shell.execute_reply":"2022-07-11T20:20:07.891551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(r.history['loss'], label='train loss')\nplt.plot(r.history['val_loss'], label='val loss')\nplt.legend()\nplt.show()\n# plt.savefig('LossVal_loss_DenseNet201')\n\n# plot the accuracy\nplt.plot(r.history['accuracy'], label='train acc')\nplt.plot(r.history['val_accuracy'], label='val acc')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.893108Z","iopub.status.idle":"2022-07-11T20:20:07.893789Z","shell.execute_reply.started":"2022-07-11T20:20:07.893539Z","shell.execute_reply":"2022-07-11T20:20:07.893565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### *MobileNet*","metadata":{}},{"cell_type":"code","source":"mobile = MobileNet(input_shape= (48,48,3) , dropout = 0.1 ,  include_top=False , weights=\"imagenet\", pooling='max')","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.895078Z","iopub.status.idle":"2022-07-11T20:20:07.895751Z","shell.execute_reply.started":"2022-07-11T20:20:07.895503Z","shell.execute_reply":"2022-07-11T20:20:07.895530Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mobile.trainable = False\nx = Flatten()(mobile.output)\nprediction = Dense(7, activation='softmax')(x)\nmobile = Model(inputs=mobile.input, outputs=prediction)","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.897000Z","iopub.status.idle":"2022-07-11T20:20:07.897699Z","shell.execute_reply.started":"2022-07-11T20:20:07.897424Z","shell.execute_reply":"2022-07-11T20:20:07.897450Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"opt = keras.optimizers.Adam(learning_rate=0.00010000000474974513)\nmobile.compile(\n  loss='categorical_crossentropy',\n  optimizer=opt,\n  metrics=['accuracy']\n)","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.899356Z","iopub.status.idle":"2022-07-11T20:20:07.900053Z","shell.execute_reply.started":"2022-07-11T20:20:07.899788Z","shell.execute_reply":"2022-07-11T20:20:07.899816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"r = mobile.fit(images[736:] , labels[736:] , batch_size=32 , epochs=50 , validation_data = (images[:245] , labels[:245]))","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.901338Z","iopub.status.idle":"2022-07-11T20:20:07.902050Z","shell.execute_reply.started":"2022-07-11T20:20:07.901732Z","shell.execute_reply":"2022-07-11T20:20:07.901812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(r.history['loss'], label='train loss')\nplt.plot(r.history['val_loss'], label='val loss')\nplt.legend()\nplt.show()\n# plt.savefig('LossVal_loss_DenseNet201')\n\n# plot the accuracy\nplt.plot(r.history['accuracy'], label='train acc')\nplt.plot(r.history['val_accuracy'], label='val acc')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.903476Z","iopub.status.idle":"2022-07-11T20:20:07.904187Z","shell.execute_reply.started":"2022-07-11T20:20:07.903916Z","shell.execute_reply":"2022-07-11T20:20:07.903944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### *VGG16*","metadata":{}},{"cell_type":"code","source":"vgg16 = VGG16(input_shape= (48,48,3) , include_top=False , weights=\"imagenet\", pooling='max')\n","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.905578Z","iopub.status.idle":"2022-07-11T20:20:07.906286Z","shell.execute_reply.started":"2022-07-11T20:20:07.906004Z","shell.execute_reply":"2022-07-11T20:20:07.906032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vgg16.trainable = True\nx = Flatten()(vgg16.output)\nprediction = Dense(7, activation='softmax')(x)\n\n# create a model object\nvgg16 = Model(inputs=vgg16.input, outputs=prediction)","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.907619Z","iopub.status.idle":"2022-07-11T20:20:07.908330Z","shell.execute_reply.started":"2022-07-11T20:20:07.908037Z","shell.execute_reply":"2022-07-11T20:20:07.908064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"opt = keras.optimizers.Adam(learning_rate=0.00010000000474974513)\nvgg16.compile(\n  loss='categorical_crossentropy',\n  optimizer=opt,\n  metrics=['accuracy']\n)","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.909643Z","iopub.status.idle":"2022-07-11T20:20:07.910364Z","shell.execute_reply.started":"2022-07-11T20:20:07.910067Z","shell.execute_reply":"2022-07-11T20:20:07.910095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"r = vgg16.fit(images[736:] , labels[736:] , batch_size=32 , epochs=50 , validation_data = (images[:245] , labels[:245]))","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.911684Z","iopub.status.idle":"2022-07-11T20:20:07.912389Z","shell.execute_reply.started":"2022-07-11T20:20:07.912101Z","shell.execute_reply":"2022-07-11T20:20:07.912128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(r.history['loss'], label='train loss')\nplt.plot(r.history['val_loss'], label='val loss')\nplt.legend()\nplt.show()\n# plt.savefig('LossVal_loss_DenseNet201')\n\n# plot the accuracy\nplt.plot(r.history['accuracy'], label='train acc')\nplt.plot(r.history['val_accuracy'], label='val acc')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.913691Z","iopub.status.idle":"2022-07-11T20:20:07.914399Z","shell.execute_reply.started":"2022-07-11T20:20:07.914111Z","shell.execute_reply":"2022-07-11T20:20:07.914137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# vgg16.save_weights('vgg16_ckplus.h5')\n# ","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.915716Z","iopub.status.idle":"2022-07-11T20:20:07.916434Z","shell.execute_reply.started":"2022-07-11T20:20:07.916145Z","shell.execute_reply":"2022-07-11T20:20:07.916173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **models**","metadata":{}},{"cell_type":"markdown","source":"*NO.1*","metadata":{}},{"cell_type":"code","source":"model = keras.Sequential([\n# Data Augmentation \n  \n\n  DenseNet121(weights='imagenet',include_top=False, classes=7, input_shape=(48,48,3)), #Extract features \n\n  layers.BatchNormalization(),\n\n\n#CNN layer \n\n  layers.Conv2D(128,(3,3),padding = 'same'), \n  layers.BatchNormalization(),\n  layers.LeakyReLU(alpha=0.1),\n  layers.MaxPooling2D(pool_size = (2,2),padding = 'same'), \n  layers.Dropout(0.5), \n\n\n  layers.Flatten(),\n#Fully connected 1st layer \n\n  layers.Dense(256),\n  layers.BatchNormalization(), \n  layers.Activation('relu'), \n  layers.Dropout(0.65), \n\n# Fully connected layer 2nd layer\n\n#   layers.Dense(128),\n#   layers.BatchNormalization(), \n#   layers.Activation('relu'), \n#   layers.Dropout(0.5), \n\n\n  layers.Dense(7, activation='softmax'),\n                          \n])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-07-12T12:28:09.182825Z","iopub.execute_input":"2022-07-12T12:28:09.183491Z","iopub.status.idle":"2022-07-12T12:28:15.851553Z","shell.execute_reply.started":"2022-07-12T12:28:09.183453Z","shell.execute_reply":"2022-07-12T12:28:15.850817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"opt = keras.optimizers.Adam(learning_rate=0.00010000000474974513)\nmodel.compile(\n  loss='categorical_crossentropy',\n  optimizer=opt,\n  metrics=['accuracy']\n)\n","metadata":{"execution":{"iopub.status.busy":"2022-07-12T12:28:22.357475Z","iopub.execute_input":"2022-07-12T12:28:22.358169Z","iopub.status.idle":"2022-07-12T12:28:22.380052Z","shell.execute_reply.started":"2022-07-12T12:28:22.358133Z","shell.execute_reply":"2022-07-12T12:28:22.379394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(images , labels , batch_size=128 , epochs=30 , validation_data = (t_images ,t_labels))","metadata":{"execution":{"iopub.status.busy":"2022-07-12T12:29:10.237657Z","iopub.execute_input":"2022-07-12T12:29:10.237937Z","iopub.status.idle":"2022-07-12T12:38:32.550036Z","shell.execute_reply.started":"2022-07-12T12:29:10.237908Z","shell.execute_reply":"2022-07-12T12:38:32.549267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['loss'], label='train loss')\nplt.plot(history.history['val_loss'], label='val loss')\nplt.legend()\nplt.show()\n# plt.savefig('LossVal_loss_DenseNet201')\n\n# plot the accuracy\nplt.plot(history.history['accuracy'], label='train acc')\nplt.plot(history.history['val_accuracy'], label='val acc')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-12T12:38:32.552089Z","iopub.execute_input":"2022-07-12T12:38:32.552320Z","iopub.status.idle":"2022-07-12T12:38:32.919159Z","shell.execute_reply.started":"2022-07-12T12:38:32.552289Z","shell.execute_reply":"2022-07-12T12:38:32.918379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### some change","metadata":{}},{"cell_type":"code","source":"model = keras.Sequential([\n# Data Augmentation \n  \n\n  DenseNet121(weights='imagenet',include_top=False, classes=7, input_shape=(48,48,3)), #Extract features \n\n  layers.BatchNormalization(),\n\n\n  #CNN layer \n# 32 ,64 ,128\n  layers.Conv2D(128,(3,3),padding = 'same'), \n  layers.BatchNormalization(),\n  layers.LeakyReLU(alpha=0.1),\n  layers.MaxPooling2D(pool_size = (2,2),padding = 'same'), \n  layers.Dropout(0.65), \n\n  layers.Conv2D(128,(3,3),padding = 'same'), \n  layers.BatchNormalization(),\n  layers.LeakyReLU(alpha=0.1),\n  layers.MaxPooling2D(pool_size = (2,2),padding = 'same'), \n  layers.Dropout(0.65), \n\n  layers.Flatten(),\n#Fully connected 1st layer \n\n  layers.Dense(16),\n  layers.BatchNormalization(), \n  layers.Activation('relu'), \n  layers.Dropout(0.6), \n    \n  layers.Dense(8),\n  layers.BatchNormalization(), \n  layers.Activation('relu'), \n  layers.Dropout(0.6), \n\n# Fully connected layer 2nd layer\n\n#   layers.Dense(128),\n#   layers.BatchNormalization(), \n#   layers.Activation('relu'), \n#   layers.Dropout(0.5), \n\n\n  layers.Dense(7, activation='softmax'),\n                          \n])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-07-12T06:18:09.844818Z","iopub.execute_input":"2022-07-12T06:18:09.845106Z","iopub.status.idle":"2022-07-12T06:18:13.854922Z","shell.execute_reply.started":"2022-07-12T06:18:09.845072Z","shell.execute_reply":"2022-07-12T06:18:13.854192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"opt = keras.optimizers.Adam(learning_rate=0.00010000000474974513)\nmodel.compile(\n  loss='categorical_crossentropy',\n  optimizer=opt,\n  metrics=['accuracy']\n)\n","metadata":{"execution":{"iopub.status.busy":"2022-07-12T06:18:19.053552Z","iopub.execute_input":"2022-07-12T06:18:19.054081Z","iopub.status.idle":"2022-07-12T06:18:19.072156Z","shell.execute_reply.started":"2022-07-12T06:18:19.054044Z","shell.execute_reply":"2022-07-12T06:18:19.071476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(images , labels , batch_size=32 , epochs=40 , validation_data = (t_images ,t_labels))","metadata":{"execution":{"iopub.status.busy":"2022-07-12T06:18:19.203797Z","iopub.execute_input":"2022-07-12T06:18:19.204115Z","iopub.status.idle":"2022-07-12T06:58:51.009118Z","shell.execute_reply.started":"2022-07-12T06:18:19.204085Z","shell.execute_reply":"2022-07-12T06:58:51.008347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['loss'], label='train loss')\nplt.plot(history.history['val_loss'], label='val loss')\nplt.legend()\nplt.show()\n# plt.savefig('LossVal_loss_DenseNet201')\n\n# plot the accuracy\nplt.plot(history.history['accuracy'], label='train acc')\nplt.plot(history.history['val_accuracy'], label='val acc')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-12T06:58:51.560641Z","iopub.execute_input":"2022-07-12T06:58:51.560867Z","iopub.status.idle":"2022-07-12T06:58:52.341803Z","shell.execute_reply.started":"2022-07-12T06:58:51.560839Z","shell.execute_reply":"2022-07-12T06:58:52.341121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = keras.Sequential([\n# Data Augmentation \n  \n\n  DenseNet121(weights='imagenet',include_top=False, classes=7, input_shape=(48,48,3)), #Extract features \n\n  layers.BatchNormalization(),\n\n\n  #CNN layer \n# 32 ,64 ,128\n  layers.Conv2D(128,(3,3),padding = 'same'), \n  layers.BatchNormalization(),\n  layers.LeakyReLU(alpha=0.1),\n  layers.MaxPooling2D(pool_size = (2,2),padding = 'same'), \n  layers.Dropout(0.65), \n\n  layers.Conv2D(128,(3,3),padding = 'same'), \n  layers.BatchNormalization(),\n  layers.LeakyReLU(alpha=0.1),\n  layers.MaxPooling2D(pool_size = (2,2),padding = 'same'), \n  layers.Dropout(0.65), \n    \n  layers.Conv2D(64,(3,3),padding = 'same'), \n  layers.BatchNormalization(),\n  layers.LeakyReLU(alpha=0.1),\n  layers.MaxPooling2D(pool_size = (2,2),padding = 'same'), \n  layers.Dropout(0.65), \n\n  layers.Flatten(),\n#Fully connected 1st layer \n\n  layers.Dense(32),\n  layers.BatchNormalization(), \n  layers.Activation('relu'), \n  layers.Dropout(0.6), \n    \n  layers.Dense(16),\n  layers.BatchNormalization(), \n  layers.Activation('relu'), \n  layers.Dropout(0.6), \n\n# Fully connected layer 2nd layer\n\n#   layers.Dense(128),\n#   layers.BatchNormalization(), \n#   layers.Activation('relu'), \n#   layers.Dropout(0.5), \n\n\n  layers.Dense(7, activation='softmax'),\n                          \n])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-07-12T07:00:49.771726Z","iopub.execute_input":"2022-07-12T07:00:49.771984Z","iopub.status.idle":"2022-07-12T07:00:52.998193Z","shell.execute_reply.started":"2022-07-12T07:00:49.771955Z","shell.execute_reply":"2022-07-12T07:00:52.997509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"opt = keras.optimizers.Adam(learning_rate=0.00010000000474974513)\nmodel.compile(\n  loss='categorical_crossentropy',\n  optimizer=opt,\n  metrics=['accuracy']\n)\nhistory = model.fit(images , labels , batch_size=32 , epochs=40 , validation_data = (t_images ,t_labels))","metadata":{"execution":{"iopub.status.busy":"2022-07-12T07:01:25.959018Z","iopub.execute_input":"2022-07-12T07:01:25.959271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*NO.2*","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.layers import Activation, Conv2D, MaxPooling2D, Dense, Flatten, Dropout, BatchNormalization\nmodel2 = tf.keras.Sequential()\n\n#Block 1:\nmodel2.add(Conv2D(64,(3,3),padding='same',kernel_initializer='he_normal',input_shape=(48,48,3)))\nmodel2.add(Activation('relu'))\nmodel2.add(BatchNormalization())\n# model2.add(Conv2D(64,(3,3),padding='same',kernel_initializer='he_normal'))\n# model2.add(Activation('relu'))\n# model2.add(BatchNormalization())\nmodel2.add(MaxPooling2D(pool_size=(2,2)))\nmodel2.add(Dropout(0.65))\n\n#Block 2:\nmodel2.add(Conv2D(256,(3,3),padding='same',kernel_initializer='he_normal'))\nmodel2.add(Activation('relu'))\nmodel2.add(BatchNormalization())\n# model2.add(Conv2D(256,(3,3),padding='same',kernel_initializer='he_normal'))\n# model2.add(Activation('relu'))\n# model2.add(BatchNormalization())\nmodel2.add(MaxPooling2D(pool_size=(2,2)))\nmodel2.add(Dropout(0.65))\n\n# #block 3:\nmodel2.add(Conv2D(512,(3,3),padding='same',kernel_initializer='he_normal'))\nmodel2.add(Activation('relu'))\nmodel2.add(BatchNormalization())\nmodel2.add(MaxPooling2D(pool_size=(2,2)))\nmodel2.add(Dropout(0.65))\n\n\nmodel2.add(Flatten())\nmodel2.add(Dense(1024,kernel_initializer='he_normal'))\nmodel2.add(Activation('relu'))\nmodel2.add(BatchNormalization())\nmodel.add(Dropout(0.65))\n\n\nmodel2.add(Dense(1024,kernel_initializer='he_normal'))\nmodel2.add(Activation('relu'))\nmodel2.add(BatchNormalization())\nmodel2.add(Dropout(0.65))\n\n\nmodel2.add(Dense(7,kernel_initializer='he_normal'))\nmodel2.add(Activation('softmax'))\n\nmodel2.summary()","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.926161Z","iopub.status.idle":"2022-07-11T20:20:07.926944Z","shell.execute_reply.started":"2022-07-11T20:20:07.926627Z","shell.execute_reply":"2022-07-11T20:20:07.926659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"opt = keras.optimizers.Adam(learning_rate=0.00010000000474974513)\nmodel2.compile(\n  loss='categorical_crossentropy',\n  optimizer=opt,\n  metrics=['accuracy']\n)\n","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.928256Z","iopub.status.idle":"2022-07-11T20:20:07.928948Z","shell.execute_reply.started":"2022-07-11T20:20:07.928687Z","shell.execute_reply":"2022-07-11T20:20:07.928716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model2.fit(images[736:] , labels[736:] , batch_size=32 , epochs=50 , validation_data = (images[:245] , labels[:245]))","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.930246Z","iopub.status.idle":"2022-07-11T20:20:07.930906Z","shell.execute_reply.started":"2022-07-11T20:20:07.930660Z","shell.execute_reply":"2022-07-11T20:20:07.930686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['loss'], label='train loss')\nplt.plot(history.history['val_loss'], label='val loss')\nplt.legend()\nplt.show()\n# plt.savefig('LossVal_loss_DenseNet201')\n\n# plot the accuracy\nplt.plot(history.history['accuracy'], label='train acc')\nplt.plot(history.history['val_accuracy'], label='val acc')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.932202Z","iopub.status.idle":"2022-07-11T20:20:07.932929Z","shell.execute_reply.started":"2022-07-11T20:20:07.932664Z","shell.execute_reply":"2022-07-11T20:20:07.932690Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### VGG16\n\n","metadata":{}},{"cell_type":"code","source":"model = keras.Sequential([\n# Data Augmentation \n  \n\n  VGG16(weights='imagenet',include_top=False, classes=6, input_shape=(64,64,3)), #Extract features \n\n  layers.BatchNormalization(),\n\n\n#CNN layer \n\n  layers.Conv2D(64,(3,3),padding = 'same'), \n  layers.BatchNormalization(),\n  layers.LeakyReLU(alpha=0.1),\n  layers.MaxPooling2D(pool_size = (2,2),padding = 'same'), \n  layers.Dropout(0.65), \n    \n#    layers.Conv2D(128,(3,3),padding = 'same'), \n#   layers.BatchNormalization(),\n#   layers.LeakyReLU(alpha=0.1),\n#   layers.MaxPooling2D(pool_size = (2,2),padding = 'same'), \n#   layers.Dropout(0.65),\n    \n#  layers.Conv2D(512,(3,3),padding = 'same'), \n#  layers.BatchNormalization(),\n#  layers.LeakyReLU(alpha=0.1),\n#  layers.MaxPooling2D(pool_size = (2,2),padding = 'same'), \n#  layers.Dropout(0.65), \n    \n layers.Flatten(),\n#Fully connected 1st layer \n\n  layers.Dense(1000),\n  layers.BatchNormalization(), \n  layers.Activation('relu'), \n  layers.Dropout(0.65), \n\n# Fully connected layer 2nd layer\n\n#   layers.Dense(128),\n#   layers.BatchNormalization(), \n#   layers.Activation('relu'), \n#   layers.Dropout(0.5), \n\n\n  layers.Dense(6, activation='softmax'),\n                          \n])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.942129Z","iopub.status.idle":"2022-07-11T20:20:07.942792Z","shell.execute_reply.started":"2022-07-11T20:20:07.942546Z","shell.execute_reply":"2022-07-11T20:20:07.942572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model.trainable = False\n# dropout1 = Dropout(0.5)\n# x = Flatten()(model.output)\n# x= x = dropout1(model.output)\n# prediction = Dense(6, activation='softmax')(x)\n# model = Model(inputs=model.input, outputs=prediction)","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.944001Z","iopub.status.idle":"2022-07-11T20:20:07.944772Z","shell.execute_reply.started":"2022-07-11T20:20:07.944502Z","shell.execute_reply":"2022-07-11T20:20:07.944531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# opt = keras.optimizers.Adam(learning_rate=0.00010000000474974513)\nopt = keras.optimizers.Adam(learning_rate=1e-7)\nmodel.compile(\n  loss='categorical_crossentropy',\n  optimizer=opt,\n  metrics=['accuracy']\n)\n","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.946018Z","iopub.status.idle":"2022-07-11T20:20:07.946673Z","shell.execute_reply.started":"2022-07-11T20:20:07.946438Z","shell.execute_reply":"2022-07-11T20:20:07.946462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(images , labels, batch_size=128 , epochs=30 , validation_data = (t_images , t_labels))","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.947908Z","iopub.status.idle":"2022-07-11T20:20:07.948580Z","shell.execute_reply.started":"2022-07-11T20:20:07.948333Z","shell.execute_reply":"2022-07-11T20:20:07.948361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['loss'], label='train loss')\nplt.plot(history.history['val_loss'], label='val loss')\nplt.legend()\nplt.show()\n# plt.savefig('LossVal_loss_DenseNet201')\n\n# plot the accuracy\nplt.plot(history.history['accuracy'], label='train acc')\nplt.plot(history.history['val_accuracy'], label='val acc')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.949784Z","iopub.status.idle":"2022-07-11T20:20:07.950417Z","shell.execute_reply.started":"2022-07-11T20:20:07.950157Z","shell.execute_reply":"2022-07-11T20:20:07.950182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### NASNetLarge","metadata":{}},{"cell_type":"code","source":"nas = NASNetLarge(\n    input_shape=(64,64,3),\n    include_top=True,\n#     weights=\"imagenet\",\n    pooling='max',\n#     classes=6\n)","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.951774Z","iopub.status.idle":"2022-07-11T20:20:07.952497Z","shell.execute_reply.started":"2022-07-11T20:20:07.952205Z","shell.execute_reply":"2022-07-11T20:20:07.952233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nas.trainable = False\nx = Flatten()(nas.output)\nprediction = Dense(7, activation='softmax')(x)\n\n# create a model object\nnas = Model(inputs=nas.input, outputs=prediction)","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.953907Z","iopub.status.idle":"2022-07-11T20:20:07.954590Z","shell.execute_reply.started":"2022-07-11T20:20:07.954355Z","shell.execute_reply":"2022-07-11T20:20:07.954380Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"opt = keras.optimizers.Adam(learning_rate=0.00010000000474974513)\nnas.compile(\n  loss='categorical_crossentropy',\n  optimizer=opt,\n  metrics=['accuracy']\n)\nhistory = nas.fit(images , labels, batch_size=32 , epochs=30 , validation_data = (t_images , t_labels))","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.955784Z","iopub.status.idle":"2022-07-11T20:20:07.956420Z","shell.execute_reply.started":"2022-07-11T20:20:07.956161Z","shell.execute_reply":"2022-07-11T20:20:07.956185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### efficientNet B0","metadata":{}},{"cell_type":"code","source":"ef_b0 = tf.keras.applications.EfficientNetB0(input_shape= (48,48,3) , include_top=False , weights=\"imagenet\", pooling='max')","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.957781Z","iopub.status.idle":"2022-07-11T20:20:07.958410Z","shell.execute_reply.started":"2022-07-11T20:20:07.958156Z","shell.execute_reply":"2022-07-11T20:20:07.958181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ef_b0.trainable = False\nx = Flatten()(ef_b0.output)\nprediction = Dense(6, activation='softmax')(x)\n\n# create a model object\nef_b0 = Model(inputs=ef_b0.input, outputs=prediction)\n\n# learning rate \nopt = keras.optimizers.Adam(learning_rate=0.00010000000474974513)\nef_b0.compile(\n  loss='categorical_crossentropy',\n  optimizer=opt,\n  metrics=['accuracy']\n)","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.959594Z","iopub.status.idle":"2022-07-11T20:20:07.960203Z","shell.execute_reply.started":"2022-07-11T20:20:07.959972Z","shell.execute_reply":"2022-07-11T20:20:07.959996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"r = ef_b0.fit(images[736:] , labels[736:] , batch_size=32 , epochs=50 , validation_data = (images[:245] , labels[:245]))","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.961464Z","iopub.status.idle":"2022-07-11T20:20:07.962141Z","shell.execute_reply.started":"2022-07-11T20:20:07.961895Z","shell.execute_reply":"2022-07-11T20:20:07.961921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(r.history['loss'], label='train loss')\nplt.plot(r.history['val_loss'], label='val loss')\nplt.legend()\nplt.show()\n# plt.savefig('LossVal_loss_DenseNet201')\n\n# plot the accuracy\nplt.plot(r.history['accuracy'], label='train acc')\nplt.plot(r.history['val_accuracy'], label='val acc')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.963401Z","iopub.status.idle":"2022-07-11T20:20:07.964012Z","shell.execute_reply.started":"2022-07-11T20:20:07.963781Z","shell.execute_reply":"2022-07-11T20:20:07.963805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### edit version\n","metadata":{}},{"cell_type":"code","source":"model = keras.Sequential([\n# Data Augmentation \n  \n tf.keras.applications.EfficientNetB0(weights='imagenet',include_top=False, classes=7, input_shape=(48,48,3)),\n# Data Augmentation \n  \n\n#   DenseNet121(weights='imagenet',include_top=False, classes=7, input_shape=(48,48,3)), #Extract features \n\n  layers.BatchNormalization(),\n\n#CNN layer \n\n#   layers.Conv2D(256,(3,3),padding = 'same'), \n#   layers.BatchNormalization(),\n#   layers.LeakyReLU(alpha=0.1),\n#   layers.MaxPooling2D(pool_size = (2,2),padding = 'same'), \n#   layers.Dropout(0.5), \n\n\n  layers.Flatten(),\n#Fully connected 1st layer \n\n  layers.Dense(1024),\n  layers.BatchNormalization(), \n  layers.Activation('relu'), \n  layers.Dropout(0.7), \n\nlayers.Dense(1024),\n  layers.BatchNormalization(), \n  layers.Activation('relu'), \n  layers.Dropout(0.7),\n# Fully connected layer 2nd layer\n\n#   layers.Dense(128),\n#   layers.BatchNormalization(), \n#   layers.Activation('relu'), \n#   layers.Dropout(0.5), \n\n\n  layers.Dense(7, activation='softmax'),\n                          \n])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-07-13T03:52:48.083653Z","iopub.execute_input":"2022-07-13T03:52:48.084203Z","iopub.status.idle":"2022-07-13T03:52:53.565558Z","shell.execute_reply.started":"2022-07-13T03:52:48.084163Z","shell.execute_reply":"2022-07-13T03:52:53.564876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"opt = keras.optimizers.Adam(learning_rate=0.00010000000474974513)\nmodel.compile(\n  loss='categorical_crossentropy',\n  optimizer=opt,\n  metrics=['accuracy']\n)\nr = model.fit(images , labels , batch_size=32 , epochs=100 , validation_data = (t_images , t_labels))","metadata":{"execution":{"iopub.status.busy":"2022-07-13T03:54:15.146152Z","iopub.execute_input":"2022-07-13T03:54:15.146679Z","iopub.status.idle":"2022-07-13T04:46:11.802204Z","shell.execute_reply.started":"2022-07-13T03:54:15.146639Z","shell.execute_reply":"2022-07-13T04:46:11.801167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(r.history['loss'], label='train loss')\nplt.plot(r.history['val_loss'], label='val loss')\nplt.legend()\nplt.show()\n# plt.savefig('LossVal_loss_DenseNet201')\n\n# plot the accuracy\nplt.plot(r.history['accuracy'], label='train acc')\nplt.plot(r.history['val_accuracy'], label='val acc')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-13T04:46:16.940271Z","iopub.execute_input":"2022-07-13T04:46:16.942479Z","iopub.status.idle":"2022-07-13T04:46:16.965330Z","shell.execute_reply.started":"2022-07-13T04:46:16.942443Z","shell.execute_reply":"2022-07-13T04:46:16.964207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = keras.Sequential([\n# Data Augmentation \n  \n tf.keras.applications.EfficientNetB0(weights='imagenet',include_top=False, classes=7, input_shape=(48,48,3)),\n# Data Augmentation \n  \n\n#   DenseNet121(weights='imagenet',include_top=False, classes=7, input_shape=(48,48,3)), #Extract features \n\n  layers.BatchNormalization(),\n\n#CNN layer \n\n  layers.Conv2D(256,(3,3),padding = 'same'), \n  layers.BatchNormalization(),\n  layers.LeakyReLU(alpha=0.1),\n  layers.MaxPooling2D(pool_size = (2,2),padding = 'same'), \n  layers.Dropout(0.7), \n\n\n  layers.Flatten(),\n#Fully connected 1st layer \n\n#   layers.Dense(16),\n#   layers.BatchNormalization(), \n#   layers.Activation('relu'), \n#   layers.Dropout(0.7), \n\n  layers.Dense(16),\n  layers.BatchNormalization(), \n  layers.Activation('relu'), \n  layers.Dropout(0.7),\n# Fully connected layer 2nd layer\n\n#   layers.Dense(128),\n#   layers.BatchNormalization(), \n#   layers.Activation('relu'), \n#   layers.Dropout(0.5), \n\n\n  layers.Dense(7, activation='softmax'),\n                          \n])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-07-13T04:52:05.532613Z","iopub.execute_input":"2022-07-13T04:52:05.532885Z","iopub.status.idle":"2022-07-13T04:52:07.602662Z","shell.execute_reply.started":"2022-07-13T04:52:05.532853Z","shell.execute_reply":"2022-07-13T04:52:07.601780Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"opt = keras.optimizers.Adam(learning_rate=0.00010000000474974513)\nmodel.compile(\n  loss='categorical_crossentropy',\n  optimizer=opt,\n  metrics=['accuracy']\n)\nr = model.fit(images , labels , batch_size=32 , epochs=100 , validation_data = (t_images , t_labels))","metadata":{"execution":{"iopub.status.busy":"2022-07-13T04:52:28.580947Z","iopub.execute_input":"2022-07-13T04:52:28.581476Z","iopub.status.idle":"2022-07-13T05:39:46.939341Z","shell.execute_reply.started":"2022-07-13T04:52:28.581441Z","shell.execute_reply":"2022-07-13T05:39:46.938021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(r.history['loss'], label='train loss')\nplt.plot(r.history['val_loss'], label='val loss')\nplt.legend()\nplt.show()\n# plt.savefig('LossVal_loss_DenseNet201')\n\n# plot the accuracy\nplt.plot(r.history['accuracy'], label='train acc')\nplt.plot(r.history['val_accuracy'], label='val acc')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-12T18:26:45.979849Z","iopub.status.idle":"2022-07-12T18:26:45.981336Z","shell.execute_reply.started":"2022-07-12T18:26:45.981083Z","shell.execute_reply":"2022-07-12T18:26:45.981108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ef_b1 = tf.keras.applications.EfficientNetB1(input_shape= (48,48,3) , include_top=False , weights=\"imagenet\", pooling='max')\n\n################## B1\n\nef_b1.trainable = False\nx = Flatten()(ef_b1.output)\nprediction = Dense(6, activation='softmax')(x)\n\n# create a model object\nef_b1 = Model(inputs=ef_b1.input, outputs=prediction)\n\n# learning rate \nopt = keras.optimizers.Adam(learning_rate=0.00010000000474974513)\nef_b1.compile(\n  loss='categorical_crossentropy',\n  optimizer=opt,\n  metrics=['accuracy']\n)","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.972696Z","iopub.status.idle":"2022-07-11T20:20:07.973366Z","shell.execute_reply.started":"2022-07-11T20:20:07.973100Z","shell.execute_reply":"2022-07-11T20:20:07.973135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"r = ef_b1.fit(images[736:] , labels[736:] , batch_size=32 , epochs=50 , validation_data = (images[:245] , labels[:245]))","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.974542Z","iopub.status.idle":"2022-07-11T20:20:07.975194Z","shell.execute_reply.started":"2022-07-11T20:20:07.974947Z","shell.execute_reply":"2022-07-11T20:20:07.974974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(r.history['loss'], label='train loss')\nplt.plot(r.history['val_loss'], label='val loss')\nplt.legend()\nplt.show()\n# plt.savefig('LossVal_loss_DenseNet201')\n\n# plot the accuracy\nplt.plot(r.history['accuracy'], label='train acc')\nplt.plot(r.history['val_accuracy'], label='val acc')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.976464Z","iopub.status.idle":"2022-07-11T20:20:07.977101Z","shell.execute_reply.started":"2022-07-11T20:20:07.976843Z","shell.execute_reply":"2022-07-11T20:20:07.976886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### EfficentNet B2","metadata":{}},{"cell_type":"code","source":"ef_b2 = tf.keras.applications.EfficientNetB2(input_shape= (48,48,3) , include_top=False , weights=\"imagenet\", pooling='max')\n\n################## B1\n\nef_b2.trainable = False\nx = Flatten()(ef_b2.output)\nprediction = Dense(6, activation='softmax')(x)\n\n# create a model object\nef_b2 = Model(inputs=ef_b2.input, outputs=prediction)\n\n# learning rate \nopt = keras.optimizers.Adam(learning_rate=0.00010000000474974513)\nef_b2.compile(\n  loss='categorical_crossentropy',\n  optimizer=opt,\n  metrics=['accuracy']\n)","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.978351Z","iopub.status.idle":"2022-07-11T20:20:07.978976Z","shell.execute_reply.started":"2022-07-11T20:20:07.978742Z","shell.execute_reply":"2022-07-11T20:20:07.978767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"r = ef_b2.fit(images , labels , batch_size=32 , epochs=50 , validation_data = (t_images , t_labels))","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.980177Z","iopub.status.idle":"2022-07-11T20:20:07.980868Z","shell.execute_reply.started":"2022-07-11T20:20:07.980632Z","shell.execute_reply":"2022-07-11T20:20:07.980658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(r.history['loss'], label='train loss')\nplt.plot(r.history['val_loss'], label='val loss')\nplt.legend()\nplt.show()\n# plt.savefig('LossVal_loss_DenseNet201')\n\n# plot the accuracy\nplt.plot(r.history['accuracy'], label='train acc')\nplt.plot(r.history['val_accuracy'], label='val acc')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.982118Z","iopub.status.idle":"2022-07-11T20:20:07.982800Z","shell.execute_reply.started":"2022-07-11T20:20:07.982551Z","shell.execute_reply":"2022-07-11T20:20:07.982577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ef_b3 = tf.keras.applications.EfficientNetB3(input_shape= (48,48,3) , include_top=False , weights=\"imagenet\", pooling='max')\n\n################## B1\n\nef_b3.trainable = False\nx = Flatten()(ef_b3.output)\nprediction = Dense(6, activation='softmax')(x)\n\n# create a model object\nef_b3 = Model(inputs=ef_b3.input, outputs=prediction)\n\n# learning rate \nopt = keras.optimizers.Adam(learning_rate=0.00010000000474974513)\nef_b3.compile(\n  loss='categorical_crossentropy',\n  optimizer=opt,\n  metrics=['accuracy']\n)","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.984046Z","iopub.status.idle":"2022-07-11T20:20:07.984712Z","shell.execute_reply.started":"2022-07-11T20:20:07.984480Z","shell.execute_reply":"2022-07-11T20:20:07.984505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"r = ef_b3.fit(images , labels , batch_size=32 , epochs=50 , validation_data = (t_images , t_labels))","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.986040Z","iopub.status.idle":"2022-07-11T20:20:07.986751Z","shell.execute_reply.started":"2022-07-11T20:20:07.986486Z","shell.execute_reply":"2022-07-11T20:20:07.986512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install utils\n","metadata":{"execution":{"iopub.status.busy":"2022-07-16T20:27:04.088772Z","iopub.execute_input":"2022-07-16T20:27:04.089109Z","iopub.status.idle":"2022-07-16T20:27:13.738501Z","shell.execute_reply.started":"2022-07-16T20:27:04.089070Z","shell.execute_reply":"2022-07-16T20:27:13.737669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install livelossplot","metadata":{"execution":{"iopub.status.busy":"2022-07-16T20:27:13.740756Z","iopub.execute_input":"2022-07-16T20:27:13.741029Z","iopub.status.idle":"2022-07-16T20:27:22.036290Z","shell.execute_reply.started":"2022-07-16T20:27:13.740995Z","shell.execute_reply":"2022-07-16T20:27:22.035412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport utils\nimport os\n%matplotlib inline\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Dense, Input, Dropout,Flatten, Conv2D\nfrom tensorflow.keras.layers import BatchNormalization, Activation, MaxPooling2D\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\nfrom tensorflow.keras.utils import plot_model\n\nfrom IPython.display import SVG, Image\nfrom livelossplot import PlotLossesKeras\n# from livelossplot import PlotLossesTensorFlowKeras\nimport tensorflow as tf\nprint(\"Tensorflow version:\", tf.__version__)\n","metadata":{"execution":{"iopub.status.busy":"2022-07-16T20:27:22.039673Z","iopub.execute_input":"2022-07-16T20:27:22.039937Z","iopub.status.idle":"2022-07-16T20:27:22.184923Z","shell.execute_reply.started":"2022-07-16T20:27:22.039908Z","shell.execute_reply":"2022-07-16T20:27:22.184231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = keras.Sequential()\n\n# Conv Block 1\nmodel.add(Conv2D(64, (3,3), padding='same', input_shape=(48,48,1)))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\n# Conv Block 2\nmodel.add(Conv2D(128,(5,5), padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\n# Conv Block 3\nmodel.add(Conv2D(512,(3,3), padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\n# Conv Block 3\nmodel.add(Conv2D(512,(3,3), padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\n\n# Fully connected Block 1\nmodel.add(Dense(256))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.25))\n\n# Fully connected Block 2\nmodel.add(Dense(512))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.25))\n\nmodel.add(Dense(7, activation='softmax'))\n\nopt = Adam(lr=0.0005)\n# opt = Adam(lr= 0.00010000000474974513)\nmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-07-16T20:27:22.186873Z","iopub.execute_input":"2022-07-16T20:27:22.187502Z","iopub.status.idle":"2022-07-16T20:27:25.214032Z","shell.execute_reply.started":"2022-07-16T20:27:22.187458Z","shell.execute_reply":"2022-07-16T20:27:25.213251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Data Augmentation\n","metadata":{}},{"cell_type":"code","source":"# datagen =  ImageDataGenerator(\n#   #preprocessing_function=preprocess_input,\n# #   rotation_range=30,\n# #   width_shift_range=0.2,\n# #   height_shift_range=0.2,\n# #   shear_range=0.2,\n# #   zoom_range=0.2,\n#   horizontal_flip=True\n# )\n\n# aug = ImageDataGenerator(rotation_range=45,\n#                          width_shift_range=0.2,\n#                          color_mode='grayscale',\n#                          height_shift_range=0.2) \n# #                          horizontal_flip = False,\n# #                          fill_mode='nearrest')\n\n# aug.fit(images)\nimg_size = 48\nbatch_size = 64\n\n# Data generator to augment data for training\ndatagen_train = ImageDataGenerator(horizontal_flip=True)\ntrain_generator = datagen_train.flow_from_directory(\"../input/emotion-detection-fer/train\", \n                                                    target_size=(img_size,img_size), \n                                                    color_mode='grayscale',\n                                                   batch_size=batch_size,\n                                                   class_mode='categorical',\n                                                   shuffle=True)\n\n# Data generator to augment data for validation\ndatagen_validation = ImageDataGenerator(horizontal_flip=True)\nvalidation_generator = datagen_train.flow_from_directory(\"../input/emotion-detection-fer/test\", \n                                                    target_size=(img_size,img_size), \n                                                    color_mode='grayscale',\n                                                   batch_size=batch_size,\n                                                   class_mode='categorical',\n                                                   shuffle=False)\n","metadata":{"execution":{"iopub.status.busy":"2022-07-16T20:27:25.215686Z","iopub.execute_input":"2022-07-16T20:27:25.215957Z","iopub.status.idle":"2022-07-16T20:27:30.787569Z","shell.execute_reply.started":"2022-07-16T20:27:25.215924Z","shell.execute_reply":"2022-07-16T20:27:30.786851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# r = model.fit(images , labels , batch_size=32 , epochs=50 , validation_data = (t_images , t_labels))\nepochs = 15\nsteps_per_epoch= train_generator.n//train_generator.batch_size\nvalidation_steps = validation_generator.n//validation_generator.batch_size\n\ncheckpoint = ModelCheckpoint(\"model_weights.h5\",monitor='val_accuracy',\n                            save_weights_only=True, mode='max',verbose=1)\nreduce_lr = ReduceLROnPlateau(monitor='val_loss' , factor=0.1, patience=2, min_lr=0.00001,model='auto')\n\ncallbacks = [PlotLossesKeras(), checkpoint, reduce_lr]\n","metadata":{"execution":{"iopub.status.busy":"2022-07-16T20:11:23.603678Z","iopub.execute_input":"2022-07-16T20:11:23.604105Z","iopub.status.idle":"2022-07-16T20:11:23.611208Z","shell.execute_reply.started":"2022-07-16T20:11:23.604065Z","shell.execute_reply":"2022-07-16T20:11:23.610092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(\n        x= train_generator,\n        steps_per_epoch=steps_per_epoch,\n        epochs=epochs,\n        validation_data=validation_generator,\n        validation_steps=validation_steps,\n        callbacks=callbacks\n)","metadata":{"execution":{"iopub.status.busy":"2022-07-16T20:11:26.525076Z","iopub.execute_input":"2022-07-16T20:11:26.525812Z","iopub.status.idle":"2022-07-16T20:20:41.747895Z","shell.execute_reply.started":"2022-07-16T20:11:26.525774Z","shell.execute_reply":"2022-07-16T20:20:41.747106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 32\nsteps_per_epoch= train_generator.n//train_generator.batch_size\nvalidation_steps = validation_generator.n//validation_generator.batch_size\n\ncheckpoint = ModelCheckpoint(\"model_weights.h5\",monitor='val_accuracy',\n                            save_weights_only=True, mode='max',verbose=1)\nreduce_lr = ReduceLROnPlateau(monitor='val_loss' , factor=0.1, patience=2, min_lr=0.00001,model='auto')\n\ncallbacks = [PlotLossesKeras(), checkpoint, reduce_lr]\n\nhistory = model.fit(\n        x= train_generator,\n        steps_per_epoch=steps_per_epoch,\n        epochs=epochs,\n        validation_data=validation_generator,\n        validation_steps=validation_steps,\n        callbacks=callbacks\n)","metadata":{"execution":{"iopub.status.busy":"2022-07-16T20:27:30.788981Z","iopub.execute_input":"2022-07-16T20:27:30.789223Z","iopub.status.idle":"2022-07-16T20:46:18.920876Z","shell.execute_reply.started":"2022-07-16T20:27:30.789188Z","shell.execute_reply":"2022-07-16T20:46:18.920052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = keras.Sequential([\n# Data Augmentation \n  \n\n  DenseNet121(weights='imagenet',include_top=False, classes=7, input_shape=(48,48,3)), #Extract features \n\n  layers.BatchNormalization(),\n\n\n#CNN layer \n\n  layers.Conv2D(128,(3,3),padding = 'same'), \n  layers.BatchNormalization(),\n  layers.LeakyReLU(alpha=0.1),\n  layers.MaxPooling2D(pool_size = (2,2),padding = 'same'), \n  layers.Dropout(0.5), \n\n\n  layers.Flatten(),\n#Fully connected 1st layer \n\n  layers.Dense(256),\n  layers.BatchNormalization(), \n  layers.Activation('relu'), \n  layers.Dropout(0.65), \n\n# Fully connected layer 2nd layer\n\n#   layers.Dense(128),\n#   layers.BatchNormalization(), \n#   layers.Activation('relu'), \n#   layers.Dropout(0.5), \n\n\n  layers.Dense(7, activation='softmax'),\n                          \n])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-07-16T21:01:19.712466Z","iopub.execute_input":"2022-07-16T21:01:19.712771Z","iopub.status.idle":"2022-07-16T21:01:23.106563Z","shell.execute_reply.started":"2022-07-16T21:01:19.712736Z","shell.execute_reply":"2022-07-16T21:01:23.105872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## DeepFace","metadata":{}},{"cell_type":"code","source":"!pip install deepface\n","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.988008Z","iopub.status.idle":"2022-07-11T20:20:07.988700Z","shell.execute_reply.started":"2022-07-11T20:20:07.988460Z","shell.execute_reply":"2022-07-11T20:20:07.988486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from deepface import DeepFace\n","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.989954Z","iopub.status.idle":"2022-07-11T20:20:07.990603Z","shell.execute_reply.started":"2022-07-11T20:20:07.990368Z","shell.execute_reply":"2022-07-11T20:20:07.990394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"face_analysis = DeepFace.analyze(img_path = \"../input/emotion-detection-fer/train/neutral/im1026.png\")\n","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.991858Z","iopub.status.idle":"2022-07-11T20:20:07.992561Z","shell.execute_reply.started":"2022-07-11T20:20:07.992312Z","shell.execute_reply":"2022-07-11T20:20:07.992339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"face_analysis","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:20:07.993823Z","iopub.status.idle":"2022-07-11T20:20:07.994498Z","shell.execute_reply.started":"2022-07-11T20:20:07.994229Z","shell.execute_reply":"2022-07-11T20:20:07.994269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}