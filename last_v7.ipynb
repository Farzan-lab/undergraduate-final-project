{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"../input/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-04T07:12:29.239556Z","iopub.execute_input":"2022-03-04T07:12:29.240148Z","iopub.status.idle":"2022-03-04T07:12:29.267891Z","shell.execute_reply.started":"2022-03-04T07:12:29.24005Z","shell.execute_reply":"2022-03-04T07:12:29.266073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### import libs\n","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport tensorflow as tf\nimport tensorflow.keras as k\n\nimport csv\nimport cv2\nimport os\n\nfrom tensorflow.keras.layers import Input, Lambda, Dense, Flatten\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.applications.densenet import DenseNet201 ,DenseNet121\nfrom tensorflow.keras.applications.mobilenet import MobileNet\nfrom tensorflow.keras.applications import VGG16,VGG19\nfrom tensorflow.keras.applications.densenet import preprocess_input\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\n\nfrom sklearn.utils import shuffle\nfrom sklearn.preprocessing import LabelEncoder , OneHotEncoder\nfrom sklearn.model_selection import train_test_split\n\nfrom scipy import ndimage","metadata":{"execution":{"iopub.status.busy":"2022-07-10T12:16:02.134646Z","iopub.execute_input":"2022-07-10T12:16:02.135225Z","iopub.status.idle":"2022-07-10T12:16:08.687070Z","shell.execute_reply.started":"2022-07-10T12:16:02.135134Z","shell.execute_reply":"2022-07-10T12:16:08.685811Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"imagetype= os.listdir(\"../input/emotion-detection-fer/train\")\ntest_imagetype= os.listdir(\"../input/emotion-detection-fer/test\")\nck_imagetype= os.listdir(\"../input/ckplus/CK+48\")\nimagetype.remove(\"disgusted\")\ntest_imagetype.remove(\"disgusted\")\n# ck_imagetype.remove(\"contempt\")\nprint(imagetype)\nprint(test_imagetype)\nprint(ck_imagetype)","metadata":{"execution":{"iopub.status.busy":"2022-07-10T12:16:08.693394Z","iopub.execute_input":"2022-07-10T12:16:08.696218Z","iopub.status.idle":"2022-07-10T12:16:08.736586Z","shell.execute_reply.started":"2022-07-10T12:16:08.696141Z","shell.execute_reply":"2022-07-10T12:16:08.735837Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"images = []    #images for train list will store all images\nlabels= []\nt_images = []    #images for test list will store all images\nt_labels= []\nck_images = []\nck_labels = []\npath = \"../input/emotion-detection-fer/train/\"\nt_path = \"../input/emotion-detection-fer/test/\"\nck_path = \"../input/ckplus/CK+48\"","metadata":{"execution":{"iopub.status.busy":"2022-07-10T12:16:08.737555Z","iopub.execute_input":"2022-07-10T12:16:08.738418Z","iopub.status.idle":"2022-07-10T12:16:08.744798Z","shell.execute_reply.started":"2022-07-10T12:16:08.738382Z","shell.execute_reply":"2022-07-10T12:16:08.743791Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## **FER13**","metadata":{}},{"cell_type":"markdown","source":"### *Load data*","metadata":{}},{"cell_type":"code","source":"for i in imagetype:\n    print(i)\n    flower_path=path+str(i)\n    data_list=[j for j in os.listdir(flower_path) if j.endswith(\".png\") ]\n    counter=0\n    for data in data_list:\n#         if counter> 2390: break\n        img=cv2.imread(flower_path + '/'+ data)\n#         img = cv2.resize(img , (64,64))\n        images.append(img)\n        labels.append(i)\n    \nprint(\"total train images:\",len(images))\nprint(\"total train images:\",len(labels))\n","metadata":{"execution":{"iopub.status.busy":"2022-07-10T12:16:08.748380Z","iopub.execute_input":"2022-07-10T12:16:08.749404Z","iopub.status.idle":"2022-07-10T12:18:03.332345Z","shell.execute_reply.started":"2022-07-10T12:16:08.749127Z","shell.execute_reply":"2022-07-10T12:18:03.331525Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"for i in test_imagetype:\n    print(i)\n    flower_path=t_path+str(i)\n    test_data_list=[j for j in os.listdir(flower_path) if j.endswith(\".png\") ]\n    counter=0\n    for data in test_data_list:\n#         if counter> 2390: break\n        img=cv2.imread(flower_path + '/'+ data)\n#         img = cv2.resize(img , (64,64))\n        t_images.append(img)\n        t_labels.append(i)\nprint(\"total test images:\",len(t_images))\nprint(\"total test images:\",len(t_labels))","metadata":{"execution":{"iopub.status.busy":"2022-07-10T12:18:03.334717Z","iopub.execute_input":"2022-07-10T12:18:03.335159Z","iopub.status.idle":"2022-07-10T12:18:28.807345Z","shell.execute_reply.started":"2022-07-10T12:18:03.335121Z","shell.execute_reply":"2022-07-10T12:18:28.806410Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# images,labels = shuffle(images, labels, random_state=10)\n# t_image , t_labels =  shuffle(t_images, t_labels, random_state=10)\n\n\n# for i in range(0,2000):\n#     images.append(t_images[i])\n#     labels.append(t_labels[i])","metadata":{"execution":{"iopub.status.busy":"2022-07-10T12:18:28.808701Z","iopub.execute_input":"2022-07-10T12:18:28.808969Z","iopub.status.idle":"2022-07-10T12:18:28.813031Z","shell.execute_reply.started":"2022-07-10T12:18:28.808932Z","shell.execute_reply":"2022-07-10T12:18:28.812158Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"type(images)","metadata":{"execution":{"iopub.status.busy":"2022-07-10T12:18:28.814808Z","iopub.execute_input":"2022-07-10T12:18:28.815092Z","iopub.status.idle":"2022-07-10T12:18:28.828079Z","shell.execute_reply.started":"2022-07-10T12:18:28.815058Z","shell.execute_reply":"2022-07-10T12:18:28.826899Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"encode= LabelEncoder()\nlabels=encode.fit_transform(labels)\nencode2= LabelEncoder()\nt_labels = encode2.fit_transform(t_labels)\nt_labels[1:10]","metadata":{"execution":{"iopub.status.busy":"2022-07-10T12:18:28.829595Z","iopub.execute_input":"2022-07-10T12:18:28.829901Z","iopub.status.idle":"2022-07-10T12:18:28.854272Z","shell.execute_reply.started":"2022-07-10T12:18:28.829845Z","shell.execute_reply":"2022-07-10T12:18:28.853648Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"labels=labels.reshape(-1,1)\nonehotencoder= OneHotEncoder()\nlabels=onehotencoder.fit_transform(labels)\nlabels=labels.toarray()\nlabels\nprint(\"train labels is ready!\")","metadata":{"execution":{"iopub.status.busy":"2022-07-10T12:18:28.855245Z","iopub.execute_input":"2022-07-10T12:18:28.856148Z","iopub.status.idle":"2022-07-10T12:18:28.864743Z","shell.execute_reply.started":"2022-07-10T12:18:28.856112Z","shell.execute_reply":"2022-07-10T12:18:28.863876Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"t_labels=t_labels.reshape(-1,1)\nonehotencoder= OneHotEncoder()\nt_labels=onehotencoder.fit_transform(t_labels)\nt_labels=t_labels.toarray()\nprint(\"test labels is ready!\")\nt_labels[:10]","metadata":{"execution":{"iopub.status.busy":"2022-07-10T12:18:28.867660Z","iopub.execute_input":"2022-07-10T12:18:28.867992Z","iopub.status.idle":"2022-07-10T12:18:28.878114Z","shell.execute_reply.started":"2022-07-10T12:18:28.867957Z","shell.execute_reply":"2022-07-10T12:18:28.877316Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"images=np.array(images)\nprint(images.shape)\nprint(labels.shape)","metadata":{"execution":{"iopub.status.busy":"2022-07-10T12:18:28.879290Z","iopub.execute_input":"2022-07-10T12:18:28.879669Z","iopub.status.idle":"2022-07-10T12:18:28.971950Z","shell.execute_reply.started":"2022-07-10T12:18:28.879636Z","shell.execute_reply":"2022-07-10T12:18:28.971141Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"t_images=np.array(t_images)\nprint(t_images.shape)\nprint(t_labels.shape)","metadata":{"execution":{"iopub.status.busy":"2022-07-10T12:18:28.973208Z","iopub.execute_input":"2022-07-10T12:18:28.973833Z","iopub.status.idle":"2022-07-10T12:18:28.999640Z","shell.execute_reply.started":"2022-07-10T12:18:28.973792Z","shell.execute_reply":"2022-07-10T12:18:28.998956Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"images,labels = shuffle(images, labels, random_state=10)\nt_images , t_labels =  shuffle(t_images, t_labels, random_state=10)","metadata":{"execution":{"iopub.status.busy":"2022-07-10T12:18:29.000668Z","iopub.execute_input":"2022-07-10T12:18:29.000880Z","iopub.status.idle":"2022-07-10T12:18:29.087157Z","shell.execute_reply.started":"2022-07-10T12:18:29.000857Z","shell.execute_reply":"2022-07-10T12:18:29.086429Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"plt.imshow(images[4])\nplt.xlabel(labels[4])","metadata":{"execution":{"iopub.status.busy":"2022-07-10T12:18:29.089395Z","iopub.execute_input":"2022-07-10T12:18:29.089893Z","iopub.status.idle":"2022-07-10T12:18:29.287160Z","shell.execute_reply.started":"2022-07-10T12:18:29.089856Z","shell.execute_reply":"2022-07-10T12:18:29.286466Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"## **CKPLUS**","metadata":{}},{"cell_type":"markdown","source":"### *load data*","metadata":{}},{"cell_type":"code","source":"for i in ck_imagetype:\n    print(i)\n    flower_path=ck_path+\"/\"+str(i)\n    data_list=[j for j in os.listdir(flower_path) if j.endswith(\".png\") ]\n    counter=0\n    for data in data_list:\n#         if counter> 2390: break\n        img=cv2.imread(flower_path + '/'+ data)\n#         img = cv2.resize(img , (64,64))\n        images.append(img)\n        labels.append(i)\n    \nprint(\"total train images:\",len(images))\nprint(\"total train images:\",len(labels))","metadata":{"execution":{"iopub.status.busy":"2022-03-13T13:47:13.130189Z","iopub.execute_input":"2022-03-13T13:47:13.130489Z","iopub.status.idle":"2022-03-13T13:47:19.430654Z","shell.execute_reply.started":"2022-03-13T13:47:13.13046Z","shell.execute_reply":"2022-03-13T13:47:19.429598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"start encoding\", end=\" ---> \")\nencode= LabelEncoder()\nlabels=encode.fit_transform(labels)\nprint (\"encoding finished\")\nprint (\"start one hot encoding\", end=\" ---> \")\nlabels=labels.reshape(-1,1)\nonehotencoder= OneHotEncoder()\nlabels=onehotencoder.fit_transform(labels)\nlabels=labels.toarray()\nprint(\"one hot encoding finished\")\nimages=np.array(images)\nprint(\"images and list shapes:\")\nprint(\"images shape:\", end=\" \" )\nprint(images.shape)\nprint(\"labels shape:\", end=\" \" )\nprint(labels.shape)\n","metadata":{"execution":{"iopub.status.busy":"2022-03-13T13:47:19.43252Z","iopub.execute_input":"2022-03-13T13:47:19.433662Z","iopub.status.idle":"2022-03-13T13:47:19.456528Z","shell.execute_reply.started":"2022-03-13T13:47:19.4336Z","shell.execute_reply":"2022-03-13T13:47:19.455582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images,labels = shuffle(images, labels, random_state=10)\nplt.imshow(images[4])\nplt.xlabel(labels[4])","metadata":{"execution":{"iopub.status.busy":"2022-03-13T13:47:19.460286Z","iopub.execute_input":"2022-03-13T13:47:19.460528Z","iopub.status.idle":"2022-03-13T13:47:19.71632Z","shell.execute_reply.started":"2022-03-13T13:47:19.460485Z","shell.execute_reply":"2022-03-13T13:47:19.715397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### *DenseNet201*","metadata":{}},{"cell_type":"code","source":"DenseNet201 = DenseNet201(input_shape= (48,48,3) ,  include_top=False , weights=\"imagenet\", pooling='max')","metadata":{"execution":{"iopub.status.busy":"2022-03-13T09:54:59.922444Z","iopub.execute_input":"2022-03-13T09:54:59.923233Z","iopub.status.idle":"2022-03-13T09:55:07.157908Z","shell.execute_reply.started":"2022-03-13T09:54:59.923192Z","shell.execute_reply":"2022-03-13T09:55:07.157158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DenseNet201.trainable = False\nx = Flatten()(DenseNet201.output)\nprediction = Dense(7, activation='softmax')(x)\n\n# create a model object\nDenseNet201 = Model(inputs=DenseNet201.input, outputs=prediction)","metadata":{"execution":{"iopub.status.busy":"2022-03-13T09:55:07.159914Z","iopub.execute_input":"2022-03-13T09:55:07.160425Z","iopub.status.idle":"2022-03-13T09:55:07.235774Z","shell.execute_reply.started":"2022-03-13T09:55:07.160388Z","shell.execute_reply":"2022-03-13T09:55:07.23512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"opt = keras.optimizers.Adam(learning_rate=0.00010000000474974513)\nDenseNet201.compile(\n  loss='categorical_crossentropy',\n  optimizer=opt,\n  metrics=['accuracy']\n)","metadata":{"execution":{"iopub.status.busy":"2022-03-13T09:55:07.23689Z","iopub.execute_input":"2022-03-13T09:55:07.237131Z","iopub.status.idle":"2022-03-13T09:55:07.26013Z","shell.execute_reply.started":"2022-03-13T09:55:07.237097Z","shell.execute_reply":"2022-03-13T09:55:07.259511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"r = DenseNet201.fit(images[736:] , labels[736:] , batch_size=32 , epochs=50 , validation_data = (images[:245] , labels[:245]))","metadata":{"execution":{"iopub.status.busy":"2022-03-13T09:55:07.262067Z","iopub.execute_input":"2022-03-13T09:55:07.262515Z","iopub.status.idle":"2022-03-13T09:55:53.920563Z","shell.execute_reply.started":"2022-03-13T09:55:07.26248Z","shell.execute_reply":"2022-03-13T09:55:53.919859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(r.history['loss'], label='train loss')\nplt.plot(r.history['val_loss'], label='val loss')\nplt.legend()\nplt.show()\n# plt.savefig('LossVal_loss_DenseNet201')\n\n# plot the accuracy\nplt.plot(r.history['accuracy'], label='train acc')\nplt.plot(r.history['val_accuracy'], label='val acc')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-13T09:55:53.924014Z","iopub.execute_input":"2022-03-13T09:55:53.924212Z","iopub.status.idle":"2022-03-13T09:55:54.287308Z","shell.execute_reply.started":"2022-03-13T09:55:53.924188Z","shell.execute_reply":"2022-03-13T09:55:54.286507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### *MobileNet*","metadata":{}},{"cell_type":"code","source":"mobile = MobileNet(input_shape= (48,48,3) , dropout = 0.1 ,  include_top=False , weights=\"imagenet\", pooling='max')","metadata":{"execution":{"iopub.status.busy":"2022-03-13T09:55:54.288727Z","iopub.execute_input":"2022-03-13T09:55:54.288981Z","iopub.status.idle":"2022-03-13T09:55:55.288119Z","shell.execute_reply.started":"2022-03-13T09:55:54.288948Z","shell.execute_reply":"2022-03-13T09:55:55.287418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mobile.trainable = False\nx = Flatten()(mobile.output)\nprediction = Dense(7, activation='softmax')(x)\nmobile = Model(inputs=mobile.input, outputs=prediction)","metadata":{"execution":{"iopub.status.busy":"2022-03-13T09:55:55.290118Z","iopub.execute_input":"2022-03-13T09:55:55.290356Z","iopub.status.idle":"2022-03-13T09:55:55.315713Z","shell.execute_reply.started":"2022-03-13T09:55:55.290323Z","shell.execute_reply":"2022-03-13T09:55:55.315082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"opt = keras.optimizers.Adam(learning_rate=0.00010000000474974513)\nmobile.compile(\n  loss='categorical_crossentropy',\n  optimizer=opt,\n  metrics=['accuracy']\n)","metadata":{"execution":{"iopub.status.busy":"2022-03-13T09:55:55.317025Z","iopub.execute_input":"2022-03-13T09:55:55.317272Z","iopub.status.idle":"2022-03-13T09:55:55.328529Z","shell.execute_reply.started":"2022-03-13T09:55:55.317239Z","shell.execute_reply":"2022-03-13T09:55:55.327677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"r = mobile.fit(images[736:] , labels[736:] , batch_size=32 , epochs=50 , validation_data = (images[:245] , labels[:245]))","metadata":{"execution":{"iopub.status.busy":"2022-03-13T09:55:55.330854Z","iopub.execute_input":"2022-03-13T09:55:55.331372Z","iopub.status.idle":"2022-03-13T09:56:02.552533Z","shell.execute_reply.started":"2022-03-13T09:55:55.331336Z","shell.execute_reply":"2022-03-13T09:56:02.551834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(r.history['loss'], label='train loss')\nplt.plot(r.history['val_loss'], label='val loss')\nplt.legend()\nplt.show()\n# plt.savefig('LossVal_loss_DenseNet201')\n\n# plot the accuracy\nplt.plot(r.history['accuracy'], label='train acc')\nplt.plot(r.history['val_accuracy'], label='val acc')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-13T09:56:02.554167Z","iopub.execute_input":"2022-03-13T09:56:02.554413Z","iopub.status.idle":"2022-03-13T09:56:02.903297Z","shell.execute_reply.started":"2022-03-13T09:56:02.554378Z","shell.execute_reply":"2022-03-13T09:56:02.902644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### *VGG16*","metadata":{}},{"cell_type":"code","source":"vgg16 = VGG16(input_shape= (48,48,3) , include_top=False , weights=\"imagenet\", pooling='max')\n","metadata":{"execution":{"iopub.status.busy":"2022-03-13T09:56:02.904784Z","iopub.execute_input":"2022-03-13T09:56:02.905277Z","iopub.status.idle":"2022-03-13T09:56:03.543496Z","shell.execute_reply.started":"2022-03-13T09:56:02.90524Z","shell.execute_reply":"2022-03-13T09:56:03.542741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vgg16.trainable = True\nx = Flatten()(vgg16.output)\nprediction = Dense(7, activation='softmax')(x)\n\n# create a model object\nvgg16 = Model(inputs=vgg16.input, outputs=prediction)","metadata":{"execution":{"iopub.status.busy":"2022-03-13T09:56:03.544701Z","iopub.execute_input":"2022-03-13T09:56:03.545035Z","iopub.status.idle":"2022-03-13T09:56:03.566689Z","shell.execute_reply.started":"2022-03-13T09:56:03.544976Z","shell.execute_reply":"2022-03-13T09:56:03.566033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"opt = keras.optimizers.Adam(learning_rate=0.00010000000474974513)\nvgg16.compile(\n  loss='categorical_crossentropy',\n  optimizer=opt,\n  metrics=['accuracy']\n)","metadata":{"execution":{"iopub.status.busy":"2022-03-13T09:56:03.569079Z","iopub.execute_input":"2022-03-13T09:56:03.569315Z","iopub.status.idle":"2022-03-13T09:56:03.578721Z","shell.execute_reply.started":"2022-03-13T09:56:03.569284Z","shell.execute_reply":"2022-03-13T09:56:03.577896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"r = vgg16.fit(images[736:] , labels[736:] , batch_size=32 , epochs=50 , validation_data = (images[:245] , labels[:245]))","metadata":{"execution":{"iopub.status.busy":"2022-03-13T09:56:03.581116Z","iopub.execute_input":"2022-03-13T09:56:03.581638Z","iopub.status.idle":"2022-03-13T09:56:19.516115Z","shell.execute_reply.started":"2022-03-13T09:56:03.581602Z","shell.execute_reply":"2022-03-13T09:56:19.515251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(r.history['loss'], label='train loss')\nplt.plot(r.history['val_loss'], label='val loss')\nplt.legend()\nplt.show()\n# plt.savefig('LossVal_loss_DenseNet201')\n\n# plot the accuracy\nplt.plot(r.history['accuracy'], label='train acc')\nplt.plot(r.history['val_accuracy'], label='val acc')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-13T09:56:19.518011Z","iopub.execute_input":"2022-03-13T09:56:19.518372Z","iopub.status.idle":"2022-03-13T09:56:19.935501Z","shell.execute_reply.started":"2022-03-13T09:56:19.518333Z","shell.execute_reply":"2022-03-13T09:56:19.934672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# vgg16.save_weights('vgg16_ckplus.h5')\n# ","metadata":{"execution":{"iopub.status.busy":"2022-03-10T09:33:08.977113Z","iopub.execute_input":"2022-03-10T09:33:08.977368Z","iopub.status.idle":"2022-03-10T09:33:08.9997Z","shell.execute_reply.started":"2022-03-10T09:33:08.977339Z","shell.execute_reply":"2022-03-10T09:33:08.998783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **models**","metadata":{}},{"cell_type":"markdown","source":"*NO.1*","metadata":{}},{"cell_type":"code","source":"model = keras.Sequential([\n# Data Augmentation \n  \n\n  DenseNet121(weights='imagenet',include_top=False, classes=6, input_shape=(48,48,3)), #Extract features \n\n  layers.BatchNormalization(),\n\n\n#CNN layer \n\n  layers.Conv2D(128,(3,3),padding = 'same'), \n  layers.BatchNormalization(),\n  layers.LeakyReLU(alpha=0.1),\n  layers.MaxPooling2D(pool_size = (2,2),padding = 'same'), \n  layers.Dropout(0.65), \n\n\n  layers.Flatten(),\n#Fully connected 1st layer \n\n  layers.Dense(256),\n  layers.BatchNormalization(), \n  layers.Activation('relu'), \n  layers.Dropout(0.65), \n\n# Fully connected layer 2nd layer\n\n#   layers.Dense(128),\n#   layers.BatchNormalization(), \n#   layers.Activation('relu'), \n#   layers.Dropout(0.5), \n\n\n  layers.Dense(7, activation='softmax'),\n                          \n])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-03-13T13:47:54.203257Z","iopub.execute_input":"2022-03-13T13:47:54.20367Z","iopub.status.idle":"2022-03-13T13:48:02.986259Z","shell.execute_reply.started":"2022-03-13T13:47:54.203617Z","shell.execute_reply":"2022-03-13T13:48:02.985254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"opt = keras.optimizers.Adam(learning_rate=0.00010000000474974513)\nmodel.compile(\n  loss='categorical_crossentropy',\n  optimizer=opt,\n  metrics=['accuracy']\n)\n","metadata":{"execution":{"iopub.status.busy":"2022-03-13T13:48:11.064486Z","iopub.execute_input":"2022-03-13T13:48:11.064797Z","iopub.status.idle":"2022-03-13T13:48:11.091314Z","shell.execute_reply.started":"2022-03-13T13:48:11.064768Z","shell.execute_reply":"2022-03-13T13:48:11.090276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(images[736:] , labels[736:] , batch_size=32 , epochs=60 , validation_data = (images[:245] , labels[:245]))","metadata":{"execution":{"iopub.status.busy":"2022-03-13T13:48:18.644478Z","iopub.execute_input":"2022-03-13T13:48:18.644797Z","iopub.status.idle":"2022-03-13T13:49:53.49201Z","shell.execute_reply.started":"2022-03-13T13:48:18.644752Z","shell.execute_reply":"2022-03-13T13:49:53.490683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['loss'], label='train loss')\nplt.plot(history.history['val_loss'], label='val loss')\nplt.legend()\nplt.show()\n# plt.savefig('LossVal_loss_DenseNet201')\n\n# plot the accuracy\nplt.plot(history.history['accuracy'], label='train acc')\nplt.plot(history.history['val_accuracy'], label='val acc')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-13T13:49:53.494992Z","iopub.execute_input":"2022-03-13T13:49:53.495346Z","iopub.status.idle":"2022-03-13T13:49:53.935688Z","shell.execute_reply.started":"2022-03-13T13:49:53.495298Z","shell.execute_reply":"2022-03-13T13:49:53.934694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*NO.2*","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.layers import Activation, Conv2D, MaxPooling2D, Dense, Flatten, Dropout, BatchNormalization\nmodel2 = tf.keras.Sequential()\n\n#Block 1:\nmodel2.add(Conv2D(64,(3,3),padding='same',kernel_initializer='he_normal',input_shape=(48,48,3)))\nmodel2.add(Activation('relu'))\nmodel2.add(BatchNormalization())\n# model2.add(Conv2D(64,(3,3),padding='same',kernel_initializer='he_normal'))\n# model2.add(Activation('relu'))\n# model2.add(BatchNormalization())\nmodel2.add(MaxPooling2D(pool_size=(2,2)))\nmodel2.add(Dropout(0.65))\n\n#Block 2:\nmodel2.add(Conv2D(256,(3,3),padding='same',kernel_initializer='he_normal'))\nmodel2.add(Activation('relu'))\nmodel2.add(BatchNormalization())\n# model2.add(Conv2D(256,(3,3),padding='same',kernel_initializer='he_normal'))\n# model2.add(Activation('relu'))\n# model2.add(BatchNormalization())\nmodel2.add(MaxPooling2D(pool_size=(2,2)))\nmodel2.add(Dropout(0.65))\n\n# #block 3:\nmodel2.add(Conv2D(512,(3,3),padding='same',kernel_initializer='he_normal'))\nmodel2.add(Activation('relu'))\nmodel2.add(BatchNormalization())\nmodel2.add(MaxPooling2D(pool_size=(2,2)))\nmodel2.add(Dropout(0.65))\n\n\nmodel2.add(Flatten())\nmodel2.add(Dense(1024,kernel_initializer='he_normal'))\nmodel2.add(Activation('relu'))\nmodel2.add(BatchNormalization())\nmodel.add(Dropout(0.65))\n\n\nmodel2.add(Dense(1024,kernel_initializer='he_normal'))\nmodel2.add(Activation('relu'))\nmodel2.add(BatchNormalization())\nmodel2.add(Dropout(0.65))\n\n\nmodel2.add(Dense(7,kernel_initializer='he_normal'))\nmodel2.add(Activation('softmax'))\n\nmodel2.summary()","metadata":{"execution":{"iopub.status.busy":"2022-03-13T14:14:28.06256Z","iopub.execute_input":"2022-03-13T14:14:28.062919Z","iopub.status.idle":"2022-03-13T14:14:28.274494Z","shell.execute_reply.started":"2022-03-13T14:14:28.062854Z","shell.execute_reply":"2022-03-13T14:14:28.273553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"opt = keras.optimizers.Adam(learning_rate=0.00010000000474974513)\nmodel2.compile(\n  loss='categorical_crossentropy',\n  optimizer=opt,\n  metrics=['accuracy']\n)\n","metadata":{"execution":{"iopub.status.busy":"2022-03-13T14:14:29.231593Z","iopub.execute_input":"2022-03-13T14:14:29.231901Z","iopub.status.idle":"2022-03-13T14:14:29.2597Z","shell.execute_reply.started":"2022-03-13T14:14:29.231843Z","shell.execute_reply":"2022-03-13T14:14:29.258658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model2.fit(images[736:] , labels[736:] , batch_size=32 , epochs=50 , validation_data = (images[:245] , labels[:245]))","metadata":{"execution":{"iopub.status.busy":"2022-03-13T14:14:31.210076Z","iopub.execute_input":"2022-03-13T14:14:31.210404Z","iopub.status.idle":"2022-03-13T14:14:42.609085Z","shell.execute_reply.started":"2022-03-13T14:14:31.210374Z","shell.execute_reply":"2022-03-13T14:14:42.608075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['loss'], label='train loss')\nplt.plot(history.history['val_loss'], label='val loss')\nplt.legend()\nplt.show()\n# plt.savefig('LossVal_loss_DenseNet201')\n\n# plot the accuracy\nplt.plot(history.history['accuracy'], label='train acc')\nplt.plot(history.history['val_accuracy'], label='val acc')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-13T14:14:05.977009Z","iopub.execute_input":"2022-03-13T14:14:05.978075Z","iopub.status.idle":"2022-03-13T14:14:06.441782Z","shell.execute_reply.started":"2022-03-13T14:14:05.978024Z","shell.execute_reply":"2022-03-13T14:14:06.44084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Augmentation\n","metadata":{}},{"cell_type":"code","source":"datagen =  ImageDataGenerator(\n  #preprocessing_function=preprocess_input,\n  rotation_range=30,\n  width_shift_range=0.2,\n  height_shift_range=0.2,\n  shear_range=0.2,\n  zoom_range=0.2,\n  horizontal_flip=True\n)","metadata":{"execution":{"iopub.status.busy":"2022-03-13T09:58:01.595918Z","iopub.execute_input":"2022-03-13T09:58:01.596667Z","iopub.status.idle":"2022-03-13T09:58:01.601943Z","shell.execute_reply.started":"2022-03-13T09:58:01.596616Z","shell.execute_reply":"2022-03-13T09:58:01.600909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"aug = ImageDataGenerator(rotation_range=45, width_shift_range=0.2,\n                        height_shift_range=0.2, horizontal_flip = False,\n                        fill_mode='nearrest')","metadata":{"execution":{"iopub.status.busy":"2022-03-09T12:51:33.727674Z","iopub.execute_input":"2022-03-09T12:51:33.728489Z","iopub.status.idle":"2022-03-09T12:51:33.732996Z","shell.execute_reply.started":"2022-03-09T12:51:33.728449Z","shell.execute_reply":"2022-03-09T12:51:33.731884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"aug.fit(images)\n","metadata":{"execution":{"iopub.status.busy":"2022-03-09T12:51:34.192556Z","iopub.execute_input":"2022-03-09T12:51:34.19281Z","iopub.status.idle":"2022-03-09T12:51:34.604616Z","shell.execute_reply.started":"2022-03-09T12:51:34.192781Z","shell.execute_reply":"2022-03-09T12:51:34.603896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(images , labels, batch_size=32 , epochs=60 , validation_data = (t_images , t_labels))","metadata":{"execution":{"iopub.status.busy":"2022-03-09T12:53:14.088564Z","iopub.execute_input":"2022-03-09T12:53:14.089108Z","iopub.status.idle":"2022-03-09T12:54:40.233686Z","shell.execute_reply.started":"2022-03-09T12:53:14.089072Z","shell.execute_reply":"2022-03-09T12:54:40.232753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### VGG16\n\n","metadata":{}},{"cell_type":"code","source":"model = keras.Sequential([\n# Data Augmentation \n  \n\n  VGG16(weights='imagenet',include_top=False, classes=6, input_shape=(64,64,3)), #Extract features \n\n  layers.BatchNormalization(),\n\n\n#CNN layer \n\n  layers.Conv2D(64,(3,3),padding = 'same'), \n  layers.BatchNormalization(),\n  layers.LeakyReLU(alpha=0.1),\n  layers.MaxPooling2D(pool_size = (2,2),padding = 'same'), \n  layers.Dropout(0.65), \n    \n#    layers.Conv2D(128,(3,3),padding = 'same'), \n#   layers.BatchNormalization(),\n#   layers.LeakyReLU(alpha=0.1),\n#   layers.MaxPooling2D(pool_size = (2,2),padding = 'same'), \n#   layers.Dropout(0.65),\n    \n#  layers.Conv2D(512,(3,3),padding = 'same'), \n#  layers.BatchNormalization(),\n#  layers.LeakyReLU(alpha=0.1),\n#  layers.MaxPooling2D(pool_size = (2,2),padding = 'same'), \n#  layers.Dropout(0.65), \n    \n layers.Flatten(),\n#Fully connected 1st layer \n\n  layers.Dense(1000),\n  layers.BatchNormalization(), \n  layers.Activation('relu'), \n  layers.Dropout(0.65), \n\n# Fully connected layer 2nd layer\n\n#   layers.Dense(128),\n#   layers.BatchNormalization(), \n#   layers.Activation('relu'), \n#   layers.Dropout(0.5), \n\n\n  layers.Dense(6, activation='softmax'),\n                          \n])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-03-11T09:10:48.973185Z","iopub.execute_input":"2022-03-11T09:10:48.973729Z","iopub.status.idle":"2022-03-11T09:10:49.359598Z","shell.execute_reply.started":"2022-03-11T09:10:48.973692Z","shell.execute_reply":"2022-03-11T09:10:49.358892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model.trainable = False\n# dropout1 = Dropout(0.5)\n# x = Flatten()(model.output)\n# x= x = dropout1(model.output)\n# prediction = Dense(6, activation='softmax')(x)\n# model = Model(inputs=model.input, outputs=prediction)","metadata":{"execution":{"iopub.status.busy":"2022-03-11T09:10:52.911837Z","iopub.execute_input":"2022-03-11T09:10:52.912612Z","iopub.status.idle":"2022-03-11T09:10:52.917416Z","shell.execute_reply.started":"2022-03-11T09:10:52.91256Z","shell.execute_reply":"2022-03-11T09:10:52.916712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# opt = keras.optimizers.Adam(learning_rate=0.00010000000474974513)\nopt = keras.optimizers.Adam(learning_rate=1e-7)\nmodel.compile(\n  loss='categorical_crossentropy',\n  optimizer=opt,\n  metrics=['accuracy']\n)\n","metadata":{"execution":{"iopub.status.busy":"2022-03-11T09:12:54.592735Z","iopub.execute_input":"2022-03-11T09:12:54.592991Z","iopub.status.idle":"2022-03-11T09:12:54.610658Z","shell.execute_reply.started":"2022-03-11T09:12:54.592959Z","shell.execute_reply":"2022-03-11T09:12:54.609986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(images , labels, batch_size=128 , epochs=30 , validation_data = (t_images , t_labels))","metadata":{"execution":{"iopub.status.busy":"2022-03-11T09:12:56.135569Z","iopub.execute_input":"2022-03-11T09:12:56.136091Z","iopub.status.idle":"2022-03-11T09:14:54.052572Z","shell.execute_reply.started":"2022-03-11T09:12:56.13604Z","shell.execute_reply":"2022-03-11T09:14:54.051283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['loss'], label='train loss')\nplt.plot(history.history['val_loss'], label='val loss')\nplt.legend()\nplt.show()\n# plt.savefig('LossVal_loss_DenseNet201')\n\n# plot the accuracy\nplt.plot(history.history['accuracy'], label='train acc')\nplt.plot(history.history['val_accuracy'], label='val acc')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-11T09:02:31.282989Z","iopub.execute_input":"2022-03-11T09:02:31.28328Z","iopub.status.idle":"2022-03-11T09:02:31.656886Z","shell.execute_reply.started":"2022-03-11T09:02:31.28324Z","shell.execute_reply":"2022-03-11T09:02:31.656224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### NASNetLarge","metadata":{}},{"cell_type":"code","source":"nas = NASNetLarge(\n    input_shape=(64,64,3),\n    include_top=True,\n#     weights=\"imagenet\",\n    pooling='max',\n#     classes=6\n)","metadata":{"execution":{"iopub.status.busy":"2022-03-11T07:11:59.267905Z","iopub.execute_input":"2022-03-11T07:11:59.26823Z","iopub.status.idle":"2022-03-11T07:11:59.29883Z","shell.execute_reply.started":"2022-03-11T07:11:59.268197Z","shell.execute_reply":"2022-03-11T07:11:59.29742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nas.trainable = False\nx = Flatten()(nas.output)\nprediction = Dense(7, activation='softmax')(x)\n\n# create a model object\nnas = Model(inputs=nas.input, outputs=prediction)","metadata":{"execution":{"iopub.status.busy":"2022-03-11T06:51:29.242486Z","iopub.execute_input":"2022-03-11T06:51:29.243096Z","iopub.status.idle":"2022-03-11T06:51:29.370897Z","shell.execute_reply.started":"2022-03-11T06:51:29.243062Z","shell.execute_reply":"2022-03-11T06:51:29.369879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"opt = keras.optimizers.Adam(learning_rate=0.00010000000474974513)\nnas.compile(\n  loss='categorical_crossentropy',\n  optimizer=opt,\n  metrics=['accuracy']\n)\nhistory = nas.fit(images , labels, batch_size=32 , epochs=30 , validation_data = (t_images , t_labels))","metadata":{"execution":{"iopub.status.busy":"2022-03-11T06:51:31.810136Z","iopub.execute_input":"2022-03-11T06:51:31.81049Z","iopub.status.idle":"2022-03-11T06:51:32.298499Z","shell.execute_reply.started":"2022-03-11T06:51:31.810458Z","shell.execute_reply":"2022-03-11T06:51:32.296819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### efficientNet B0","metadata":{}},{"cell_type":"code","source":"ef_b0 = tf.keras.applications.EfficientNetB0(input_shape= (48,48,3) , include_top=False , weights=\"imagenet\", pooling='max')","metadata":{"execution":{"iopub.status.busy":"2022-07-10T12:29:38.153577Z","iopub.execute_input":"2022-07-10T12:29:38.153848Z","iopub.status.idle":"2022-07-10T12:29:39.677458Z","shell.execute_reply.started":"2022-07-10T12:29:38.153818Z","shell.execute_reply":"2022-07-10T12:29:39.676682Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"ef_b0.trainable = False\nx = Flatten()(ef_b0.output)\nprediction = Dense(6, activation='softmax')(x)\n\n# create a model object\nef_b0 = Model(inputs=ef_b0.input, outputs=prediction)\n\n# learning rate \nopt = keras.optimizers.Adam(learning_rate=0.00010000000474974513)\nef_b0.compile(\n  loss='categorical_crossentropy',\n  optimizer=opt,\n  metrics=['accuracy']\n)","metadata":{"execution":{"iopub.status.busy":"2022-07-10T12:31:34.791131Z","iopub.execute_input":"2022-07-10T12:31:34.791393Z","iopub.status.idle":"2022-07-10T12:31:34.832167Z","shell.execute_reply.started":"2022-07-10T12:31:34.791356Z","shell.execute_reply":"2022-07-10T12:31:34.831426Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"opt = keras.optimizers.Adam(learning_rate=0.00010000000474974513)\nef_b0.compile(\n  loss='categorical_crossentropy',\n  optimizer=opt,\n  metrics=['accuracy']\n)","metadata":{"execution":{"iopub.status.busy":"2022-07-10T12:31:34.915467Z","iopub.execute_input":"2022-07-10T12:31:34.916319Z","iopub.status.idle":"2022-07-10T12:31:34.930546Z","shell.execute_reply.started":"2022-07-10T12:31:34.916210Z","shell.execute_reply":"2022-07-10T12:31:34.929709Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"r = ef_b0.fit(images[736:] , labels[736:] , batch_size=32 , epochs=50 , validation_data = (images[:245] , labels[:245]))","metadata":{"execution":{"iopub.status.busy":"2022-07-10T12:31:35.106371Z","iopub.execute_input":"2022-07-10T12:31:35.106617Z","iopub.status.idle":"2022-07-10T12:42:01.829515Z","shell.execute_reply.started":"2022-07-10T12:31:35.106589Z","shell.execute_reply":"2022-07-10T12:42:01.828777Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"plt.plot(r.history['loss'], label='train loss')\nplt.plot(r.history['val_loss'], label='val loss')\nplt.legend()\nplt.show()\n# plt.savefig('LossVal_loss_DenseNet201')\n\n# plot the accuracy\nplt.plot(r.history['accuracy'], label='train acc')\nplt.plot(r.history['val_accuracy'], label='val acc')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-10T12:48:31.351745Z","iopub.execute_input":"2022-07-10T12:48:31.352412Z","iopub.status.idle":"2022-07-10T12:48:31.725334Z","shell.execute_reply.started":"2022-07-10T12:48:31.352376Z","shell.execute_reply":"2022-07-10T12:48:31.724607Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"ef_b1 = tf.keras.applications.EfficientNetB1(input_shape= (48,48,3) , include_top=False , weights=\"imagenet\", pooling='max')\n\n################## B1\n\nef_b1.trainable = False\nx = Flatten()(ef_b1.output)\nprediction = Dense(6, activation='softmax')(x)\n\n# create a model object\nef_b1 = Model(inputs=ef_b1.input, outputs=prediction)\n\n# learning rate \nopt = keras.optimizers.Adam(learning_rate=0.00010000000474974513)\nef_b1.compile(\n  loss='categorical_crossentropy',\n  optimizer=opt,\n  metrics=['accuracy']\n)","metadata":{"execution":{"iopub.status.busy":"2022-07-10T12:48:45.594978Z","iopub.execute_input":"2022-07-10T12:48:45.595221Z","iopub.status.idle":"2022-07-10T12:48:49.213220Z","shell.execute_reply.started":"2022-07-10T12:48:45.595194Z","shell.execute_reply":"2022-07-10T12:48:49.212529Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"r = ef_b1.fit(images[736:] , labels[736:] , batch_size=32 , epochs=50 , validation_data = (images[:245] , labels[:245]))","metadata":{"execution":{"iopub.status.busy":"2022-07-10T12:49:10.995250Z","iopub.execute_input":"2022-07-10T12:49:10.995508Z","iopub.status.idle":"2022-07-10T13:03:39.631073Z","shell.execute_reply.started":"2022-07-10T12:49:10.995479Z","shell.execute_reply":"2022-07-10T13:03:39.630293Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"plt.plot(r.history['loss'], label='train loss')\nplt.plot(r.history['val_loss'], label='val loss')\nplt.legend()\nplt.show()\n# plt.savefig('LossVal_loss_DenseNet201')\n\n# plot the accuracy\nplt.plot(r.history['accuracy'], label='train acc')\nplt.plot(r.history['val_accuracy'], label='val acc')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-10T13:03:39.633132Z","iopub.execute_input":"2022-07-10T13:03:39.633330Z","iopub.status.idle":"2022-07-10T13:03:39.999215Z","shell.execute_reply.started":"2022-07-10T13:03:39.633306Z","shell.execute_reply":"2022-07-10T13:03:39.998565Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"#### EfficentNet B2","metadata":{}},{"cell_type":"code","source":"ef_b2 = tf.keras.applications.EfficientNetB2(input_shape= (48,48,3) , include_top=False , weights=\"imagenet\", pooling='max')\n\n################## B1\n\nef_b2.trainable = False\nx = Flatten()(ef_b2.output)\nprediction = Dense(6, activation='softmax')(x)\n\n# create a model object\nef_b2 = Model(inputs=ef_b2.input, outputs=prediction)\n\n# learning rate \nopt = keras.optimizers.Adam(learning_rate=0.00010000000474974513)\nef_b2.compile(\n  loss='categorical_crossentropy',\n  optimizer=opt,\n  metrics=['accuracy']\n)","metadata":{"execution":{"iopub.status.busy":"2022-07-10T13:04:35.055919Z","iopub.execute_input":"2022-07-10T13:04:35.056169Z","iopub.status.idle":"2022-07-10T13:04:37.501534Z","shell.execute_reply.started":"2022-07-10T13:04:35.056142Z","shell.execute_reply":"2022-07-10T13:04:37.500773Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"r = ef_b2.fit(images , labels , batch_size=32 , epochs=50 , validation_data = (t_images , t_labels))","metadata":{"execution":{"iopub.status.busy":"2022-07-10T13:04:37.503236Z","iopub.execute_input":"2022-07-10T13:04:37.503553Z","iopub.status.idle":"2022-07-10T13:23:06.015659Z","shell.execute_reply.started":"2022-07-10T13:04:37.503516Z","shell.execute_reply":"2022-07-10T13:23:06.014722Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"plt.plot(r.history['loss'], label='train loss')\nplt.plot(r.history['val_loss'], label='val loss')\nplt.legend()\nplt.show()\n# plt.savefig('LossVal_loss_DenseNet201')\n\n# plot the accuracy\nplt.plot(r.history['accuracy'], label='train acc')\nplt.plot(r.history['val_accuracy'], label='val acc')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-10T13:27:09.343509Z","iopub.execute_input":"2022-07-10T13:27:09.343782Z","iopub.status.idle":"2022-07-10T13:27:09.709271Z","shell.execute_reply.started":"2022-07-10T13:27:09.343750Z","shell.execute_reply":"2022-07-10T13:27:09.708571Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"ef_b3 = tf.keras.applications.EfficientNetB3(input_shape= (48,48,3) , include_top=False , weights=\"imagenet\", pooling='max')\n\n################## B1\n\nef_b3.trainable = False\nx = Flatten()(ef_b3.output)\nprediction = Dense(6, activation='softmax')(x)\n\n# create a model object\nef_b3 = Model(inputs=ef_b3.input, outputs=prediction)\n\n# learning rate \nopt = keras.optimizers.Adam(learning_rate=0.00010000000474974513)\nef_b3.compile(\n  loss='categorical_crossentropy',\n  optimizer=opt,\n  metrics=['accuracy']\n)","metadata":{"execution":{"iopub.status.busy":"2022-07-10T13:27:52.897266Z","iopub.execute_input":"2022-07-10T13:27:52.897537Z","iopub.status.idle":"2022-07-10T13:27:56.393903Z","shell.execute_reply.started":"2022-07-10T13:27:52.897506Z","shell.execute_reply":"2022-07-10T13:27:56.393186Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"r = ef_b3.fit(images , labels , batch_size=32 , epochs=50 , validation_data = (t_images , t_labels))","metadata":{"execution":{"iopub.status.busy":"2022-07-10T13:28:17.103670Z","iopub.execute_input":"2022-07-10T13:28:17.103969Z","iopub.status.idle":"2022-07-10T13:48:46.928281Z","shell.execute_reply.started":"2022-07-10T13:28:17.103939Z","shell.execute_reply":"2022-07-10T13:48:46.927505Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"plt.plot(r.history['loss'], label='train loss')\nplt.plot(r.history['val_loss'], label='val loss')\nplt.legend()\nplt.show()\n# plt.savefig('LossVal_loss_DenseNet201')\n\n# plot the accuracy\nplt.plot(r.history['accuracy'], label='train acc')\nplt.plot(r.history['val_accuracy'], label='val acc')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-10T13:49:36.177498Z","iopub.execute_input":"2022-07-10T13:49:36.177767Z","iopub.status.idle":"2022-07-10T13:49:36.535946Z","shell.execute_reply.started":"2022-07-10T13:49:36.177718Z","shell.execute_reply":"2022-07-10T13:49:36.535227Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"ef_b4 = tf.keras.applications.EfficientNetB4(input_shape= (48,48,3) , include_top=False , weights=\"imagenet\", pooling='max')\n\n################## B1\n\nef_b4.trainable = False\nx = Flatten()(ef_b4.output)\nprediction = Dense(6, activation='softmax')(x)\n\n# create a model object\nef_b4 = Model(inputs=ef_b4.input, outputs=prediction)\n\n# learning rate \nopt = keras.optimizers.Adam(learning_rate=0.00010000000474974513)\nef_b4.compile(\n  loss='categorical_crossentropy',\n  optimizer=opt,\n  metrics=['accuracy']\n)","metadata":{"execution":{"iopub.status.busy":"2022-07-10T13:56:46.368332Z","iopub.execute_input":"2022-07-10T13:56:46.368616Z","iopub.status.idle":"2022-07-10T13:56:50.478346Z","shell.execute_reply.started":"2022-07-10T13:56:46.368587Z","shell.execute_reply":"2022-07-10T13:56:50.477629Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"r = ef_b3.fit(images , labels , batch_size=32 , epochs=50 , validation_data = (t_images , t_labels))","metadata":{"execution":{"iopub.status.busy":"2022-07-10T13:57:12.734477Z","iopub.execute_input":"2022-07-10T13:57:12.734743Z","iopub.status.idle":"2022-07-10T14:17:35.033785Z","shell.execute_reply.started":"2022-07-10T13:57:12.734699Z","shell.execute_reply":"2022-07-10T14:17:35.033021Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"plt.plot(r.history['loss'], label='train loss')\nplt.plot(r.history['val_loss'], label='val loss')\nplt.legend()\nplt.show()\n# plt.savefig('LossVal_loss_DenseNet201')\n\n# plot the accuracy\nplt.plot(r.history['accuracy'], label='train acc')\nplt.plot(r.history['val_accuracy'], label='val acc')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-10T14:25:08.128563Z","iopub.execute_input":"2022-07-10T14:25:08.128827Z","iopub.status.idle":"2022-07-10T14:25:08.489225Z","shell.execute_reply.started":"2022-07-10T14:25:08.128798Z","shell.execute_reply":"2022-07-10T14:25:08.488563Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}